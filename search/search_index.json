{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"distribution/","title":"Flux Distribution Introduction","text":"<p>ControlPlane Enterprise for Flux CD is a comprehensive solution for organizations seeking to leverage the power of GitOps in their Kubernetes environments.</p> <p>Built on top of the CNCF-graduated Flux project, the ControlPlane distribution provides a secure, scalable, and enterprise-ready platform for managing the delivery of application and infrastructure workloads on multi-tenant Kubernetes clusters.</p> <p>The ControlPlane distribution comes with enterprise-hardened Flux controllers including support services for running Flux in production.</p>"},{"location":"distribution/#highlights","title":"Highlights","text":"<ul> <li> <p> Hardened Images</p> <p>The ControlPlane enterprise distribution comes with FIPS-compliant hardened containers images for the GitOps Toolkit controllers in-sync with the upstream CNCF Flux releases.</p> </li> <li> <p> Extended Kubernetes Compatibility</p> <p>The distribution is end-to-end tested with the latest six minor releases of Kubernetes, as well as RedHat OpenShift and Kubernetes LTS versions provided by cloud vendors such as AWS EKS, Azure AKS and Google GKE.</p> </li> <li> <p> Zero CVEs</p> <p>The ControlPlane images are continuously scanned for vulnerabilities and patched accordingly. We offer SLAs for remediation of critical vulnerabilities affecting Flux functionality, and we provide SBOMs and VEX documents for container images, dependencies and build environments.</p> </li> <li> <p> Maintained by Experts</p> <p>The enterprise distribution is maintained by security experts at ControlPlane together with CNCF Flux core maintainers. We provide hotfixes and CVE patches for the enterprise distribution ahead of the upstream releases, while keeping the feature set in-sync with the Flux project.</p> </li> </ul> <p>Flux Operator</p> <p>To streamline the deployment of the enterprise distribution, the ControlPlane team created the Flux Operator. The operator manages the lifecycle of the Flux controllers and automates the upgrade process, including the patching of hotfixes and CVEs affecting Flux functionality.</p>"},{"location":"distribution/#distribution-channels","title":"Distribution Channels","text":"<p>We offer the following distribution channels for the Flux controllers:</p> <ul> <li> FIPS-compliant</li> <li> Mainline</li> </ul>"},{"location":"distribution/#fips-compliant","title":"FIPS-compliant","text":"<p>The ControlPlane distribution offers hardened Google Distroless-based Flux images to organizations that must comply with NIST FIPS-140-3 standards.</p> <p>The Flux controller binaries are built using the FIPS 140-3 mode, and the Go runtime is configured to restrict all TLS configuration to FIPS-approved settings.</p>"},{"location":"distribution/#mainline","title":"Mainline","text":"<p>The mainline distribution channel offers Alpine Linux-based images fully compatible with the upstream Flux feature set.</p> <p>The major difference between the Flux upstream images and the ControlPlane mainline images is the continuous scanning and CVE patching for the container base images, OS packages, and Go dependencies.</p>"},{"location":"distribution/#distribution-components","title":"Distribution Components","text":"<p>The ControlPlane distribution comprises Open Source components such as the CNCF Flux controllers (Apache 2.0 License) and the Flux Operator (AGPL-3.0 License).</p> <p>Delivery Pipeline</p> <p>The build, test and release pipeline developed by ControlPlane is compliant with the SLSA security framework.</p> <p>The ControlPlane build system produces FIPS-compliant binaries, multi-arch container images, generates SBOMs, applies CVE patches &amp; hotfixes to the Open Source components, and runs conformance tests. The resulting container images and SBOMs are hosted on private registries that are only available to customers with a valid subscription.</p>"},{"location":"distribution/install/","title":"Flux Distribution Installation","text":"<p>ControlPlane offers a seamless transition from CNCF Flux to the enterprise distribution with no impact to Flux availability. The hardened container images provided by ControlPlane are fully compatible with the upstream Flux installation and bootstrap procedure.</p>"},{"location":"distribution/install/#flux-bootstrap","title":"Flux Bootstrap","text":"<p>Customers can bootstrap Flux with the enterprise distribution using the Flux CLI or the Flux Terraform provider. To access the ControlPlane images, customers need to provide the registry address and their credentials.</p> <p>Example of Flux CLI bootstrap with the FIPS-compliant images:</p> <pre><code>flux bootstrap github \\\n  --owner=customer-org \\\n  --repository=customer-repo \\\n  --branch=main \\\n  --path=clusters/production \\\n  --image-pull-secret=flux-enterprise-auth \\\n  --registry-creds=flux:$ENTERPRISE_TOKEN \\\n  --registry=ghcr.io/controlplaneio-fluxcd/distroless\n</code></pre> <p>Example of Flux Terraform Provider bootstrap with the mainline images:</p> <pre><code>resource \"flux_bootstrap_git\" \"this\" {\n  embedded_manifests   = true\n  path                 = \"clusters/my-cluster\"\n  image_pull_secret    = \"flux-enterprise-auth\"\n  registry_credentials = \"flux:${var.enterprise_token}\"\n  registry             = \"ghcr.io/controlplaneio-fluxcd/alpine\"\n}\n</code></pre> <p>Running the bootstrap command for a cluster with an existing Flux installation will trigger an in-place upgrade of the Flux controllers to the ControlPlane distribution.</p>"},{"location":"distribution/install/#automated-updates-to-bootstrap-repositories","title":"Automated Updates to Bootstrap Repositories","text":"<p>For keeping the Flux controllers images digests and manifests up-to-date with the latest version of the Enterprise Distribution, ControlPlane provides Kustomize images patches for the Flux manifests, which can be found in the distribution repository.</p> <p>Customers using GitHub can leverage the ControlPlane GitHub Actions to automate the update of the Flux manifests in their bootstrap repositories. For more information, see the Update Flux GitHub Action documentation.</p> <p>For customers using other Git providers, ControlPlane provides support for configuring automated updates for the Flux enterprise distribution.</p>"},{"location":"distribution/install/#migration-to-controlplane-distribution","title":"Migration to ControlPlane Distribution","text":"<p>Migration to the ControlPlane distribution is straightforward and requires minimal changes to the existing tooling used for deploying the Flux controllers. Having access to the ControlPlane registry, you can start using the enterprise distribution by changing the container image references from <code>ghcr.io/fluxcd/&lt;controller-name&gt;</code> to <code>&lt;control-plane-registry&gt;/&lt;controller-name&gt;</code>.</p> <p>On air-gapped environments, customers can copy the ControlPlane container images and the OCI artifacts (SBOMs and signatures) to their private registry using the crane CLI.</p> <p>Example script for copying the ControlPlane FIPS-compliant images to a private registry:</p> <pre><code>FLUX_CONTROLLERS=(\n\"source-controller\"\n\"kustomize-controller\"\n\"helm-controller\"\n\"notification-controller\"\n\"image-reflector-controller\"\n\"image-automation-controller\"\n)\n\ncrane auth login ghcr.io -u flux -p $ENTERPRISE_TOKEN\n\nfor controller in \"${FLUX_CONTROLLERS[@]}\"; do\n crane copy --all-tags ghcr.io/controlplaneio-fluxcd/distroless/$controller  &lt;your-registry&gt;/$controller\ndone\n</code></pre>"},{"location":"distribution/install/#flux-operator","title":"Flux Operator","text":"<p>The ControlPlane distribution includes the Flux Operator, which provides a declarative API for the lifecycle management of the Flux controllers, including automated CVE patching and upgrades.</p> <p>The operator offers an alternative to bootstrap, with the option to configure the reconciliation of the cluster state from OCI artifacts or S3-compatible storage, besides Git repositories.</p> <p>To deploy the enterprise distribution of Flux, point the operator to the ControlPlane registry:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\nspec:\n  distribution:\n    version: \"2.7.x\"\n    registry: \"ghcr.io/controlplaneio-fluxcd/distroless\"\n    imagePullSecret: \"flux-enterprise-auth\"\n  cluster:\n    type: kubernetes\n    domain: \"cluster.local\"\n    multitenant: true\n    networkPolicy: true\n</code></pre> <p>To access the ControlPlane registry, the <code>flux-enterprise-auth</code> Kubernetes secret must be created in the <code>flux-system</code> namespace and should contain the credentials to pull the enterprise images:</p> <pre><code>kubectl create secret docker-registry flux-enterprise-auth \\\n  --namespace flux-system \\\n  --docker-server=ghcr.io \\\n  --docker-username=flux \\\n  --docker-password=$ENTERPRISE_TOKEN\n</code></pre> <p>For more information, see the Flux Operator documentation.</p>"},{"location":"distribution/security/","title":"Supply Chain Security","text":"<p>The build, release and provenance portions of the ControlPlane distribution supply chain meet SLSA Build Level 3.</p>"},{"location":"distribution/security/#software-bill-of-materials","title":"Software Bill of Materials","text":"<p>The ControlPlane images come with SBOMs in SPDX format for each CPU architecture.</p> <p>Example of extracting the SBOM from the source-controller image:</p> <pre><code>docker buildx imagetools inspect \\\n    &lt;registry&gt;/source-controller:v1.3.0 \\\n    --format \"{{ json (index .SBOM \\\"linux/amd64\\\").SPDX}}\"\n</code></pre>"},{"location":"distribution/security/#signature-verification","title":"Signature Verification","text":"<p>The ControlPlane images are signed using Sigstore Cosign and GitHub OIDC.</p> <p>Example of verifying the signature of the source-controller image:</p> <pre><code>cosign verify &lt;registry&gt;/source-controller:v1.3.0 \\\n  --certificate-identity-regexp=^https://github\\\\.com/controlplaneio-fluxcd/.*$ \\\n  --certificate-oidc-issuer=https://token.actions.githubusercontent.com\n</code></pre>"},{"location":"distribution/security/#slsa-provenance-verification","title":"SLSA Provenance Verification","text":"<p>The provenance attestations are generated at build time with Docker Buildkit and include facts about the build process such as:</p> <ul> <li>Build timestamps</li> <li>Build parameters and environment</li> <li>Version control metadata</li> <li>Source code details</li> <li>Materials (files, scripts) consumed during the build</li> </ul> <p>Example of extracting the SLSA provenance JSON for the source-controller image:</p> <pre><code>docker buildx imagetools inspect \\\n  &lt;registry&gt;/source-controller:v1.3.0 \\\n  --format \"{{ json (index .Provenance \\\"linux/amd64\\\").SLSA}}\"\n</code></pre> <p>The provenance of the build artifacts is generated with the official SLSA GitHub Generator.</p> <p>Example of verifying the provenance of the source-controller image:</p> <pre><code>cosign verify-attestation --type slsaprovenance \\\n  --certificate-identity-regexp=^https://github.com/slsa-framework/slsa-github-generator/.github/workflows/generator_container_slsa3.yml.*$ \\\n  --certificate-oidc-issuer=https://token.actions.githubusercontent.com \\\n  &lt;registry&gt;/source-controller:v1.3.0\n</code></pre>"},{"location":"distribution/security/#vulnerability-exploitability-exchange","title":"Vulnerability Exploitability eXchange","text":"<p>The Flux controllers (source code, binaries and container images) are continuously scanned for CVEs. Once a CVE is detected, the ControlPlane team assesses the exploitability of the vulnerability. If the vulnerability is proven to be exploitable, the ControlPlane team provides a patch within the agreed SLA and issues a security bulletin to customers containing the CVE details and the container images digests that include the fix.</p> <p>There are cases where the vulnerability is not exploitable in the context of the Flux controllers, and in such cases, the ControlPlane team issues a CVE exception in the OpenVEX format.</p> <p>For each Flux minor release, the ControlPlane team maintains a VEX document with the list of vulnerabilities that do not affect the Flux controllers. The VEX documents are available in the enterprise distribution repository under the <code>vex</code> directory.</p> <p>Example of scanning the source-controller image with Trivy using the VEX document:</p> <pre><code>$ trivy image &lt;registry&gt;/source-controller:v1.2.2 --vex ./vex/v2.2.json --show-suppressed\n\nSuppressed Vulnerabilities (Total: 1)\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     Library     \u2502 Vulnerability  \u2502 Severity \u2502    Status    \u2502          Statement          \u2502 Source  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 helm.sh/helm/v3 \u2502 CVE-2019-25210 \u2502 MEDIUM   \u2502 not_affected \u2502 vulnerable_code_not_present \u2502 OpenVEX \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"distribution/upgrade/","title":"Flux Distribution Upgrade Procedure","text":"<p>The Flux distribution has a release cadence of approximately one minor release every three months, with patch releases in between. On production clusters, it is recommended to configure Flux Operator to automatically upgrade Flux to the latest patch release in the specified minor version range.</p> <p>Flux Operator</p> <p>The Flux Operator APIs are stable and backward compatible, so it is safe to upgrade the operator to the latest version at any time.</p>"},{"location":"distribution/upgrade/#upgrading-the-flux-operator","title":"Upgrading the Flux Operator","text":"<p>Depending on the installation method, upgrading the Flux Operator should be done in an automated manner.</p> <p>If you installed the operator with the Helm CLI, you can configure automated upgrades with a Flux <code>HelmRelease</code> as follows:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSet\nmetadata:\n  name: flux-operator\n  namespace: flux-system\nspec:\n  inputs:\n    - interval: \"1h\" # check for updates every hour\n      version: \"*\" # upgrade to latest stable version\n  resources:\n   - apiVersion: source.toolkit.fluxcd.io/v1\n     kind: OCIRepository\n     metadata:\n      name: &lt;&lt; inputs.provider.name &gt;&gt;\n      namespace: &lt;&lt; inputs.provider.namespace &gt;&gt;\n     spec:\n      interval: &lt;&lt; inputs.interval | quote &gt;&gt;\n      url: oci://ghcr.io/controlplaneio-fluxcd/charts/flux-operator\n      layerSelector:\n        mediaType: \"application/vnd.cncf.helm.chart.content.v1.tar+gzip\"\n        operation: copy\n      ref:\n        semver: &lt;&lt; inputs.version | quote &gt;&gt;\n   - apiVersion: helm.toolkit.fluxcd.io/v2\n     kind: HelmRelease\n     metadata:\n        name: &lt;&lt; inputs.provider.name &gt;&gt;\n        namespace: &lt;&lt; inputs.provider.namespace &gt;&gt;\n     spec:\n      interval: 12h\n      releaseName: &lt;&lt; inputs.provider.name &gt;&gt;\n      serviceAccountName: &lt;&lt; inputs.provider.name &gt;&gt;\n      chartRef:\n        kind: OCIRepository\n        name: &lt;&lt; inputs.provider.name &gt;&gt;\n      values:\n        reporting:\n          interval: 30s\n</code></pre> <p>If you installed the operator with Terraform/OpenTofu, update the <code>version</code> argument in the <code>helm_release</code> resource and apply the changes with <code>terraform apply</code>.</p> <p>If you installed the operator from OperatorHub, you can configure automatic upgrades by setting <code>Approval</code> to <code>Automatic</code> in OpenShift.</p>"},{"location":"distribution/upgrade/#upgrading-the-flux-distribution","title":"Upgrading the Flux Distribution","text":"<p>It is recommended to set the Flux distribution version in the <code>FluxInstance</code> manifest to a specific minor version, such as <code>2.6.x</code>, to have more control over the upgrade process.</p>"},{"location":"distribution/upgrade/#migrate-to-flux-stable-apis-in-git","title":"Migrate to Flux stable APIs in Git","text":"<p>Flux beta APIs EOL</p> <p>In Flux v2.7, the deprecated beta1 APIs have reached their end of life and are no longer supported.</p> <p>In Flux v2.8, the deprecated beta2 APIs will reach their end of life on Q1 2026.</p> <p>Before upgrading to Flux v2.7 or later, make sure to migrate all your manifests to the Flux v2.6 stable APIs in your Git repositories by using the <code>flux migrate -f</code> command:</p> <pre><code>git clone &lt;your-git-repo&gt;\ncd &lt;your-git-repo&gt;\nflux migrate -v 2.6 -f .\ngit commit -am \"Migrate to Flux v2.6 stable APIs\"\ngit push\n</code></pre>"},{"location":"distribution/upgrade/#update-the-flux-instance","title":"Update the Flux Instance","text":"<p>After migrating your resources in all Git repositories, update the <code>FluxInstance</code> manifest to the desired version:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\nspec:\n  distribution:\n    version: \"2.7.x\"\n</code></pre> <p>The operator will automatically upgrade the Flux components and migrate the Flux APIs to their latest API versions in-cluster.</p>"},{"location":"distribution/upgrade/#kubernetes-version-compatibility","title":"Kubernetes Version Compatibility","text":"<p>When planning an upgrade of the Flux distribution, make sure to check the compatibility with your Kubernetes cluster version.</p> <p>The Enterprise distribution of Flux supports the 6 most recent minor versions of Kubernetes, including Long-Term Support (LTS) versions offered by cloud providers, and the 3 most recent OpenShift versions. The list of supported Kubernetes and OpenShift versions is updated with every Flux Enterprise minor release and can be found in the release notes.</p> <p>The CNCF Flux distribution supports the 3 most recent minor versions of Kubernetes. The list of supported versions is updated with every Flux minor release and can be found in the flux2 release notes.</p>"},{"location":"guides/d1-architecture-reference/","title":"Flux D1 Architectural Reference","text":"<p>We present the Design 1 Reference Architecture Guide, our first set of best practices and production ready examples for complex multi-tenant multi-cluster environments.</p> <ul> <li> <p> GitOps Continuous Delivery</p> <p>The guide will show you how to orchestrate the GitOps delivery of applications and infrastructure workloads across multi-tenant clusters while catering to the different teams and stakeholders within an organisation. And how to automate the update of Helm OCI Artifacts to the staging environment while enabling gated promotion to production by leveraging GitHub Pull Requests.</p> </li> <li> <p> GitOps Security</p> <p>The guide will show you how to leverage on GitHub fine-grained Personal Access Tokens and Kubernetes RBAC for segregating responsibilities and access between platform, services, and application teams while maintaining security and compliance in a multi-tenant environment.</p> </li> </ul> <p> Download the guide</p>"},{"location":"guides/d2-architecture-reference/","title":"Flux D2 Architectural Reference","text":"<p>We present the Design 2 Reference Architecture Guide, which builds on the D1 architecture with some notable enhancements and new features.</p> <p>In this iteration of our reference architecture, we introduce the concept of Gitless GitOps: the desired state of the system is driven by OCI Artifacts stored in container registries that are built from manifests tracked in Git repositories during the Continuous Integration process. Continuous synchronization of desired and actual system state is achieved through automated workflows and Flux reconciliation mechanisms.</p>"},{"location":"guides/d2-architecture-reference/#repositories","title":"Repositories","text":"<ul> <li>d2-fleet - Defines the desired state of the Kubernetes clusters and tenants in the fleet.</li> <li>d2-infra - Defines the desired state of the cluster add-ons and the monitoring stack.</li> <li>d2-apps - Defines the desired state of the applications deployed across environments.</li> </ul> <p> Download the guide</p>"},{"location":"guides/flux-architecture/","title":"Flux Architecture","text":"<p>In this guide we will explore the architecture of Flux CD, and we will compare the deployment strategies of the Flux components when implementing GitOps for multi-cluster continuous delivery.</p>"},{"location":"guides/flux-architecture/#flux-components","title":"Flux components","text":"<p>Flux is powered by the GitOps Toolkit, a set of composable APIs and specialized tools that enable a wide range of continuous delivery use-cases, from simple Kubernetes deployment pipelines to multi-tenant/multi-env progressive delivery rollouts.</p> <p>The Flux project is made out of the following components:</p> <ul> <li> <p> Flux CLI</p> <p>A command-line tool for installing, upgrading, operating, monitoring and debugging the Flux controllers running on Kubernetes clusters.</p> </li> <li> <p> Flux Terraform Provider</p> <p>An infrastructure-as-code provider for bootstrapping Flux with Terraform and OpenTofu.</p> </li> <li> <p> Flux APIs</p> <p>A set of Kubernetes CRDs that allow defining continuous delivery workflows in a declarative manner.</p> </li> <li> <p> Flux controllers</p> <p>A set of Kubernetes controllers that automate all aspects of continuous delivery based on the declarative workflows defined with the Flux APIs.</p> </li> </ul>"},{"location":"guides/flux-architecture/#flux-controllers","title":"Flux controllers","text":"<ul> <li> <p> source-controller</p> <p>A controller specialised in artifacts acquisition from external sources such as Git, OCI, Helm repositories and S3-compatible buckets.</p> </li> <li> <p> kustomize-controller</p> <p>A controller specialized in running continuous delivery pipelines for infrastructure and workloads defined with Kubernetes manifests and assembled with Kustomize.</p> </li> <li> <p> helm-controller</p> <p>A controller specialized in managing the lifecycle of applications packaged as Helm charts.</p> </li> <li> <p> notification-controller</p> <p>A controller specialized in sending and receiving continuous delivery events to/from external services.</p> </li> <li> <p> image-reflector-controller</p> <p>A controller specialized in scanning container registries for new image versions and OCI artifacts revisions.</p> </li> <li> <p> image-automation-controller</p> <p>A controller specialized in automating the update of container images and OCI artifacts to Git.</p> </li> </ul> <p>Unlike most CI/CD systems, Flux does not rely on 3rd-party tools to perform its operations and can't be used to execute arbitrary scripts or commands in the cluster. From a security perspective, Flux execution is limited to the operations defined in the Flux APIs and the controllers are designed for multi-tenancy, using Kubernetes impersonation when deploying applications on behalf of tenants.</p> <p>To extend Flux beyond its built-in functions, custom controllers can be developed using the Flux controller SDK. For example, tofu-controller is a Flux controller for reconciling Terraform and OpenTofu modules.</p>"},{"location":"guides/flux-architecture/#flux-bootstrap","title":"Flux bootstrap","text":"<p>Bootstrap is the process of deploying the Flux controllers on a Kubernetes cluster and configuring them to watch a Git repository for changes. The bootstrap repository can contain references to other Git repos, OCI repos, Helm charts, S3-compatible buckets; together all these sources form the desired state of the cluster. </p> <p>With Flux running on the cluster, all changes to the desired state are automatically reconciled, including the self-update of the Flux controllers. If the cluster state drifts from the desired state, Flux will automatically correct it, effectively undoing any changes made to the cluster outside of the GitOps workflow.</p> <p></p> <p>A bootstrap repository can serve multiple clusters &amp; tenants, and can contain delivery pipelines that span across multiple environments. A typical repository structure used by platform teams to manage multiple clusters and tenants looks like this:</p> <pre><code>\u251c\u2500\u2500 clusters\n\u2502   \u251c\u2500\u2500 prod1\n\u2502   \u251c\u2500\u2500 prod2\n\u2502   \u251c\u2500\u2500 staging\n\u251c\u2500\u2500 infrastructure\n\u2502   \u251c\u2500\u2500 base\n\u2502   \u251c\u2500\u2500 production\n\u2502   \u2514\u2500\u2500 staging\n\u2514\u2500\u2500 tenants\n    \u251c\u2500\u2500 team1\n    \u2514\u2500\u2500 team2\n</code></pre> <p>The platform team can segregate the clusters add-ons from the tenants' applications. The cluster add-ons defined in the infrastructure directory, such as admission controllers, ingress, monitoring, logging, security policies, etc. are deployed by Flux under the cluster admin role. The platform team can define the reconciliation order and dependencies between the infrastructure components and the tenants' applications using the Flux <code>dependsOn</code> feature.</p> <p>The applications deployed on the clusters as Helm releases can be managed by various dev teams in their own repositories. The platform team can reference these repositories in the bootstrap repo and apply policies that enforce security, compliance, and best practices.</p>"},{"location":"guides/flux-architecture/#flux-multi-cluster-deployment-strategies","title":"Flux multi-cluster deployment strategies","text":"<p>When managing a fleet of Kubernetes clusters with Flux, the platform team can choose between two deployment strategies:</p> <ul> <li> <p> Standalone</p> <p>Flux is bootstrapped on each Kubernetes cluster.</p> </li> <li> <p> Hub and Spoke</p> <p>Flux is bootstrapped on a central cluster, acting as a GitOps hub.</p> </li> </ul>"},{"location":"guides/flux-architecture/#standalone","title":"Standalone","text":"<p>In the standalone mode, each Kubernetes cluster runs its own Flux controllers. This mode is suitable for most use-cases, where the clusters are reconciled independently, from the same or different bootstrap repositories.</p> <p></p> <p>Pros:</p> <ul> <li>Reduced attack surface, the API server of each cluster doesn't need to be exposed to external systems.</li> <li>Reduced blast radius, each cluster is self-sufficient and can operate independently.</li> <li>Suitable for hard multi-tenancy and air-gapped environments where clusters can't communicate with each other.</li> </ul> <p>Cons:</p> <ul> <li>Operational overhead, each cluster needs to be bootstrapped with Flux separately.</li> <li>Maintenance overhead, each Flux instance needs to be updated independently.</li> <li>Monitoring and observability overhead, each Flux instance needs to be monitored separately, the collected metrics and events need to be aggregated.</li> </ul> <p>To improve the observability of standalone instances, the platform team can configure the Flux notification-controller on each cluster to send all the continuous delivery events to a central alerting system.</p> <p>To reduce the operational overhead, the platform team can integrate the Flux Terraform provider with the cluster provisioning process, ensuring that each cluster is bootstrapped with Flux as part of the cluster creation workflow.</p> <p>To reduce the maintenance burden of standalone instances, the platform team can automate the Flux self-update process using GitHub Actions or Renovate bot.</p> <p>In standalone mode, the Git server hosting the bootstrap repository is a Single point of failure (SPOF).  The SPOF is mitigated by Flux source-controller which maintains a local cache of all external sources and can ensure that the cluster state drift detection and correction can continue even if the Git server suffers an outage.</p> <p>For more information on how to configure Flux for standalone mode, see the flux2-kustomize-helm-example and the flux2-multi-tenancy repositories.</p>"},{"location":"guides/flux-architecture/#hub-and-spoke","title":"Hub and Spoke","text":"<p>In the Hub and Spoke mode, a central cluster acts as a GitOps hub, managing the continuous delivery for multiple Kubernetes clusters. The hub cluster runs the Flux controllers from where it reconciles the spoke clusters by connecting to their Kubernetes API servers.</p> <p></p> <p>Pros:</p> <ul> <li>Reduced operational and maintenance overhead, bootstrapping and updating Flux is done once on the hub cluster.</li> <li>Single pane of glass, the platform team can monitor and observe the continuous delivery for all clusters using the Flux metrics and events from the hub instance.</li> <li>Suitable when clusters are provisioned with Kubernetes Cluster API, where the hub cluster acts as a management cluster.</li> </ul> <p>Cons:</p> <ul> <li>Single point of failure, the hub cluster is a SPOF for the continuous delivery for all clusters.</li> <li>Security concerns, if the hub cluster is compromised the attacker can gain access to all spoke clusters.</li> <li>Operational complexity, the platform team needs to manage the network connectivity between the hub and spoke clusters API servers.</li> </ul> <p>For more information on how to configure Flux for Hub and Spoke mode, see the flux2-hub-spoke-example repository.</p>"},{"location":"guides/flux-architecture/#hub-sharding-and-horizontal-scaling","title":"Hub sharding and horizontal scaling","text":"<p>When managing a large number of spoke clusters, the hub cluster can be sharded to distribute the reconciliation load across multiple Flux instances.</p> <p></p> <p>The primary Flux instance is responsible for deploying the Flux shard instances on the hub cluster and for distributing the reconciliation tasks across the shards. The bootstrap repository contains the sharding configuration, allowing the platform team to define the shard-to-cluster mapping and the reconciliation order in a declarative manner.</p> <p>For more information on how to assign Flux instances to specific clusters, see the Flux sharding and horizontal scaling guide.</p>"},{"location":"guides/flux-architecture/#conclusions","title":"Conclusions","text":"<p>Running Flux in the standalone mode offers a higher degree of security and autonomy for the clusters at the expense of operational overhead when it comes to bootstrapping and monitoring the Flux instances.</p> <p>The hub and spoke mode reduces the operational and maintenance overhead by centralizing the continuous delivery tooling on a single cluster, but introduces a single point of failure and networking complexity that can be challenging from a security perspective.</p> <p>In the standalone mode, Flux vertical scaling would suffice to handle the reconciliation load of thousands of applications, while in the hub and spoke mode, Flux horizontal scaling is required due to the increased latency and network overhead when managing a large number of clusters.</p> <p>Depending on the size and security constrains of the Kubernetes fleet, the platform team can choose a mix of standalone and hub-spoke modes. For example, using a hub cluster for managing the dev &amp; ephemeral test environments and standalone instances for the production clusters.</p>"},{"location":"guides/flux-cli-quick-reference/","title":"Flux CLI Quick Reference","text":"<p>This guide contains a list of commonly used <code>flux</code> commands for monitoring and troubleshooting the GitOps workflows managed by Flux.</p> <p>We assume that the Flux Operator was used to bootstrap the cluster and the Flux CLI users are restricted to read-only operations.</p>"},{"location":"guides/flux-cli-quick-reference/#installation","title":"Installation","text":"<p>The Flux CLI is available as a binary executable for Linux, macOS and Windows. The CLI can be downloaded from the FluxCD GitHub releases page.</p> <p>For macOS users, the Flux CLI can be installed using Homebrew:</p> <pre><code>brew install fluxcd/tap/flux\n</code></pre> <p>For Windows users, the Flux CLI can be installed using winget:</p> <pre><code>winget install --id=FluxCD.Flux  -e\n</code></pre>"},{"location":"guides/flux-cli-quick-reference/#shell-autocompletion","title":"Shell autocompletion","text":"<p>The Flux CLI supports shell completion for Bash, Zsh and Fish and PowerShell.</p> <p>When installing the Flux CLI using Homebrew, the completion scripts are automatically enabled.</p> <p>On Linux, auto-completion can be enabled using the <code>flux completion</code> commands, for example to enable it for Bash run:</p> <pre><code>echo \"source &lt;(flux completion bash)\" &gt;&gt; ~/.bash_profile\n</code></pre> <p>On Windows, the PowerShell completion can be enabled by running:</p> <pre><code>cd \"$env:USERPROFILE\\Documents\\WindowsPowerShell\\Modules\"\nflux completion powershell &gt;&gt; flux-completion.ps1\n</code></pre> <p>The Flux CLI autocompletion works the same as <code>kubectl</code>, to get suggestions for the available commands flags, namespaces, resources, etc., press the <code>Tab</code> key. Note that autocompletion for resource names requires the namespace to be specified first e.g. <code>flux -n apps get kustomization &lt;TAB&gt;</code>.</p>"},{"location":"guides/flux-cli-quick-reference/#cluster-access-configuration","title":"Cluster access configuration","text":"<p>The Flux CLI uses the Kubernetes configuration file (<code>~/.kube/config</code>) to access the cluster. Similar to <code>kubectl</code>, the Flux CLI can be configured to use a different configuration file by setting the <code>KUBECONFIG</code> environment variable or by using the <code>--kubeconfig</code> flag.</p> <p>When the Kubernetes configuration file contains multiple contexts, the Flux CLI will use the current one. To pick a different context, use the <code>--context</code> flag.</p> <p>One notable difference between <code>kubectl</code> and <code>flux</code> is that the Flux CLI defaults to the <code>flux-system</code> namespace when the <code>--namespace</code> flag is not set.</p>"},{"location":"guides/flux-cli-quick-reference/#flux-distribution-status","title":"Flux distribution status","text":"<p>Check the status of the Flux controllers and the CRDs installed on the cluster:</p> <pre><code>flux check\n</code></pre> <p>View the version of the Flux distribution installed on the cluster:</p> <pre><code>flux version\n</code></pre> <p>Note that is recommended for the CLI minor version to match the Flux distribution version installed on the cluster. If the versions do not match, the CLI could fail to query the cluster resources.</p>"},{"location":"guides/flux-cli-quick-reference/#cluster-reconciliation-status","title":"Cluster reconciliation status","text":"<p>List all the Flux resources and their status at the cluster level:</p> <pre><code>flux get all --all-namespaces\n</code></pre> <p>Note that the <code>--all-namespaces</code> flag alias is <code>-A</code>.</p> <p>To list all the resources in a specific namespace, use the <code>--namespace</code> flag (alias <code>-n</code>):</p> <pre><code>flux -n apps get all\n</code></pre> <p>Note that when not specifying the namespace, the <code>flux-system</code> namespace is used.</p> <p>To list all the resources of a specific kind, use the <code>flux get &lt;kind&gt;</code> command. For example, to list all the Flux Kustomizations in the <code>flux-system</code> namespace:</p> <pre><code>flux get kustomizations\n</code></pre> <p>To display the status of a specific resource, use the <code>flux get &lt;kind&gt; &lt;name&gt;</code> command. For example:</p> <pre><code>flux -n monitoring get kustomization kube-prometheus-stack\n</code></pre> <p>To find all the get commands available, run:</p> <pre><code>flux get --help\n</code></pre> <p>To view a report of Flux resources grouped by kind, including their readiness status and the amount of cumulative storage used for each source:</p> <pre><code>flux stats -A\n</code></pre>"},{"location":"guides/flux-cli-quick-reference/#kubernetes-objects-inspection","title":"Kubernetes objects inspection","text":"<p>To view the Kubernetes objects managed by a Flux Kustomization:</p> <pre><code>flux tree kustomization monitoring\n</code></pre> <p>The <code>flux tree</code> command displays all the managed Kubernetes objects by recursively inspecting the Flux resources including HelmReleases. </p> <p>To determine if a specific Kubernetes object is managed by Flux:</p> <pre><code>flux -n apps trace deployment podinfo\n</code></pre> <p>The <code>flux trace</code> command displays the Flux Kustomization or HelmRelease that manages the specified Kubernetes object and the Flux source (GitRepository, OCIRepository or HelmChart). This command is useful to determine the source of a specific Kubernetes object including the Git URL, branch, commit hash or the Helm chart version.</p>"},{"location":"guides/flux-cli-quick-reference/#troubleshooting","title":"Troubleshooting","text":"<p>List all Flux resources that are failing to reconcile and display the error message:</p> <pre><code>flux get all -A --status-selector ready=false\n</code></pre> <p>List all Flux resources that are currently reconciling and have not reached a ready state:</p> <pre><code>flux get all -A --status-selector ready=unknown\n</code></pre> <p>Display the events for all failing resources in a specific namespace:</p> <pre><code>flux -n apps events --types warning\n</code></pre> <p>Watch the error logs of all Flux controllers:</p> <pre><code>flux logs -A --level error --follow\n</code></pre>"},{"location":"guides/flux-cli-quick-reference/#flux-kustomization-debugging","title":"Flux Kustomization debugging","text":"<p>List all failed Kustomizations at the cluster level:</p> <pre><code>flux get kustomizations -A --status-selector ready=false\n</code></pre> <p>Display the configuration of a Kustomization:</p> <pre><code>flux -n apps export kustomization podinfo\n</code></pre> <p>Display the events of a Kustomization to see each reconciliation step:</p> <pre><code>flux -n apps events --for Kustomization/podinfo\n</code></pre> <p>Display the events of a Kustomization source, for example the GitRepository:</p> <pre><code>flux -n apps events --for GitRepository/podinfo\n</code></pre> <p>Display the logs of kustomize-controller for a specific Kustomization:</p> <pre><code>flux -n apps logs --kind Kustomization --name podinfo\n</code></pre> <p>Display the final variables used for post-build substitutions composed of referred ConfigMaps and Secrets:</p> <pre><code>flux -n apps debug kustomization podinfo --show-vars\n</code></pre> <p>Build a Flux Kustomization locally and display the resulting Kubernetes manifests:</p> <pre><code>flux -n apps build kustomization podinfo \\\n--path ./path/to/local/manifests \\\n--kustomization-file ./path/to/local/podinfo-kustomization.yaml\n</code></pre> <p>Note the build command can be used to test changes to Flux Kustomizations locally before pushing the changes to the Git repository.</p>"},{"location":"guides/flux-cli-quick-reference/#flux-helmrelease-debugging","title":"Flux HelmRelease debugging","text":"<p>List all failed HelmReleases at the cluster level:</p> <pre><code>flux get helmreleases -A --status-selector ready=false\n</code></pre> <p>Display the final values of a HelmRelease including the merged values from ConfigMaps and Secrets:</p> <pre><code>flux -n apps debug helmrelease podinfo --show-values\n</code></pre> <p>Display the configuration of a HelmRelease:</p> <pre><code>flux -n apps export helmrelease podinfo\n</code></pre> <p>Display the events of a HelmRelease to troubleshoot the reconciliation process:</p> <pre><code>flux -n apps events --for HelmRelese/podinfo\n</code></pre> <p>Display the events of a HelmRelease source, for example the OCIRepository that provides the Helm chart:</p> <pre><code>flux -n apps events --for OCIRepository/podinfo\n</code></pre> <p>Display the logs of helm-controller for a specific HelmRelease:</p> <pre><code>flux -n apps logs --kind HelmRelease --name podinfo\n</code></pre> <p>Display the logs of source-controller for a specific Helm chart source:</p> <pre><code>flux -n apps logs --kind OCIRepository --name podinfo\n</code></pre>"},{"location":"guides/flux-cli-quick-reference/#read-only-mode","title":"Read-only mode","text":"<p>To prevent users from altering the clusters state with commands such as <code>flux delete</code> or <code>flux reconciler</code> and only allow read operations, the following ClusterRole can be assigned to the Flux CLI users:</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: flux-cli-readonly\nrules:\n- apiGroups:\n  - source.toolkit.fluxcd.io\n  - kustomize.toolkit.fluxcd.io\n  - helm.toolkit.fluxcd.io\n  - notification.toolkit.fluxcd.io\n  - image.toolkit.fluxcd.io\n  resources:\n  - '*'\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - apiextensions.k8s.io\n  resources:\n  - customresourcedefinitions\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - apps\n  resources:\n  - deployments\n  - replicasets\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - \"\"\n  resources:\n  - pods\n  - pods/log\n  - events\n  - namespaces\n  - configmaps\n  verbs:\n  - get\n  - list\n  - watch\n</code></pre> <p>The following commands can be used in read-only mode:</p> <ul> <li><code>flux build</code></li> <li><code>flux check</code></li> <li><code>flux debug</code></li> <li><code>flux events</code></li> <li><code>flux export</code></li> <li><code>flux get</code></li> <li><code>flux logs</code></li> <li><code>flux stats</code></li> <li><code>flux trace</code></li> <li><code>flux tree</code></li> <li><code>flux version</code></li> </ul> <p>Note that the <code>flux build</code> and <code>flux debug</code> commands may require get permissions for Kubernetes Secrets, which are not included in the ClusterRole above.</p>"},{"location":"guides/flux-generic-helm-chart/","title":"Standardizing App Delivery with Flux and Generic Helm Charts","text":"<p>In this guide we will explore how Flux can be used to standardize the lifecycle management of applications by leveraging the Generic Helm Chart pattern.</p> <p>The big promise of this pattern is that it should reduce the cognitive load on developers, as they only need to focus on the service-specific configuration, while the Generic Helm Chart shields them from the complexity of the Kubernetes API.</p>"},{"location":"guides/flux-generic-helm-chart/#the-generic-helm-chart-pattern","title":"The Generic Helm Chart Pattern","text":"<p>We've seen the Generic Helm Chart popularity grow among the Flux community, especially in large organizations  as part of the platform team efforts to provide a consistent deployment experience to developers. After gathering feedback from the community, we've implemented a couple of features in Flux to make this pattern easier to implement at scale. Before we dive into the details, let's see why this pattern is so popular and what are the benefits and pitfalls of using it.</p> <p>A Generic Helm Chart can help ensure that all workloads are deployed in a consistent way, with the same configuration options and best practices. A major benefit of this approach is that it can considerably speed up the bootstrapping process for new services, as developers can reuse the Helm chart and only focus on the app configuration. Instead of spending time developing a new Helm chart, developers would only need to add a Flux <code>HelmRelease</code> resource and values files to the Git repository used by Flux to deploy applications across environments.</p> <p>Another benefit is that a common Helm chart can help implement security and compliance policies across all workloads. For example, we've seen organizations implementing restricted pod &amp; container security context, network policies and resource limits. A Generic Helm Chart that contains common sidecar containers, would speed up considerably the fix of security vulnerabilities across all services depending on these sidecars.</p>"},{"location":"guides/flux-generic-helm-chart/#one-helm-chart-per-service-type","title":"One Helm Chart per Service Type","text":"<p>One important aspect is that forcing all services to use the same Helm chart can drive the complexity of the configuration up, to avoid this, teams should consider creating a common Helm chart per service type. For example, one Helm chart for all web services developed with Node.js, one for all services developed with Java, etc. Some technologies might require sidecar containers to  function properly (e.g. NGINX with PHP-FPM), and this can be easily achieved by adding them to the common Helm chart dedicated to the PHP services without affecting the other services. Dedicated Helm charts can also improve the developer experience (DX), the chart values can expose technology-specific configuration options, such as JVM settings, while also providing sensible defaults specific to the technology stack.</p> <p>Having dedicated Helm charts for each service type can improve the maintainability of the charts and also limit the ownership to the team responsible for a particular technology stack. We've seen organizations adopting a co-ownership model where the platform team is involved in the maintenance of all Helm charts, while the development teams are responsible for the service-specific configuration for the generic Helm charts used by their services.</p>"},{"location":"guides/flux-generic-helm-chart/#developing-generic-helm-charts","title":"Developing Generic Helm Charts","text":"<p>When developing generic Helm charts, teams should consider having a dedicated Git repository for each chart. Changes to the Helm chart should be made with pull requests which are reviewed by people from the platform team and development teams.</p> <p>To ensure the changes are working as expected, teams should consider running unit tests and end-to-end tests as part of the CI/CD pipeline before merging PRs. Some popular tools are helm-unittest and chart-testing, the latter being developed and maintained by the Helm community.</p> <p>When developing the Helm chart, teams should take in to consideration the following aspects:</p> <ul> <li>Changes to the Helm chart should be backward compatible, especially when the chart is used by multiple   services. When structural changes are required to the values file, teams should consider deprecating   the old values and providing a migration path for the services using the Helm chart. Both old and new   values should be supported for a certain period of time to allow services to migrate to the new values.</li> <li>One pitfall of Helm charts in general is that the configuration options can grow to a point where   you end up with the whole Kubernetes API mingled in the values file. To avoid this, teams should consider   using the Flux <code>HelmRelease</code> post rendering feature   to address configuration edge cases instead of adding more configuration options to the Helm chart values.</li> <li>A Helm release is a namespace-scoped resource, thus the chart should not contain cluster-scoped resources,   especially Kubernetes <code>Namespace</code> resources. The namespace should be created by the Flux <code>Kustomization</code> that   reconciles the <code>HelmRelease</code> resources.</li> <li>In general, applications are not consumers of the Kubernetes API, thus the Helm chart should not grant any   permissions to the application pods. A good practice is to include a dedicated <code>ServiceAccount</code> in the Helm chart   and no <code>RoleBinding</code>, and especially no <code>ClusterRoleBinding</code>. The dedicated <code>ServiceAccount</code> can be useful if the   application needs to access cloud provider APIs, by leveraging the Kubernetes Workload Identity feature.</li> <li>An important aspect is that the Helm chart versioning is completely decoupled from the   application versioning. This means that the Helm <code>appVersion</code> metadata field can no longer be used   to track the application version. Teams should consider using the application container image   tag for the <code>app.kubernetes.io/version</code> label or have a dedicated field in the Helm chart values   to track the application version. When implementing observability, teams should consider surfacing   both the chart version and the application version for each Helm release.</li> </ul>"},{"location":"guides/flux-generic-helm-chart/#pushing-helm-charts-to-oci-registry","title":"Pushing Helm Charts to OCI Registry","text":"<p>The release process for the Helm chart should be fully automated based on the Git repository tags in semver format. When publishing pre-release versions of the Helm chart, teams should consider using the <code>X.Y.Z-rc.N</code> format to indicate that the version is not stable. Note that for Flux to correctly determine the latest release candidate version, you need to use a dot separator between the <code>rc</code> and the revision number, e.g. <code>1.0.0-rc.1</code> and <code>1.0.0-rc.2</code>.</p> <p>The release pipeline involves pushing the Helm chart to a container registry that is  accessible by the Kubernetes clusters. The registry must support the OCI Artifacts specification to be able to store Helm charts. Nowadays, most container registries hosted by Cloud provides support OCI Artifacts, also DockerHub, GitHub, GitLab. For on-prem, you can choose between: Harbor, Zot, Artifactory, Quay and the Docker distribution.</p> <p>A typical Helm chart release process involves the following steps:</p> <pre><code># Package the Helm chart\nhelm package src/my-jmv-chart --version ${GIT_TAG}\n\n# Login to the container registry\nhelm registry login my-registry.io\n\n# Push the Helm chart to the container registry\nhelm push my-jvm-chart-${GIT_TAG}.tgz oci://my-registry.io/charts\n\n# Sign the Helm chart\ncosign sign my-registry.io/charts/my-jmv-chart:${GIT_TAG}\n</code></pre> <p>Note that signing the Helm chart is optional, but it's a good practice to ensure the integrity and provenance of the OCI artifact. Flux supports verifying the Helm chart signature during the reconciliation process using Sigstore cosign or Notary notation.</p>"},{"location":"guides/flux-generic-helm-chart/#pulling-helm-charts-from-oci-registry-with-flux","title":"Pulling Helm Charts from OCI Registry with Flux","text":"<p>Starting with Flux v2.3, you can use the <code>OCIRepository</code> resource to pull Helm charts from OCI registries inside the Kubernetes cluster. The <code>OCIRepository</code> resource can be referenced by <code>HelmRelease</code> resources to deploy applications.</p> <p>What's important to note is that the an <code>OCIRepository</code> can be reused across multiple <code>HelmRelease</code> resources, which is useful when deploying multiple microservices using the generic Helm chart.</p> <p>Here is an example of an <code>OCIRepository</code> resource that pulls a Helm chart from an OCI registry:</p> <pre><code>apiVersion: source.toolkit.fluxcd.io/v1\nkind: OCIRepository\nmetadata:\n  name: my-jvm-chart\n  namespace: my-java-apps\nspec:\n  interval: 10m\n  url: oci://my-registry.io/charts/my-jvm-chart\n  layerSelector:\n    mediaType: \"application/vnd.cncf.helm.chart.content.v1.tar+gzip\"\n    operation: copy\n  ref:\n    semver: \"1.x\"\n</code></pre> <p>With <code>.spec.ref.semver</code> we can specify a semver range to match the Helm chart version. This is useful when we want to automatically pull to the latest version of the Helm chart. The <code>.spec.interval</code> field instructs the controller to check for new chart versions at a regular interval. When a new version is found, the Flux source-controller will pull the latest OCI artifact from the registry, which will automatically trigger Flux helm-controller to perform an upgrade of all the Helm releases referencing the shared <code>OCIRepository</code>.</p> <p>Examples of semver range:</p> <ul> <li><code>*</code> - matches the latest stable version (pre-releases are excluded)</li> <li><code>1.0.x</code> - matches the latest stable patch version of the 1.0.x series</li> <li><code>1.x</code> - matches the latest stable minor version of the 1.x series</li> <li><code>&gt;= 1.0.1 &lt; 1.1.0</code> - matches the latest stable version greater or equal to 1.0.1 and less than 1.1.0</li> <li><code>&gt;= 1.0.0-rc.0</code> - matches the latest version including pre-releases greater or equal to 1.0.0-rc.0</li> <li><code>1.2.3</code> - matches the exact version 1.2.3</li> </ul>"},{"location":"guides/flux-generic-helm-chart/#testing-pre-release-versions","title":"Testing pre-release versions","text":"<p>When testing pre-release versions (<code>X.Y.Z-rc.N</code>) of the generic Helm chart on staging clusters, the <code>.spec.ref.semver</code> field can be set to a range that matches the pre-release and  the <code>.spec.ref.semverFilter</code> field can be used to filter out the stable versions.</p> <p>Example of pulling the latest pre-release while filtering out versions that don't contain <code>-rc</code>:</p> <pre><code>kind: OCIRepository\nspec:\n  ref:\n    semver: \"&gt;= 0.0.0-0\"\n    semverFilter: \".*-rc.*\"\n</code></pre>"},{"location":"guides/flux-generic-helm-chart/#authenticating-to-the-oci-registry","title":"Authenticating to the OCI Registry","text":"<p>Flux supports the following authentication methods for OCI registries:</p> <ul> <li>Basic authentication with username and password or PAT (e.g. DockerHub, GitHub, Harbour)</li> <li>OIDC-based authentication using Kubernetes Workload Identity (e.g. ACR, GAR, ECR)</li> </ul> <p>When using static credentials, a Kubernetes Secret of type <code>kubernetes.io/dockerconfigjson</code> must be created in the same namespace as the <code>OCIRepository</code> containing the credentials.</p> <p>Example of generating a Secret containing GHCR credentials:</p> <pre><code>flux create secret oci ghcr-auth \\\n  --namespace=my-java-apps \\\n  --url=ghcr.io \\\n  --username=flux \\\n  --password=${GITHUB_PAT}\n</code></pre> <p>The image pull secret can be referenced in the <code>OCIRepository</code> spec as follows:</p> <pre><code>kind: OCIRepository\nspec:\n  provider: generic\n  secretRef:\n    name: ghcr-auth\n</code></pre> <p>When running Flux on AKS, EKS, or GKE, you can use the OIDC-based authentication method by setting the <code>.spec.provider</code> field to <code>azure</code>, <code>aws</code> or <code>gcp</code>. For more details on how to configure Kubernetes Workload Identity, refer to the OCIRepository provider documentation.</p>"},{"location":"guides/flux-generic-helm-chart/#verifying-the-helm-chart-signature","title":"Verifying the Helm Chart Signature","text":"<p>When using signed OCI Artifacts, Flux can verify the signature of the Helm chart using the following methods:</p> <ul> <li>Sigstore cosign with static key pair or OIDC-based signing</li> <li>Notary notation with static key pair</li> </ul> <p>Example of enabling signature verification for a Helm chart signed with cosign keyless and GitHub OIDC:</p> <pre><code>kind: OCIRepository\nspec:\n  verify:\n    provider: cosign\n    matchOIDCIdentity:\n      - issuer: \"^https://token.actions.githubusercontent.com$\"\n        subject: \"^https://github.com/my-org/my-jvm-chart.*$\"\n</code></pre> <p>For or more details on how to configure signature verification, refer to the OCIRepository verification documentation.</p>"},{"location":"guides/flux-generic-helm-chart/#deploying-apps-from-a-generic-helm-chart-with-flux","title":"Deploying Apps from a Generic Helm Chart with Flux","text":"<p>Once the <code>OCIRepository</code> is in place, we can reference it in the <code>HelmRelease</code> resources to deploy applications using the common Helm chart.</p> <p>Here is an example of multiple <code>HelmRelease</code> resources that reference the same <code>OCIRepository</code>:</p> <pre><code>apiVersion: helm.toolkit.fluxcd.io/v2\nkind: HelmRelease\nmetadata:\n  name: my-java-app1\n  namespace: my-java-apps\nspec:\n  interval: 1h\n  releaseName: my-java-app1\n  chartRef:\n    kind: OCIRepository\n    name: my-jvm-chart\n  values:\n    image:\n      repository: my-registry.io/my-java-app1\n      tag: 1.0.0\n---\napiVersion: helm.toolkit.fluxcd.io/v2\nkind: HelmRelease\nmetadata:\n  name: my-java-app2\n  namespace: my-java-apps\nspec:\n  interval: 1h\n  releaseName: my-java-app2\n  chartRef:\n    kind: OCIRepository\n    name: my-jvm-chart\n  values:\n    image:\n      repository: my-registry.io/my-java-app2\n      tag: 2.0.0\n</code></pre> <p>It is recommended to reuse the <code>OCIRepository</code> across multiple <code>HelmRelease</code> resources in the same namespace. While Flux allows chart references to other namespaces, it's a good practice to enabled Flux multi-tenancy lockdown which disables cross-namespace access to sources.</p>"},{"location":"guides/flux-generic-helm-chart/#passing-env-specific-values-to-helm-releases","title":"Passing env-specific values to Helm Releases","text":"<p>Besides setting the image repository and tag values, application-specific values are usually needed to configure the application on a per-environment basis. To change the values of the a <code>HelmRelease</code> resource based on the target environment (e.g. dev, staging, production), teams should consider using Kustomize overlays together with Kustomize configmaps and secrets generators.</p> <p>It is recommended to split the environment-specific values into separate YAML files if sensitive data is involved. The non-sensitive data can be stored in a plain text <code>values.yaml</code> file and passed to the <code>HelmRelease</code> as Kubernetes ConfigMaps generated with Kustomize <code>configMapGenerator</code>. Values like database passwords, API keys, etc. should be stored encrypted in Git using the Flux SOPS integration, and passed to the <code>HelmRelease</code> resources as Kubernetes Secrets generated with Kustomize <code>secretGenerator</code>.</p> <p>Example of a directory structure for managing environment-specific values:</p> <pre><code>my-java-apps/\n\u251c\u2500\u2500 base\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 namespace.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 oci-repository.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 app1-release.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 app2-release.yaml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 kustomization.yaml\n\u251c\u2500\u2500 production\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 app1\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 values.yaml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 values-secrets.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 app2\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 values.yaml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 values-secrets.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 kustomization.yaml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 kustomizeconfig.yaml\n\u2514\u2500\u2500 staging\n</code></pre> <p>In the <code>base</code> directory, the Flux resources are stored, such as the <code>OCIRepository</code> and <code>HelmRelease</code> YAML manifests. Passing values from ConfigMaps and Secrets to the <code>HelmRelease</code> resources can be done using the <code>.spec.valuesFrom</code> field, for example:</p> <pre><code>apiVersion: helm.toolkit.fluxcd.io/v2\nkind: HelmRelease\nmetadata:\n  name: my-java-app1\nspec:\n  valuesFrom:\n    - kind: ConfigMap\n      name: app1-values\n    - kind: Secret\n      name: app1-values-secrets\n</code></pre> <p>In the overlay directories, the environment-specific values are stored. The <code>kustomization.yaml</code> file in the overlay directory should reference the base directory and should generate the ConfigMaps and Secrets from the values files, for example:</p> <pre><code>apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nnamespace: my-java-apps\nresources:\n  - ../base\nconfigMapGenerator:\n  - name: app1-values\n    files:\n      - values.yaml=app1/values.yaml\nsecretGenerator:\n  - name: app1-values-secrets\n    files:\n      - values.yaml=app1/values-secrets.yaml\nconfigurations:\n  - kustomizeconfig.yaml\n</code></pre> <p>The <code>kustomizeconfig.yaml</code> tells Kustomize how to patch the <code>HelmRelease</code> resources with the generated ConfigMaps and Secrets by appending a unique hash to their names. This ensures that every time a values file changes, the <code>HelmRelease</code> resource is also updated, triggering a new app deployment.</p> <p>The <code>kustomizeconfig.yaml</code> file should look like this:</p> <pre><code>nameReference:\n  - kind: ConfigMap\n    version: v1\n    fieldSpecs:\n      - path: spec/valuesFrom/name\n        kind: HelmRelease\n  - kind: Secret\n    version: v1\n    fieldSpecs:\n      - path: spec/valuesFrom/name\n        kind: HelmRelease\n</code></pre> <p>To deploy the apps on the production cluster, the platform team would add a Flux Kustomization at <code>clusters/production/my-java-apps.yaml</code> with the following content:</p> <pre><code>apiVersion: kustomize.toolkit.fluxcd.io/v1\nkind: Kustomization\nmetadata:\n  name: my-java-apps\n  namespace: flux-system\nspec:\n  interval: 10m\n  timeout: 5m\n  prune: true\n  sourceRef:\n    kind: GitRepository\n    name: flux-system\n  path: my-java-apps/production\n  targetNamespace: my-java-apps\n</code></pre> <p>If the <code>values-secrets.yaml</code> files are encrypted with SOPS, the platform team should ensure that SOPS decryption is enabled in the Flux Kustomization. For more details on how to configure decryption, refer to the Flux Kustomization decryption documentation.</p>"},{"location":"guides/flux-generic-helm-chart/#passing-runtime-values-to-helm-releases","title":"Passing runtime values to Helm Releases","text":"<p>In some cases, teams might need to pass values known only at runtime to the <code>HelmRelease</code> resources. For example, an application might need to connect to a hosted service in the same region as the cluster.</p> <p>Assuming that the account ID and region are stored in a Kubernetes ConfigMap created by an IaC tool like Terraform when provisioning the cluster, for example:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: cluster-info\n  namespace: flux-system\ndata:\n  account_id: \"123456789012\"\n  cluster_region: \"us-west-2\"\n</code></pre> <p>The account ID and region values can be passed to the <code>HelmRelease</code> resources using the Flux variable substitution feature.</p> <p>In the <code>HelmRelease</code> manifests, the account ID and region values can be referenced using the <code>${account_id}</code> and <code>${cluster_region}</code> variables, for example:</p> <pre><code>apiVersion: helm.toolkit.fluxcd.io/v2\nkind: HelmRelease\nmetadata:\n  name: my-java-app1\nspec:\n  values:\n    database: \"mydb.${account_id}.${cluster_region}.rds.amazonaws.com\"\n</code></pre> <p>The platform team must ensure that the Flux Kustomization that deploys the <code>HelmRelease</code> resources has the <code>cluster-info</code> ConfigMap configured as a source of variables, for example:</p> <pre><code>apiVersion: kustomize.toolkit.fluxcd.io/v1\nkind: Kustomization\nmetadata:\n  name: my-java-apps\n  namespace: flux-system\nspec:\n  postBuild:\n    substituteFrom:\n      - kind: ConfigMap\n        name: cluster-info\n</code></pre>"},{"location":"guides/flux-generic-helm-chart/#deploying-helm-chart-pre-releases-on-staging","title":"Deploying Helm chart pre-releases on staging","text":"<p>To limit the blast radius of changes to the generic Helm chart, teams should consider deploying pre-release versions on staging clusters before promoting them to production.</p> <p>In the staging overlay directory, the <code>kustomization.yaml</code> file should contain a patch that overrides the <code>.spec.ref</code> field of the <code>OCIRepository</code> to match only pre-release versions:</p> <pre><code>apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nnamespace: my-java-apps\nresources:\n  - ../base\npatches:\n  - patch: | \n      - op: replace\n        path: /spec/ref\n        value:\n          semver: \"&gt;= 0.0.0-0\"\n          semverFilter: \".*-rc.*\"\n    target:\n      kind: OCIRepository\n</code></pre>"},{"location":"guides/flux-generic-helm-chart/#automating-app-image-updates","title":"Automating App Image Updates","text":"<p>One of the downsides of using a common Helm chart is that the application version is no longer specified in the Helm chart. When a new version of the application is released, to upgrade the Helm release, an update to the image tag in the <code>HelmRelease</code> values is required.</p> <p>To automate the application upgrades, teams should consider using the Flux Image Automation feature to automatically update the image tag in the <code>HelmRelease</code> YAML manifest stored in the Git repository.</p> <p>For Flux to update the application image tag, the <code>HelmRelease</code> manifests must be annotated with an image policy marker, for example:</p> <pre><code>apiVersion: helm.toolkit.fluxcd.io/v2\nkind: HelmRelease\nmetadata:\n  name: my-java-app1\nspec:\n  values:\n    image:\n      repository: my-registry.io/my-java-app1\n      tag: 1.0.0 # {\"$imagepolicy\": \"my-apps-automation:my-java-app1:tag\"}\n</code></pre> <p>When a new image tag is pushed to the container registry, Flux will automatically update the image tag by committing the change to the Git repository, which will trigger a new deployment of the application since the desired state has changed.</p> <p>For each application, an <code>ImageRepository</code> and <code>ImagePolicy</code> resources should be created to track the image tags. These resources can be created in a dedicated namespace used for image automation. In that namespace, besides the <code>ImageRepository</code> and <code>ImagePolicy</code> of each app, a single <code>ImageUpdateAutomation</code> and <code>GitRepository</code> resource should be created for Flux to commit the image tag updates to Git. Note that the token or SSH key used to access the Git repository should have write access.</p> <p>Note that the Flux Image Automation controllers don't need to be installed on production clusters. These controllers and the <code>ImageRepository</code>, <code>ImagePolicy</code>, <code>ImageUpdateAutomation</code> and <code>GitRepository</code> custom resources can be deployed on a management cluster used for automation purposes. One misconception is that the Flux Image Automation needs to run on the same cluster as the applications, but this is not the case. The role of these controllers is to scan the container registry for new image tags and update the Git repository, which can be done from a separate cluster regardless of where the applications are running.</p> <p>For more details on how to automate image updates to Git, refer to the Flux Image Automation documentation.</p>"},{"location":"guides/flux-generic-helm-chart/#conclusions","title":"Conclusions","text":"<p>In this guide, we've seen how the Generic Helm Chart pattern can be used in a GitOps workflow leveraging Flux's Helm and OCI Artifacts features. While this pattern can help standardize the continuous delivery process across multiple teams within large organizations, it's important to consider the complexity it introduces especially around ownership, versioning and the challenges of maintaining backward compatibility across multiple services.</p> <p>Adopting the Generic Helm Chart pattern can be beneficial for organizations that have a large number of microservices with similar deployment requirements. Applying this pattern to small organization  with a few services might introduce unnecessary complexity. In this case, teams should consider using dedicated Helm charts for each service and only share common configuration using Helm libraries. Having the Helm chart in the same repository as the application code, having a single version for both the chart and the application, and a unified release process, makes the continuous delivery process more straightforward and easier to manage.</p>"},{"location":"guides/flux-policies/","title":"Flux Multitenant Policies","text":"<p>In this guide we will cover how to use the Kubernetes built-in validating admission engine to enforce policies on multi-tenant clusters managed by Flux.</p>"},{"location":"guides/flux-policies/#kubernetes-validating-admission-policy","title":"Kubernetes Validating Admission Policy","text":"<p>Starting from Kubernetes 1.30, the Kubernetes API server comes with a built-in validating admission controller that allows defining custom policies using the Common Expression Language (CEL).</p> <p>In a GitOps setup, the Kubernetes <code>ValidatingAdmissionPolicy</code> and <code>ValidatingAdmissionPolicyBinding</code> resources are defined by cluster admins in the fleet repository. Using Flux <code>dependsOn</code> feature, the cluster admins can ensure that the policies are applied before any other resources are reconciled, thus enforcing the policies on all tenant's namespaces and workloads.</p>"},{"location":"guides/flux-policies/#restricting-access-to-flux-sources","title":"Restricting Access to Flux Sources","text":"<p>One common policy is to restrict the access to external Flux sources such as Git repositories, OCI registries and Helm repositories which are controlled by tenants.</p>"},{"location":"guides/flux-policies/#define-the-allow-list","title":"Define the Allow List","text":"<p>Assuming that cluster admins want to restrict the access to a specific GitHub organization, first, they need to define <code>ConfigMap</code> in the <code>flux-system</code> namespace with the list of allowed Flux sources:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: allowlist\n  namespace: flux-system\n  labels:\n    fluxcd.controlplane.io/role: \"policy\"\ndata:\n  sources: &gt;-\n    oci://ghcr.io/controlplaneio-fluxcd/charts/\n    https://github.com/controlplaneio-fluxcd/\n    ssh://git@github.com/controlplaneio-fluxcd/\n</code></pre> <p>The <code>sources</code> list contains the allowed URL prefixes separated by a new line for tenant-owned Flux sources e.g. <code>GitRepository</code>, <code>OCIRepository</code> and <code>HelmRepository</code>.</p>"},{"location":"guides/flux-policies/#define-the-admission-policy","title":"Define the Admission Policy","text":"<p>Next, the cluster admins need to define a <code>ValidatingAdmissionPolicy</code> resource that verifies the source URL against the allow list:</p> <pre><code>apiVersion: admissionregistration.k8s.io/v1\nkind: ValidatingAdmissionPolicy\nmetadata:\n  name: \"source.policy.fluxcd.controlplane.io\"\n  annotations:\n    policy.fluxcd.controlplane.io/role: |\n      Restrict Flux access to Git repositories, OCI registries and Helm repositories,\n      based on an allowlist defined in a ConfigMap stored in the flux-system namespace.\nspec:\n  failurePolicy: Fail\n  matchConstraints:\n    resourceRules:\n      - apiGroups: [ \"source.toolkit.fluxcd.io\" ]\n        apiVersions: [ \"*\" ]\n        operations: [ \"CREATE\", \"UPDATE\" ]\n        resources: [ \"gitrepositories\", \"ocirepositories\", \"helmrepositories\" ]\n  matchConditions:\n    - name: \"exclude-source-controller-finalizer\"\n      expression: &gt;\n        request.userInfo.username != \"system:serviceaccount:flux-system:source-controller\"\n  paramKind:\n    apiVersion: v1\n    kind: ConfigMap\n  variables:\n    - name: url\n      expression: object.spec.url\n    - name: sources\n      expression: params.data.sources.split(' ')\n  validations:\n    - expression: &gt;\n        variables.sources.exists_one(prefix, variables.url.startsWith(prefix))\n      messageExpression: &gt;\n        \"Source \" + variables.url + \" is not allowed, must be one of \" + variables.sources.join(\", \")\n      reason: Invalid\n</code></pre>"},{"location":"guides/flux-policies/#define-the-admission-policy-binding","title":"Define the Admission Policy Binding","text":"<p>Finally, the cluster admins need to define a <code>ValidatingAdmissionPolicyBinding</code> resource that binds the policy to all tenant namespaces and references the <code>ConfigMap</code> with the allow list:</p> <pre><code>apiVersion: admissionregistration.k8s.io/v1\nkind: ValidatingAdmissionPolicyBinding\nmetadata:\n  name: tenant-sources\nspec:\n  policyName: \"source.policy.fluxcd.controlplane.io\"\n  validationActions: [ \"Deny\" ]\n  paramRef:\n    name: allowlist\n    namespace: flux-system\n    parameterNotFoundAction: \"Deny\"\n  matchResources:\n    namespaceSelector:\n      matchExpressions:\n        - key: kubernetes.io/metadata.name\n          operator: NotIn\n          values:\n            - flux-system\n            - kube-system\n</code></pre> <p>With the above policy in place, any tenant trying to create or update a Flux source that is not listed in the allow list will receive a validation error and the operation will be denied.</p>"},{"location":"guides/flux-policies/#applying-the-policies","title":"Applying the Policies","text":"<p>The cluster admins can apply the policies using a dedicated Flux <code>Kustomization</code> that gets reconciled before the tenant's resources.</p> <p>Repository structure:</p> <pre><code>\u251c\u2500\u2500 clusters\n\u2502   \u2514\u2500\u2500 production\n\u2502       \u251c\u2500\u2500 policies-sync.yaml\n\u2502       \u2514\u2500\u2500 tenants-sync.yaml\n\u251c\u2500\u2500 policies\n\u2502   \u251c\u2500\u2500 allowlist.yaml\n\u2502   \u2514\u2500\u2500 policies.yaml\n\u2514\u2500\u2500 tenants\n    \u251c\u2500\u2500 team1\n    \u2514\u2500\u2500 team2\n</code></pre> <p>The <code>policies-sync.yaml</code> manifest configures Flux to reconcile the policies resources first:</p> <pre><code>apiVersion: kustomize.toolkit.fluxcd.io/v1\nkind: Kustomization\nmetadata:\n  name: policies\n  namespace: flux-system\nspec:\n  path: \"./policies\"\n  prune: true\n  wait: true\n</code></pre> <p>The <code>tenants-sync.yaml</code> manifest configures Flux to reconcile the tenants resources after the policies:</p> <pre><code>apiVersion: kustomize.toolkit.fluxcd.io/v1\nkind: Kustomization\nmetadata:\n  name: tenants\n  namespace: flux-system\nspec:\n  dependsOn:\n    - name: policies\n  path: \"./tenants\"\n  prune: true\n</code></pre>"},{"location":"guides/flux-policies/#testing-the-policy","title":"Testing the Policy","text":"<p>If a tenant adds an <code>HelmRepository</code> manifest to their repository that tries to pull Helm charts from a registry that is not in the allow list, for example:</p> <pre><code>apiVersion: source.toolkit.fluxcd.io/v1\nkind: HelmRepository\nmetadata:\n  name: podinfo\n  namespace: apps\nspec:\n  type: oci\n  url: oci://ghcr.io/stefanprodan/charts/\n</code></pre> <p>The admission controller will deny the creation of the <code>HelmRepository</code> and the tenant will receive an alert from Flux about the policy violation:</p> <pre><code>The helmrepository \"podinfo\" is invalid:\nValidatingAdmissionPolicy 'source.policy.fluxcd.controlplane.io' with binding 'tenant-sources' denied request:\nSource oci://ghcr.io/stefanprodan/charts/ is not allowed, must be one of oci://ghcr.io/controlplaneio-fluxcd/charts/, https://github.com/controlplaneio-fluxcd/, ssh://git@github.com/controlplaneio-fluxcd/\n</code></pre>"},{"location":"guides/flux-policies/#restricting-access-to-container-registries","title":"Restricting Access to Container Registries","text":"<p>Another common policy is to restrict the access to container registries for workloads running in tenant namespaces.</p> <p>Assuming that cluster admins want to restrict the access to specific container registries, they can add the allowed registry prefixes to the <code>ConfigMap</code> in the <code>flux-system</code> namespace:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: allowlist\n  namespace: flux-system\n  labels:\n    fluxcd.controlplane.io/role: \"policy\"\ndata:\n  registries: &gt;-\n    ghcr.io/controlplaneio-fluxcd/\n    709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/\n  sources: &gt;-\n    omitted for brevity\n</code></pre> <p>Next, the cluster admins need to define a <code>ValidatingAdmissionPolicy</code> resource that verifies the containers image URL against the allow list:</p> <pre><code>apiVersion: admissionregistration.k8s.io/v1\nkind: ValidatingAdmissionPolicy\nmetadata:\n  name: \"registry.policy.fluxcd.controlplane.io\"\nspec:\n  failurePolicy: Fail\n  matchConstraints:\n    resourceRules:\n      - apiGroups: [ \"apps\" ]\n        apiVersions: [ \"v1\" ]\n        operations: [ \"CREATE\", \"UPDATE\" ]\n        resources: [ \"deployments\", \"statefulsets\", \"daemonsets\" ]\n  paramKind:\n    apiVersion: v1\n    kind: ConfigMap\n  variables:\n    - name: registries\n      expression: params.data.registries.split(' ')\n  validations:\n    - expression: &gt;\n        object.spec.template.spec.containers.all(\n          container,\n          variables.registries.exists(\n              prefix, container.image.startsWith(prefix)\n          )\n        )\n      messageExpression: &gt;\n        \"Container image is not allowed, must be one of \" + variables.registries.join(\", \")\n      reason: Invalid\n    - expression: &gt;\n        !has(object.spec.template.spec.initContainers) ||\n        object.spec.template.spec.initContainers.all(\n          container,\n          variables.registries.exists(\n              prefix, container.image.startsWith(prefix)\n          )\n        )\n      messageExpression: &gt;\n        \"Init container image is not allowed, must be one of \" + variables.registries.join(\", \")\n      reason: Invalid\n</code></pre> <p>Finally, the cluster admins need to define a <code>ValidatingAdmissionPolicyBinding</code> resource that binds the policy to all tenant namespaces and references the <code>ConfigMap</code> with the allow list:</p> <pre><code>apiVersion: admissionregistration.k8s.io/v1\nkind: ValidatingAdmissionPolicyBinding\nmetadata:\n  name: tenant-registries\nspec:\n  policyName: \"registry.policy.fluxcd.controlplane.io\"\n  validationActions: [ \"Deny\" ]\n  paramRef:\n    name: allowlist\n    namespace: flux-system\n    parameterNotFoundAction: \"Deny\"\n  matchResources:\n    namespaceSelector:\n      matchExpressions:\n        - key: kubernetes.io/metadata.name\n          operator: NotIn\n          values:\n            - flux-system\n            - kube-system\n</code></pre> <p>With the above policy in place, any tenant trying to create or update a workload that uses a container image from a registry that is not listed in the allow list will receive a validation error and the operation will be denied.</p> <pre><code>The deployments \"test-deployment\" is invalid:\nValidatingAdmissionPolicy 'registry.policy.fluxcd.controlplane.io' with binding 'tenant-registries' denied request:\nInit container image is not allowed, must be one of ghcr.io/controlplaneio-fluxcd/, 709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/\n</code></pre>"},{"location":"guides/flux-policies/#conclusions","title":"Conclusions","text":"<p>In this guide we've shown how to use the Kubernetes native validating admission policies to enforce policies on multi-tenant clusters managed by Flux. Extending the examples above, cluster admins can define policies to enforce best practices, security and compliance requirements across all tenant namespaces and workloads.</p> <p>The new Kubernetes validating admission policies offer an alternative to admission webhooks such as OPA Gatekeeper or Kyverno. Admission webhooks are single points of failure and can introduce latency in the API server response time, blocking or slowing down the reconciliation of the cluster state performed by Flux. Using the built-in policy engine, eliminates the maintenance overhead of running and managing custom admission webhooks and makes policy enforcement more reliable and efficient.</p>"},{"location":"marketplace/aws/","title":"Deploy Flux from AWS Marketplace","text":"<p>AWS users can deploy the ControlPlane Enterprise Distribution of Flux CD on Amazon EKS from the AWS Marketplace. </p> <p> </p>"},{"location":"marketplace/aws/#prerequisites","title":"Prerequisites","text":"<p>After subscribing to the ControlPlane product, deploy the Flux Operator on your EKS cluster using the Helm chart provided in the AWS Marketplace.</p>"},{"location":"marketplace/aws/#iam-permissions","title":"IAM Permissions","text":"<p>First you need to grant the <code>flux-operator</code> service account from the <code>flux-system</code> namespace the necessary permissions to access the AWS Marketplace metering API. You can use the AWS managed policy <code>arn:aws:iam::aws:policy/AWSMarketplaceMeteringRegisterUsage</code> for this purpose.</p> <p>Example using <code>eksctl</code> with IAM Roles for Service Accounts:</p> <pre><code>eksctl create iamserviceaccount --cluster=&lt;clusterName&gt; \\\n  --name=flux-operator \\\n  --namespace=flux-system \\\n  --attach-policy-arn=arn:aws:iam::aws:policy/AWSMarketplaceMeteringRegisterUsage \\\n  --approve\n</code></pre>"},{"location":"marketplace/aws/#helm-chart-installation","title":"Helm Chart Installation","text":"<p>Deploy the <code>flux-operator</code> Helm chart on your EKS cluster in the <code>flux-system</code> namespace using the following values:</p> <pre><code>helm upgrade -i flux-operator oci://ghcr.io/controlplaneio-fluxcd/charts/flux-operator \\\n  --namespace flux-system \\\n  --set serviceAccount.create=false \\\n  --set image.repository=709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/flux-operator \\\n  --set marketplace.type=aws\n</code></pre>"},{"location":"marketplace/aws/#entitlements-verification","title":"Entitlements Verification","text":"<p>To verify that the AWS Marketplace entitlements are valid, check the report generated in the <code>flux-system</code> namespace:</p> <pre><code>$ kubectl -n flux-system get fluxreport/flux -o wide\nNAME   ENTITLEMENT                  AGE   READY   STATUS\nflux   Issued by controlplane-aws   1m    True    Reporting finished in 34ms\n</code></pre>"},{"location":"marketplace/aws/#flux-installation-options","title":"Flux Installation Options","text":"<ul> <li> Flux Bootstrap</li> <li> Flux Operator</li> </ul>"},{"location":"marketplace/aws/#flux-bootstrap","title":"Flux Bootstrap","text":"<p>Customers can bootstrap Flux with the enterprise distribution using the Flux CLI or the Flux Terraform provider. To access the ControlPlane images from the AWS Marketplace<sup>1</sup>, use the following registry URL:</p> <pre><code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd\n</code></pre> <p>Example of Flux CLI bootstrap with the FIPS-compliant images hosted on AWS ECR:</p> <pre><code>flux bootstrap github \\\n  --owner=customer-org \\\n  --repository=customer-repo \\\n  --branch=main \\\n  --path=clusters/production \\\n  --registry=709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd\n</code></pre> <p>Example of Flux Terraform Provider bootstrap:</p> <pre><code>resource \"flux_bootstrap_git\" \"this\" {\n  embedded_manifests   = true\n  path                 = \"clusters/my-cluster\"\n  registry             = \"709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd\"\n}\n</code></pre> <p>Running the bootstrap command for a cluster with an existing Flux installation will trigger an in-place upgrade of the Flux controllers to the ControlPlane distribution.</p>"},{"location":"marketplace/aws/#flux-operator","title":"Flux Operator","text":"<p>To deploy the enterprise distribution with Flux Operator from the AWS Marketplace, create a <code>FluxInstance</code> resource named <code>flux</code> in the <code>flux-system</code> namespace with the following configuration:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\nspec:\n  distribution:\n    version: \"2.7.x\"\n    registry: \"709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd\"\n  cluster:\n    type: aws\n    multitenant: false\n    networkPolicy: true\n    domain: \"cluster.local\"\n</code></pre> <p>Apply the manifest with <code>kubectl</code>:</p> <pre><code>kubectl apply -f flux-instance.yaml\n</code></pre> <p>On EKS clusters with access to GitHub Container Registry, the operator can check for updates and automatically update the Flux controllers to the latest patch version without having to  upgrade the Flux Operator Helm chart from the AWS Marketplace.</p> <p>To enable the automatic upgrade feature, configure the Flux instance as follows:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\n  annotations:\n    fluxcd.controlplane.io/reconcileEvery: \"1h\"\n    fluxcd.controlplane.io/reconcileTimeout: \"5m\"\nspec:\n  distribution:\n    version: \"2.4.x\"\n    registry: \"709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd\"\n    artifact: \"oci://ghcr.io/controlplaneio-fluxcd/flux-operator-manifests\"\n  cluster:\n    type: aws\n    multitenant: false\n    networkPolicy: true\n    domain: \"cluster.local\"\n</code></pre> <p>For more information, see the Flux Operator documentation.</p> <ol> <li> <p>AWS Marketplace and the AWS Marketplace logo are trademarks of Amazon.com, Inc. or its affiliates.\u00a0\u21a9</p> </li> </ol>"},{"location":"mcp/","title":"Flux MCP Server Introduction","text":"<p>The Flux Model Context Protocol (MCP) Server connects AI assistants like Claude, Cursor, GitHub Copilot, and others directly to your Kubernetes clusters running Flux Operator, enabling seamless interaction through natural language. It serves as a bridge between AI tools and your GitOps pipelines, allowing you to analyze the cluster state, troubleshoot deployment issues, and perform operations using conversational prompts.</p> <p>Experimental Feature</p> <p>Please note that the Flux MCP Server is an experimental feature provided as-is without warranty or support guarantees. Enterprise customers should use this feature at their own discretion.</p>"},{"location":"mcp/#features","title":"Features","text":"<ul> <li> <p> Cluster State Analysis</p> <p>Quickly understand your Flux installation status, resource configurations, and deployment histories across environments.</p> </li> <li> <p> Cross-Cluster Comparisons</p> <p>Compare Flux configurations for applications and infrastructure between development, staging, and production.</p> </li> <li> <p> Enhanced On-Call Experience</p> <p>Reduce mean time to resolution (MTTR) during incidents with contextual analysis and actionable remediation steps.</p> </li> <li> <p> Root Cause Analysis</p> <p>Automatically correlate events, logs, and configuration changes to identify the source of failures in a GitOps pipeline.</p> </li> <li> <p> GitOps Automation</p> <p>Trigger reconciliations, suspend/resume Flux resources, and manage your delivery pipelines with simple requests.</p> </li> <li> <p> Visual GitOps Pipelines</p> <p>Generate diagrams that map out Flux dependencies, resource relationships, and delivery workflows across clusters.</p> </li> </ul>"},{"location":"mcp/#how-it-works","title":"How It Works","text":"<p>The Flux MCP Server integrates with AI assistants through the Model Context Protocol, providing them with purpose-built tools to interact with your clusters. When you ask a question or make a request, the AI uses these tools to gather information, analyze configurations, and perform operations based on your instructions.</p> <p></p> <p>The AI assistants leveraging the Flux MCP Server can trace issues from high-level GitOps resources like ResourceSets, HelmReleases, and Kustomizations all the way down to individual pod logs. This comprehensive visibility means you can quickly identify where problems originate in your delivery pipeline \u2013 whether in Helm chart values, Kubernetes manifests, Flux configurations, or application runtime issues.</p> <p>AI Instructions</p> <p>For the best experience, we recommend configuring your AI assistants with custom instructions that guide them on how to interact with Kubernetes and the Flux MCP Server.</p>"},{"location":"mcp/#security-considerations","title":"Security Considerations","text":"<p>The Flux MCP Server is designed with security in mind:</p> <ul> <li>Operates with your existing kubeconfig permissions</li> <li>Supports service account impersonation for limited access</li> <li>Masks sensitive information in Kubernetes Secret values</li> <li>Provides a Kubernetes read-only mode for observation without affecting the cluster state</li> <li>Access to the local file system is read-only and restricted to the kubeconfig file</li> </ul> <p>For a detailed overview of configuring the Flux MCP Server, including security settings, see the Configuration Guide.</p>"},{"location":"mcp/#license","title":"License","text":"<p>The MCP Server is open-source and part of the Flux Operator project licensed under the AGPL-3.0 license.</p>"},{"location":"mcp/config-api/","title":"Flux MCP Server Config API","text":"<p>This document describes a declarative API for configuring a subset of features of the Flux MCP Server.</p>"},{"location":"mcp/config-api/#overview","title":"Overview","text":"<p>The <code>Config</code> API supports:</p> <ul> <li>MCP Transport Modes - How the MCP server receives and sends messages<ul> <li>Streamable HTTP - HTTP transport with support for streaming responses and authentication</li> <li>Standard Input/Output (stdio) - Simple transport using standard input and output streams</li> </ul> </li> <li>Authentication - Secure access control for MCP server operations when running with Streamable HTTP<ul> <li>Credentials - How credentials are extracted from incoming requests</li> <li>Providers - How extracted credentials are validated and converted to user sessions</li> </ul> </li> </ul> <p>A YAML configuration file defines the features and settings to be used by the MCP server. This file must be specified with <code>--config=&lt;path to file&gt;</code> when starting the MCP server. If this flag is not specified, the MCP server will start with default settings.</p> <p>The legacy <code>sse</code> transport mode can only be specified using the <code>--transport=sse</code> flag.</p> <p>Example:</p> <pre><code># /etc/flux-mcp/config.yaml\napiVersion: mcp.fluxcd.controlplane.io/v1\nkind: Config\nspec:\n  transport: http # or stdio\n  authentication:\n    credentials:\n      - type: BearerToken\n    providers:\n      - name: external\n        type: OIDC\n        issuerURL: \"https://auth.example.com\"\n        audience: \"https://flux-mcp.example.com\"\n        impersonation:\n          username: \"claims.sub\"\n        scopes:\n          expression: \"claims.scopes\"\n</code></pre> <pre><code>flux-operator-mcp serve --config=/etc/flux-mcp/config.yaml\n</code></pre>"},{"location":"mcp/config-api/#config-api","title":"Config API","text":"<pre><code>apiVersion: mcp.fluxcd.controlplane.io/v1\nkind: Config\nspec:\n\n  # Transport mode for MCP communication. Supported values: \"http\", \"stdio\". Default: \"stdio\"\n  transport: http\n\n  # If true, the MCP server will operate in read-only mode. The MCP server will run in read-only\n  # mode if at least one between this field or the CLI flag --read-only is set to true.\n  readonly: false # Optional, default is false.\n\n  # Authentication configuration (optional)\n  authentication:\n\n    # Methods for extracting credentials. At least one method must be defined.\n    credentials:\n      - type: BearerToken\n      - type: BasicAuth\n      - type: CustomHTTPHeader\n        headers:\n          token: \"X-Auth-Token\"\n\n    # Authentication providers. At least one provider must be defined.\n    providers:\n      - name: external\n        type: OIDC\n        issuerURL: \"https://auth.example.com\"\n        audience: \"https://flux-mcp.example.com\"\n</code></pre>"},{"location":"mcp/config-api/#authentication","title":"Authentication","text":"<p>Authentication is only supported in the Streamable HTTP MCP transport mode. When authentication is configured, it provides secure access control with support for multiple credential extraction methods and multiple authentication providers.</p>"},{"location":"mcp/config-api/#credentials","title":"Credentials","text":"<p>The field <code>spec.authentication.credentials</code> defines how credentials are extracted from incoming HTTP requests. The first credential that successfully extracts the information from a request is used.</p>"},{"location":"mcp/config-api/#bearertoken","title":"BearerToken","text":"<p>Extracts a token from the <code>Authorization: Bearer &lt;token&gt;</code> header.</p> <pre><code>spec:\n  authentication:\n    credentials:\n      - type: BearerToken\n</code></pre>"},{"location":"mcp/config-api/#basicauth","title":"BasicAuth","text":"<p>Extracts username and password from the <code>Authorization: Basic base64(&lt;username&gt;+\":\"+&lt;password&gt;)</code> header.</p> <pre><code>spec:\n  authentication:\n    credentials:\n      - type: BasicAuth\n</code></pre>"},{"location":"mcp/config-api/#customhttpheader","title":"CustomHTTPHeader","text":"<p>Extracts credentials from custom HTTP headers.</p> <pre><code>spec:\n  authentication:\n    credentials:\n      - type: CustomHTTPHeader\n        headers:\n          username: \"X-Username\" # Header containing username (optional)\n          password: \"X-Password\" # Header containing password (optional)\n          token: \"X-Auth-Token\"  # Header containing token (optional)\n</code></pre>"},{"location":"mcp/config-api/#providers","title":"Providers","text":"<p>Authentication providers validate extracted credentials and extract user information from these credentials to create a user session. Multiple providers can be configured under <code>spec.authentication.providers</code> to support different authentication systems. The first provider that successfully validates the extracted credentials and successfully extracts a user session is used.</p> <p>A user session consists of a username, a list of groups, and a list of scopes.</p> <p>The username and groups in a user session are used for Kubernetes impersonation. RBAC permissions are expected to be properly granted to this username and groups separately, the MCP server is not responsible for managing these permissions.</p>"},{"location":"mcp/config-api/#oidc-provider","title":"OIDC Provider","text":"<p>The OIDC provider validates JSON Web Tokens (JWT) against an OpenID Connect provider. An HTTP call is made to the provider's <code>/.well-known/openid-configuration</code> endpoint to fetch the provider's public keys and other metadata. The public keys are used to validate the token's signature. If the signature is valid, and the standard claims (<code>iss</code>, <code>aud</code>, <code>exp</code>, etc.) are valid, the token is considered valid.</p> <p>If a token is considered valid, the provider proceeds to extract the user session information from the token's claims, and then finally to validate custom properties defined in the configuration. The extraction and validation rules are defined using Common Expression Language (CEL) expressions. A map with the claims of the JWT is passed to the CEL expressions. References for writing CEL expressions:</p> <ul> <li>CEL Language Reference</li> <li>CEL Playground</li> </ul> <p>Multiple OIDC providers can be defined to support multiple OIDC providers.</p> <p>Each OIDC provider under <code>spec.authentication.providers</code> supports the following configuration:</p> <pre><code>spec:\n  authentication:\n    providers:\n      - # Required fields\n        name: external                                      # Provider name (must be unique)\n        type: OIDC                                          # Provider type\n        issuerURL: \"https://auth.example.com\"               # OIDC issuer URL for fetching public keys\n        audience: \"https://flux-mcp.example.com\"            # Expected \"aud\" claim in the JWT\n\n        # Optional fields\n        variables:                                          # Named variables for reuse in other expressions\n          - name: username\n            expression: \"claims.sub\"\n          - name: domain\n            expression: \"claims.email.split('@')[1]\"\n        validations:                                        # Custom claim and variables validations\n          - expression: \"variables.domain == 'example.com'\" # CEL expression returning bool\n            message: \"email domain not allowed\"\n        impersonation:                                      # Kubernetes impersonation configuration\n          username: \"variables.username\"                    # CEL expression returning string\n          groups: \"claims.groups\"                           # CEL expression returning []string\n        scopes:                                             # Scopes extraction\n          expression: \"claims.scopes\"                       # CEL expression returning []string\n</code></pre>"},{"location":"mcp/config-api/#scopes","title":"Scopes","text":"<p>Scopes provide fine-grained access control for MCP operations. When configured, the scopes extracted from authentication credentials are used by the MCP tools to limit access to certain operations.</p> <p>The scopes in a user session are used by the MCP tools individually to limit access to certain operations. Even though a user or group may have RBAC permissions to perform an operation in the Kubernetes cluster, the MCP tools will deny the operation if the required scope is not present in the user session. The opposite is not true, i.e. having the required scope does not guarantee that the operation will be allowed by Kubernetes RBAC.</p> <p>The scopes required by each MCP tool are documented in the tools reference.</p>"},{"location":"mcp/config-api/#configuration-examples","title":"Configuration Examples","text":""},{"location":"mcp/config-api/#basic-oidc-authentication","title":"Basic OIDC Authentication","text":"<pre><code>apiVersion: mcp.fluxcd.controlplane.io/v1\nkind: Config\nspec:\n  transport: http\n  authentication:\n    credentials:\n      - type: BearerToken\n    providers:\n      - name: external\n        type: OIDC\n        issuerURL: \"https://auth.example.com\"\n        audience: \"https://flux-mcp.example.com\"\n</code></pre>"},{"location":"mcp/config-api/#advanced-oidc-with-variables-and-validations","title":"Advanced OIDC with Variables and Validations","text":"<pre><code>apiVersion: mcp.fluxcd.controlplane.io/v1\nkind: Config\nspec:\n  transport: http\n  authentication:\n    credentials:\n      - type: BearerToken\n      - type: BasicAuth\n    providers:\n      - name: external\n        type: OIDC\n        issuerURL: \"https://auth.example.com\"\n        audience: \"https://flux-mcp.example.com\"\n        variables:\n          - name: email\n            expression: \"claims.email\"\n          - name: department\n            expression: \"claims.department\"\n        validations:\n          - expression: \"variables.email.endsWith('@example.com')\"\n            message: \"Only example.com emails allowed\"\n          - expression: \"variables.department in ['engineering', 'devops']\"\n            message: \"Access restricted to engineering and devops\"\n        impersonation:\n          username: \"claims.preferred_username\"\n          groups: \"claims.groups + ['authenticated']\"\n        scopes:\n          expression: \"claims.scopes\"\n</code></pre>"},{"location":"mcp/config-api/#oidc-with-variable-referencing","title":"OIDC with Variable Referencing","text":"<p>This example demonstrates how variables can reference previously declared variables, enabling complex data transformations and validations:</p> <pre><code>apiVersion: mcp.fluxcd.controlplane.io/v1\nkind: Config\nspec:\n  transport: http\n  authentication:\n    credentials:\n      - type: BearerToken\n    providers:\n      - name: external\n        type: OIDC\n        issuerURL: \"https://auth.example.com\"\n        audience: \"https://flux-mcp.example.com\"\n        variables:\n          - name: email\n            expression: \"claims.email\"                  # Extract email from claims\n          - name: domain\n            expression: \"variables.email.split('@')[1]\" # Extract domain from email variable\n          - name: normalized_domain\n            expression: \"variables.domain.lowerAscii()\" # Normalize domain using previous variable\n          - name: username_prefix\n            expression: \"variables.email.split('@')[0]\" # Extract username part from email\n        validations:\n          - expression: \"variables.normalized_domain in ['example.com', 'corp.example.com']\"\n            message: \"Email domain not allowed\"\n          - expression: \"size(variables.username_prefix) &gt;= 3\"\n            message: \"Username must be at least 3 characters\"\n        impersonation:\n          username: \"variables.email\"\n          groups: \"['users', 'domain:' + variables.normalized_domain]\"\n        scopes:\n          expression: \"['read', 'write:' + variables.normalized_domain]\"\n</code></pre>"},{"location":"mcp/config/","title":"Flux MCP Server Configuration","text":"<p>This document covers the configuration options for the Flux Model Context Protocol (MCP) Server, including transport modes, security settings, and how to restrict access to your clusters.</p>"},{"location":"mcp/config/#configuration-options","title":"Configuration Options","text":"<p>The <code>flux-operator-mcp serve</code> command accepts the following flags:</p> Flag Description Default <code>--transport</code> The transport protocol (stdio, sse or http) stdio <code>--port</code> The port to listen on (for sse or http) 8080 <code>--read-only</code> Run in read-only mode false <code>--mask-secrets</code> Mask secret values true <code>--kube-as</code> Kubernetes account to impersonate none"},{"location":"mcp/config/#transport-modes","title":"Transport Modes","text":""},{"location":"mcp/config/#standard-inputoutput-stdio","title":"Standard Input/Output (<code>stdio</code>)","text":"<p>The MCP Server uses standard input/output (stdio) by default, which is compatible with most AI assistants.</p> <p>To start the server in this mode, use the following configuration:</p> <pre><code>{\n  \"flux-operator-mcp\":{\n    \"command\":\"/path/to/flux-operator-mcp\",\n    \"args\":[\"serve\"],\n    \"env\":{\n      \"KUBECONFIG\":\"/path/to/.kube/config\"\n    }\n  }\n}\n</code></pre>"},{"location":"mcp/config/#streamable-http-http","title":"Streamable HTTP (<code>http</code>)","text":"<p>Web-based transport that allows the server to push updates to the client.</p> <p>To use Streamable HTTP (<code>http</code>), start the server with:</p> <pre><code>export KUBECONFIG=$HOME/.kube/config\nflux-operator-mcp serve --transport http --port 8080\n</code></pre> <p>To connect to the server from VS Code, use the following configuration:</p> <pre><code>{\n  \"mcp\": {\n    \"servers\": {\n      \"flux-operator-mcp\": {\n        \"type\": \"http\",\n        \"url\": \"http://localhost:8080/mcp\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"mcp/config/#server-sent-events-sse","title":"Server-Sent Events (<code>sse</code>)","text":"<p>Web-based transport that allows the server to push updates to the client, now considered legacy by the MCP specification, and superseded by Streamable HTTP.</p> <p>To use Server-Sent Events (<code>sse</code>), start the server with:</p> <pre><code>export KUBECONFIG=$HOME/.kube/config\nflux-operator-mcp serve --transport sse --port 8080\n</code></pre> <p>To connect to the server from VS Code, use the following configuration:</p> <pre><code>{\n  \"mcp\": {\n    \"servers\": {\n      \"flux-operator-mcp\": {\n        \"type\": \"sse\",\n        \"url\": \"http://localhost:8080/sse\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"mcp/config/#security-options","title":"Security Options","text":""},{"location":"mcp/config/#read-only-mode","title":"Read-only Mode","text":"<p>In production environments, you can run the server in read-only mode to prevent any modifications to your clusters:</p> <pre><code>{\n  \"flux-operator-mcp\":{\n    \"command\":\"/path/to/flux-operator-mcp\",\n    \"args\":[\n      \"serve\",\n      \"--read-only\"\n    ],\n    \"env\":{\n      \"KUBECONFIG\":\"/path/to/.kube/config\"\n    }\n  }\n}\n</code></pre> <p>Warning</p> <p>In read-only mode, the MCP tools that modify the cluster state (reconcile, suspend, resume, apply, delete) are disabled.</p>"},{"location":"mcp/config/#secret-masking","title":"Secret Masking","text":"<p>By default, the server masks sensitive values in Kubernetes Secrets. You can disable this if needed:</p> <pre><code>{\n  \"flux-operator-mcp\":{\n    \"command\":\"/path/to/flux-operator-mcp\",\n    \"args\":[\n      \"serve\",\n      \"--mask-secrets=false\"\n    ],\n    \"env\":{\n      \"KUBECONFIG\":\"/path/to/.kube/config\"\n    }\n  }\n}\n</code></pre> <p>Warning</p> <p>Disabling secret masking will expose sensitive information to the AI assistant and potentially to its training data. Only disable this in controlled environments when using self-hosted models.</p>"},{"location":"mcp/config/#service-account-impersonation","title":"Service Account Impersonation","text":"<p>For tighter security control, you can configure the server to impersonate a specific service account:</p> <pre><code>{\n  \"flux-operator-mcp\":{\n    \"command\":\"/path/to/flux-operator-mcp\",\n    \"args\":[\n      \"serve\",\n      \"--kube-as=system:serviceaccount:my-namespace:my-service-account\"\n    ],\n    \"env\":{\n      \"KUBECONFIG\":\"/path/to/.kube/config\"\n    }\n  }\n}\n</code></pre> <p>This limits the server's permissions to those granted to the specified service account. Note that your user set in the kubeconfig must have permission to impersonate service accounts.</p>"},{"location":"mcp/config/#deploy-on-kubernetes","title":"Deploy on Kubernetes","text":"<p>To deploy the Flux MCP Server in a Kubernetes cluster, you can create a ResourceSet with the following configuration:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSet\nmetadata:\n  name: flux-operator-mcp\n  namespace: flux-system\nspec:\n  inputs:\n    - readonly: false\n      accessFrom: flux-system\n  resources:\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: OCIRepository\n      metadata:\n        name: &lt;&lt; inputs.provider.name &gt;&gt;\n        namespace: &lt;&lt; inputs.provider.namespace &gt;&gt;\n      spec:\n        interval: 60m\n        url: oci://ghcr.io/controlplaneio-fluxcd/charts/flux-operator-mcp\n        layerSelector:\n          mediaType: \"application/vnd.cncf.helm.chart.content.v1.tar+gzip\"\n          operation: copy\n        ref:\n          semver: \"*\"\n    - apiVersion: helm.toolkit.fluxcd.io/v2\n      kind: HelmRelease\n      metadata:\n        name: &lt;&lt; inputs.provider.name &gt;&gt;\n        namespace: &lt;&lt; inputs.provider.namespace &gt;&gt;\n      spec:\n        serviceAccountName: flux-operator\n        chartRef:\n          kind: OCIRepository\n          name: &lt;&lt; inputs.provider.name &gt;&gt;\n        interval: 30m\n        values:\n          transport: http # defaults to the legacy 'sse' transport\n          readonly: &lt;&lt; inputs.readonly &gt;&gt;\n          networkPolicy:\n            ingress:\n              namespaces: [&lt;&lt; inputs.accessFrom &gt;&gt;]\n</code></pre> <p>See the full docs and values API for the Helm chart here.</p> <p>This ResourceSet will create a Kubernetes Deployment for the Flux MCP Server with <code>cluster-admin</code> permissions. It is recommended to set the <code>readonly</code> input to <code>true</code> in production environments to prevent modifications to the cluster state.</p> <p>The server is exposed via a Kubernetes Service named <code>flux-operator-mcp</code> in the <code>flux-system</code> namespace, listening on port <code>9090</code>. If the MCP client is running in-cluster, the <code>accessFrom</code> input should be set to the name of the namespace where the MCP client is deployed.</p> <p>To connect to the server, start port forwarding with:</p> <pre><code>kubectl port-forward -n flux-system svc/flux-operator-mcp 9090:9090\n</code></pre> <p>Then, in your VS Code settings, add:</p> <pre><code>{\n  \"mcp\": {\n    \"servers\": {\n      \"flux-operator-mcp\": {\n        \"type\": \"http\",\n        \"url\": \"http://localhost:9090/mcp\"\n      }\n    }\n  }\n}\n</code></pre> <p>For the legacy <code>sse</code> transport, add:</p> <pre><code>{\n  \"mcp\": {\n    \"servers\": {\n      \"flux-operator-mcp\": {\n        \"type\": \"sse\",\n        \"url\": \"http://localhost:9090/sse\"\n      }\n    }\n  }\n}\n</code></pre> <p>Warning</p> <p>Note that when running in-cluster, the kubeconfig context switching tools are disabled, so comparing deployments across clusters is not possible.</p>"},{"location":"mcp/install/","title":"Flux MCP Server Installation","text":"<p>This guide walks you through installing, configuring, and using the Flux MCP Server with various AI assistants.</p>"},{"location":"mcp/install/#prerequisites","title":"Prerequisites","text":"<p>Before installing the Flux MCP Server, ensure you have:</p> <ul> <li>A Kubernetes cluster with Flux Operator installed</li> <li>A valid kubeconfig file to access the clusters</li> <li>Appropriate permissions to view Flux resources</li> </ul>"},{"location":"mcp/install/#installation-options","title":"Installation Options","text":""},{"location":"mcp/install/#install-with-homebrew","title":"Install with Homebrew","text":"<p>If you are using macOS or Linux, you can install the Flux MCP Server using Homebrew:</p> <pre><code>brew install controlplaneio-fluxcd/tap/flux-operator-mcp\n</code></pre>"},{"location":"mcp/install/#download-pre-built-binaries","title":"Download Pre-built Binaries","text":"<p>The Flux MCP Server is available as a binary executable for Linux, macOS, and Windows. The <code>flux-operator-mcp</code> AMD64 and ARM64 binaries can be downloaded from GitHub releases page.</p> <p>After downloading the <code>flux-operator-mcp</code> archive for your platform and architecture, unpack it and place the binary in a directory included in your system's <code>PATH</code>.</p>"},{"location":"mcp/install/#build-from-source","title":"Build from Source","text":"<p>If you prefer to build from source, clone the repository and build the binary using <code>make</code> (requires Go 1.24+):</p> <pre><code>git clone https://github.com/controlplaneio-fluxcd/flux-operator.git\ncd flux-operator\nmake mcp-build\n</code></pre> <p>The <code>flux-operator-mcp</code> binary will be available in the <code>bin</code> directory relative to the repository root.</p>"},{"location":"mcp/install/#configuration-with-ai-assistants","title":"Configuration with AI Assistants","text":"<p>The Flux MCP Server is compatible with AI assistants that support the Model Context Protocol (MCP) using any of the following transport modes:</p> <ul> <li>Standard Input/Output (<code>stdio</code>)</li> <li>Server-Sent Events (<code>sse</code>)</li> <li>Streamable HTTP (<code>http</code>)</li> </ul> <p>See the Configuration Options for more details on how to set up the server in different modes.</p>"},{"location":"mcp/install/#claude-cursor-and-windsurf","title":"Claude, Cursor, and Windsurf","text":"<p>Add the following configuration to your AI assistant's settings to enable the Flux MCP Server:</p> <pre><code>{\n \"mcpServers\": {\n   \"flux-operator-mcp\": {\n     \"command\": \"/path/to/flux-operator-mcp\",\n     \"args\": [\"serve\"],\n     \"env\": {\n       \"KUBECONFIG\": \"/path/to/.kube/config\"\n     }\n   }\n }\n}\n</code></pre> <p>Replace <code>/path/to/flux-operator-mcp</code> with the actual path to the binary and <code>/path/to/.kube/config</code> with the path to your kubeconfig file.</p> <p>To determine the correct paths for the binary and kubeconfig, you can use the following commands:</p> <pre><code>which flux-operator-mcp\necho $HOME/.kube/config\n</code></pre>"},{"location":"mcp/install/#vs-code-copilot-chat","title":"VS Code Copilot Chat","text":"<p>Add the following configuration to your VS Code settings:</p> <pre><code>{\n \"mcp\": {\n   \"servers\": {\n     \"flux-operator-mcp\": {\n       \"command\": \"/path/to/flux-operator-mcp\",\n       \"args\": [\"serve\"],\n       \"env\": {\n         \"KUBECONFIG\": \"/path/to/.kube/config\"\n       }\n     }\n   }\n },\n \"chat.mcp.enabled\": true\n}\n</code></pre> <p>Replace <code>/path/to/flux-operator-mcp</code> with the actual path to the binary and <code>/path/to/.kube/config</code> with the path to your kubeconfig file.</p> <p>When using GitHub Copilot Chat, enable Agent mode to access the Flux MCP tools.</p>"},{"location":"mcp/install/#testing-your-installation","title":"Testing Your Installation","text":"<p>Before using the Flux MCP Server, it is important to set up the AI instructions for your assistant. Copy the rules from the instructions.md file and place them into the appropriate settings for your assistant, for more details on how to do this see the AI Instructions section.</p> <p>After the instructions are in place, you can test the installation with the following prompts:</p> <ul> <li>\"Which cluster contexts are available in my kubeconfig?\"</li> <li>\"What version of Flux is running in my current cluster?\"</li> </ul> <p>If the AI assistant successfully interacts with your cluster and provides relevant information, your installation is working correctly.</p>"},{"location":"mcp/install/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Server not found<ul> <li>Verify the path to the binary is correct</li> <li>Ensure the binary has execute permissions</li> </ul> </li> <li>AI assistant can't find the tools<ul> <li>Restart the AI assistant application</li> <li>Verify the MCP configuration is correct</li> <li>For VS Code, ensure Agent mode is enabled</li> </ul> </li> <li>Kubeconfig not found<ul> <li>Check the path to your kubeconfig</li> <li>Verify the kubeconfig is valid with <code>kubectl get crds</code></li> </ul> </li> <li>Permission issues<ul> <li>Ensure your kubeconfig has sufficient permissions </li> <li>Verify the permissions with <code>kubectl get fluxinstance -A</code></li> </ul> </li> </ul>"},{"location":"mcp/install/#upgrading","title":"Upgrading","text":"<p>To upgrade the Flux MCP Server to a newer version:</p> <ol> <li>Download the latest binary from the GitHub Releases page</li> <li>Replace your existing binary with the new one</li> <li>Restart any AI assistant applications that use the server</li> </ol>"},{"location":"mcp/install/#uninstallation","title":"Uninstallation","text":"<p>To uninstall the Flux MCP Server:</p> <ol> <li>Remove the binary from your system</li> <li>Remove the MCP configuration from your AI assistant's settings</li> </ol>"},{"location":"mcp/instructions/","title":"AI Chat Guidelines for Flux MCP Server","text":""},{"location":"mcp/instructions/#purpose","title":"Purpose","text":"<p>You are an AI assistant specialized in analyzing and troubleshooting GitOps pipelines managed by Flux Operator on Kubernetes clusters. You will be using the <code>flux-operator-mcp</code> tools to connect to clusters and fetch Kubernetes and Flux resources.</p>"},{"location":"mcp/instructions/#flux-custom-resources-overview","title":"Flux Custom Resources Overview","text":"<p>Flux consists of the following Kubernetes controllers and custom resource definitions (CRDs):</p> <ul> <li>Flux Operator</li> <li>FluxInstance: Manages the Flux controllers installation and configuration</li> <li>FluxReport: Reflects the state of a Flux installation</li> <li>ResourceSet: Manages groups of Kubernetes resources based on input matrices</li> <li>ResourceSetInputProvider: Fetches input values from external services (GitHub, GitLab)</li> <li>Source Controller</li> <li>GitRepository: Points to a Git repository containing Kubernetes manifests or Helm charts</li> <li>OCIRepository: Points to a container registry containing OCI artifacts (manifests or Helm charts)</li> <li>Bucket: Points to an S3-compatible bucket containing manifests</li> <li>HelmRepository: Points to a Helm chart repository</li> <li>HelmChart: References a chart from a HelmRepository or a GitRepository</li> <li>Kustomize Controller</li> <li>Kustomization: Builds and applies Kubernetes manifests from sources</li> <li>Helm Controller</li> <li>HelmRelease: Manages Helm chart releases from sources</li> <li>Notification Controller</li> <li>Provider: Represents a notification service (Slack, MS Teams, etc.)</li> <li>Alert: Configures events to be forwarded to providers</li> <li>Receiver: Defines webhooks for triggering reconciliations</li> <li>Image Automation Controllers</li> <li>ImageRepository: Scans container registries for new tags</li> <li>ImagePolicy: Selects the latest image tag based on policy</li> <li>ImageUpdateAutomation: Updates Git repository with new image tags</li> </ul> <p>For a deep understanding of the Flux CRDs, call the <code>search_flux_docs</code> tool for each resource kind.</p>"},{"location":"mcp/instructions/#general-rules","title":"General rules","text":"<ul> <li>When asked about the Flux installation status, call the <code>get_flux_instance</code> tool.</li> <li>When asked about Kubernetes or Flux resources, call the <code>get_kubernetes_resources</code> tool.</li> <li>Don't make assumptions about the <code>apiVersion</code> of a Kubernetes or Flux resource, call the <code>get_kubernetes_api_versions</code> tool to find the correct one.</li> <li>When asked to use a specific cluster, call the <code>get_kubernetes_contexts</code> tool to find the cluster context before switching to it with the <code>set_kubernetes_context</code> tool.</li> <li>After switching the context to a new cluster, call the <code>get_flux_instance</code> tool to determine the Flux Operator status and settings.</li> <li>To determine if a Kubernetes resource is Flux-managed, search the metadata field for <code>fluxcd</code> labels.</li> <li>When asked to create or update resources, generate a Kubernetes YAML manifest and call the <code>apply_kubernetes_resource</code> tool to apply it.</li> <li>Avoid applying changes to Flux-managed resources unless explicitly requested.</li> <li>When asked about Flux CRDs call the <code>search_flux_docs</code> tool to get the latest API docs.</li> </ul>"},{"location":"mcp/instructions/#kubernetes-logs-analysis","title":"Kubernetes logs analysis","text":"<p>When looking at logs, first you need to determine the pod name:</p> <ul> <li>Get the Kubernetes deployment that manages the pods using the <code>get_kubernetes_resources</code> tool.</li> <li>Look for the <code>matchLabels</code> and the container name in the deployment spec.</li> <li>List the pods with the <code>get_kubernetes_resources</code> tool using the found <code>matchLabels</code> from the deployment spec.</li> <li>Get the logs by calling the <code>get_kubernetes_logs</code> tool using the pod name and container name.</li> </ul>"},{"location":"mcp/instructions/#flux-helmrelease-analysis","title":"Flux HelmRelease analysis","text":"<p>When troubleshooting a HelmRelease, follow these steps:</p> <ul> <li>Use the <code>get_flux_instance</code> tool to check the helm-controller deployment status and the apiVersion of the HelmRelease kind.</li> <li>Use the <code>get_kubernetes_resources</code> tool to get the HelmRelease, then analyze the spec, the status, inventory and events.</li> <li>Determine which Flux object is managing the HelmRelease by looking at the annotations; it can be a Kustomization or a ResourceSet.</li> <li>If <code>valuesFrom</code> is present, get all the referenced ConfigMap and Secret resources.</li> <li>Identify the HelmRelease source by looking at the <code>chartRef</code> or the <code>sourceRef</code> field.</li> <li>Use the <code>get_kubernetes_resources</code> tool to get the HelmRelease source then analyze the source status and events.</li> <li>If the HelmRelease is in a failed state or in progress, it may be due to failures in one of the managed resources found in the inventory.</li> <li>Use the <code>get_kubernetes_resources</code> tool to get the managed resources and analyze their status.</li> <li>If the managed resources are in a failed state, analyze their logs using the <code>get_kubernetes_logs</code> tool.</li> <li>If any issues were found, create a root cause analysis report for the user.</li> <li>If no issues were found, create a report with the current status of the HelmRelease and its managed resources and container images.</li> </ul>"},{"location":"mcp/instructions/#flux-kustomization-analysis","title":"Flux Kustomization analysis","text":"<p>When troubleshooting a Kustomization, follow these steps:</p> <ul> <li>Use the <code>get_flux_instance</code> tool to check the kustomize-controller deployment status and the apiVersion of the Kustomization kind.</li> <li>Use the <code>get_kubernetes_resources</code> tool to get the Kustomization, then analyze the spec, the status, inventory and events.</li> <li>Determine which Flux object is managing the Kustomization by looking at the annotations; it can be another Kustomization or a ResourceSet.</li> <li>If <code>substituteFrom</code> is present, get all the referenced ConfigMap and Secret resources.</li> <li>Identify the Kustomization source by looking at the <code>sourceRef</code> field.</li> <li>Use the <code>get_kubernetes_resources</code> tool to get the Kustomization source then analyze the source status and events.</li> <li>If the Kustomization is in a failed state or in progress, it may be due to failures in one of the managed resources found in the inventory.</li> <li>Use the <code>get_kubernetes_resources</code> tool to get the managed resources and analyze their status.</li> <li>If the managed resources are in a failed state, analyze their logs using the <code>get_kubernetes_logs</code> tool.</li> <li>If any issues were found, create a root cause analysis report for the user.</li> <li>If no issues were found, create a report with the current status of the Kustomization and its managed resources.</li> </ul>"},{"location":"mcp/instructions/#flux-comparison-analysis","title":"Flux Comparison analysis","text":"<p>When comparing a Flux resource between clusters, follow these steps:</p> <ul> <li>Use the <code>get_kubernetes_contexts</code> tool to get the cluster contexts.</li> <li>Use the <code>set_kubernetes_context</code> tool to switch to a specific cluster.</li> <li>Use the <code>get_flux_instance</code> tool to check the Flux Operator status and settings.</li> <li>Use the <code>get_kubernetes_resources</code> tool to get the resource you want to compare.</li> <li>If the Flux resource contains <code>valuesFrom</code> or <code>substituteFrom</code>, get all the referenced ConfigMap and Secret resources.</li> <li>Repeat the above steps for each cluster.</li> </ul> <p>When comparing resources, look for differences in the <code>spec</code>, <code>status</code> and <code>events</code>, including the referenced ConfigMaps and Secrets. The Flux resource <code>spec</code> represents the desired state and should be the main focus of the comparison, while the status and events represent the current state in the cluster.</p>"},{"location":"mcp/prompt-engineering/","title":"Flux MCP Server Prompting Guide","text":"<p>This guide provides recommendations for configuring your AI assistants with instructions and offers effective prompting strategies to get the most out of the Flux MCP Server.</p>"},{"location":"mcp/prompt-engineering/#ai-instructions","title":"AI Instructions","text":"<p>Providing instructions is crucial for guiding the behavior of your AI assistant when interacting with the Flux MCP Server. We've created a set of instructions (1400 tokens) that you can use as a starting point.</p> <p>Copy the rules from the instructions.md file and place them into the appropriate settings for your assistant as follows:</p> <ul> <li>Claude: Use the <code>Project Instructions</code> section in Claude Desktop</li> <li>Cursor: Use the <code>.cursor/rules</code> dir in your Git repository</li> <li>Windsurf: Use the <code>.windsurf/rules</code> dir in your Git repository</li> <li>GitHub Copilot: Use the <code>.github/copilot-instructions.md</code> file in your Git repository</li> </ul> <p>It is recommended to enhance the instructions with relevant information about your clusters to help the AI assistant understand your context better. For example, Kubernetes distribution, Cloud provider, what type of applications are deployed, how secrets are managed.</p>"},{"location":"mcp/prompt-engineering/#prompting-strategies","title":"Prompting Strategies","text":"<p>For the best experience with the Flux MCP Server tools:</p> <ul> <li>Start broad, then narrow: Begin with general queries about your Flux installation before drilling down</li> <li>Include context: Mention the namespace, cluster, and relevant details in your requests</li> <li>Chain operations: For complex workflows, ask the AI to perform a sequence of related operations</li> <li>Verify changes: After performing modifications, ask for verification of the new state</li> <li>Use documentation: When in doubt about Flux features, explicitly ask to search the Flux API documentation</li> </ul>"},{"location":"mcp/prompt-engineering/#repository-context","title":"Repository Context","text":"<p>When using an AI chat within your IDE, you can leverage the context of your Git repositories that contain Kubernetes and Flux resources. This will enable the AI assistant to compare manifest files with cluster state and provide an accurate analysis.</p> <p>When using Claude Desktop, you can install the filesystem MCP server and allow the assistant to access the Kubernetes manifests in your Git repository.</p> <p>In the Claude project knowledge, add the Flux Operator documentation using the <code>https://github.com/controlplaneio-fluxcd/distribution</code> repository and select the <code>docs/operator</code> folder. This will ensure that the latest Flux Operator API specifications are available to the model along with guides and examples.</p>"},{"location":"mcp/prompt-engineering/#example-prompts","title":"Example Prompts","text":"<p>Reporting and troubleshooting:</p> <ul> <li>Analyze the Flux installation in my current cluster and report the status of all components.</li> <li>List the clusters in my kubeconfig and compare the Flux instances across them.</li> <li>Are there any reconciliation errors in the Flux-managed resources?</li> <li>Are the Flux kustomizations and Helm releases configured correctly?</li> <li>Based on Flux events, what deployments have been updated today?</li> <li>Draw a diagram of the Flux dependency flow in the cluster.</li> <li>What is the Git source and revision of the Flux OCI repositories?</li> <li>Which Kubernetes deployments are managed by Flux in the current cluster?</li> <li>Which images are deployed by Flux in the monitoring namespace?</li> <li>Perform a root cause analysis of the last failed deployment in the frontend namespace.</li> </ul> <p>Actions:</p> <ul> <li>Reconcile the flux-system kustomization with its source in the current cluster.</li> <li>Reconcile all the Flux Kustomization from flux-system namespace in the depends-on order, then verify their status.</li> <li>Suspend all failing Helm releases in the test namespace, then delete them from the cluster.</li> <li>Search for all the suspended Flux Kustomizations in the cluster and resume them.</li> <li>Generate a namespace called test and apply it on my current cluster.</li> <li>Copy the flux service account and its RBAC from the frontend namespace into test (remove the fluxcd labels).</li> <li>Delete the test namespace from my current cluster.</li> </ul> <p>Learning:</p> <ul> <li>How to configure mutual TLS for Git? Answer using the latest Flux docs.</li> <li>What is the role of the interval setting in a Flux Kustomization?  Search the latest docs.</li> <li>How to trigger a Flux reconciliation with a webhook? Search the latest docs.</li> </ul>"},{"location":"mcp/prompt-engineering/#predefined-prompts","title":"Predefined Prompts","text":"<p>The Flux MCP Server comes with a set of predefined prompts. These prompts are designed to help you quickly get started with common tasks such as troubleshooting Flux Kustomizations and Helm releases.</p> <p>For a complete list of predefined prompts, refer to the MCP prompts documentation.</p>"},{"location":"mcp/prompts/","title":"Flux MCP Server Prompts","text":"<p>The Flux MCP Server comes with a set of predefined prompts that instruct the AI assistant to perform complex tasks by chaining together multiple MCP tools.</p>"},{"location":"mcp/prompts/#debugging-prompts","title":"Debugging Prompts","text":"<p>These prompts are designed to help you quickly identify and resolve issues with your GitOps pipeline.</p>"},{"location":"mcp/prompts/#debug_flux_kustomization","title":"debug_flux_kustomization","text":"<p>Troubleshoot a Flux Kustomization and provide root cause analysis for any issues.</p> <p>Parameters:</p> <ul> <li><code>name</code> (required): The name of the Kustomization</li> <li><code>namespace</code> (required): The namespace of the Kustomization</li> <li><code>cluster</code> (optional): The cluster context to use</li> </ul>"},{"location":"mcp/prompts/#debug_flux_helmrelease","title":"debug_flux_helmrelease","text":"<p>Troubleshoot a Flux HelmRelease and provide root cause analysis for any issues.</p> <p>Parameters:</p> <ul> <li><code>name</code> (required): The name of the HelmRelease</li> <li><code>namespace</code> (required): The namespace of the HelmRelease</li> <li><code>cluster</code> (optional): The cluster context to use</li> </ul>"},{"location":"mcp/tools/","title":"Flux MCP Server Tools","text":"<p>The Flux Model Context Protocol (MCP) Server provides a comprehensive set of tools that enable AI assistants to interact with Kubernetes clusters managed by Flux Operator.</p>"},{"location":"mcp/tools/#reporting-tools","title":"Reporting Tools","text":"<p>These tools gather information from the cluster without making any changes to the system state.</p>"},{"location":"mcp/tools/#get_flux_instance","title":"get_flux_instance","text":"<p>Retrieves detailed information about the Flux installation.</p> <p>Parameters: None</p> <p>Output:</p> <p>The tool returns comprehensive details about the Flux instance configuration, including the distribution version information, component status and health, cluster sync statistics.</p>"},{"location":"mcp/tools/#get_kubernetes_resources","title":"get_kubernetes_resources","text":"<p>Retrieves Kubernetes resources from the cluster, including Flux custom resources, their status, and associated events.</p> <p>Parameters:</p> <ul> <li><code>apiVersion</code> (required): The API version of the resource(s)</li> <li><code>kind</code> (required): The kind of the resource(s)</li> <li><code>name</code> (optional): The name of a specific resource</li> <li><code>namespace</code> (optional): The namespace to query</li> <li><code>selector</code> (optional): Label selector in the format <code>key1=value1,key2=value2</code></li> <li><code>limit</code> (optional): Maximum number of resources to return</li> </ul> <p>Output:</p> <p>Returns the requested resources in YAML format, including: - Resource specifications - Status conditions - Related events - Metadata including Flux source references</p>"},{"location":"mcp/tools/#get_kubernetes_logs","title":"get_kubernetes_logs","text":"<p>Retrieves logs from Kubernetes pods, allowing AI assistants to analyze application behavior and troubleshoot issues.</p> <p>Parameters:</p> <ul> <li><code>pod_name</code> (required): The name of the pod</li> <li><code>pod_namespace</code> (required): The namespace of the pod</li> <li><code>container_name</code> (required): The name of the container</li> <li><code>limit</code> (optional): Maximum number of log lines to return (default: 100)</li> </ul> <p>Output:</p> <p>Returns the specified number of log lines from the requested container, with timestamps and log levels preserved.</p>"},{"location":"mcp/tools/#get_kubernetes_metrics","title":"get_kubernetes_metrics","text":"<p>Retrieves CPU and Memory usage for Kubernetes pods, allowing AI assistants to monitor resource consumption and performance. This tool depends on the Kubernetes metrics-server being installed in the cluster.</p> <p>Parameters:</p> <ul> <li><code>pod_name</code> (optional): The name of the pod, when not specified all pods are selected.</li> <li><code>pod_namespace</code> (required): The namespace of the pods.</li> <li><code>pod_selector</code> (optional): Label selector in the format <code>key1=value1,key2=value2</code></li> <li><code>limit</code> (optional): Maximum number of metrics to return (default: 100)</li> </ul> <p>Output:</p> <p>Returns the metrics for the specified pods, including CPU and Memory for each container, in YAML format.</p>"},{"location":"mcp/tools/#get_kubernetes_api_versions","title":"get_kubernetes_api_versions","text":"<p>Retrieves the Kubernetes CRDs registered on the cluster and returns the preferred apiVersion for each kind.</p> <p>Parameters: None</p> <p>Output:</p> <p>Returns a mapping of Kubernetes resource kinds to their preferred API versions, which is essential for crafting valid API calls.</p>"},{"location":"mcp/tools/#multi-cluster-tools","title":"Multi-Cluster Tools","text":"<p>These tools facilitate interaction with multiple Kubernetes clusters, enabling cross-cluster comparisons and operations.</p>"},{"location":"mcp/tools/#get_kubeconfig_contexts","title":"get_kubeconfig_contexts","text":"<p>Retrieves the available Kubernetes cluster contexts from the kubeconfig.</p> <p>Parameters: None</p> <p>Output:</p> <p>List of available Kubernetes contexts with their associated cluster name.</p>"},{"location":"mcp/tools/#set_kubeconfig_context","title":"set_kubeconfig_context","text":"<p>Switches the current session to use a specific Kubernetes cluster context, without modifying the kubeconfig file.</p> <p>Parameters:</p> <ul> <li><code>name</code> (required): The name of the context to set</li> </ul> <p>Output:</p> <p>Confirmation message indicating the context has been switched.</p>"},{"location":"mcp/tools/#reconciliation-tools","title":"Reconciliation Tools","text":"<p>These tools trigger reconciliation of Flux resources, causing Flux to synchronize the desired state with the current state.</p>"},{"location":"mcp/tools/#reconcile_flux_resourceset","title":"reconcile_flux_resourceset","text":"<p>Triggers the reconciliation of a Flux ResourceSet.</p> <p>Parameters:</p> <ul> <li><code>name</code> (required): The name of the ResourceSet</li> <li><code>namespace</code> (required): The namespace of the ResourceSet</li> </ul> <p>Output:</p> <p>Confirmation message and instructions for verifying the reconciliation status.</p>"},{"location":"mcp/tools/#reconcile_flux_source","title":"reconcile_flux_source","text":"<p>Triggers the reconciliation of Flux sources (GitRepository, OCIRepository, HelmRepository, HelmChart, Bucket).</p> <p>Parameters:</p> <ul> <li><code>kind</code> (required): The kind of Flux source</li> <li><code>name</code> (required): The name of the source</li> <li><code>namespace</code> (required): The namespace of the source</li> </ul> <p>Output:</p> <p>Confirmation message and instructions for verifying the reconciliation status.</p>"},{"location":"mcp/tools/#reconcile_flux_kustomization","title":"reconcile_flux_kustomization","text":"<p>Triggers the reconciliation of a Flux Kustomization.</p> <p>Parameters:</p> <ul> <li><code>name</code> (required): The name of the Kustomization</li> <li><code>namespace</code> (required): The namespace of the Kustomization</li> <li><code>with_source</code> (optional): Whether to also reconcile the source (default: false)</li> </ul> <p>Output:</p> <p>Confirmation message and instructions for verifying the reconciliation status.</p>"},{"location":"mcp/tools/#reconcile_flux_helmrelease","title":"reconcile_flux_helmrelease","text":"<p>Triggers the reconciliation of a Flux HelmRelease.</p> <p>Parameters:</p> <ul> <li><code>name</code> (required): The name of the HelmRelease</li> <li><code>namespace</code> (required): The namespace of the HelmRelease</li> <li><code>with_source</code> (optional): Whether to also reconcile the source (default: false)</li> </ul> <p>Output:</p> <p>Confirmation message and instructions for verifying the reconciliation status.</p>"},{"location":"mcp/tools/#suspendresume-tools","title":"Suspend/Resume Tools","text":"<p>These tools allow for pausing and resuming the reconciliation of Flux resources.</p>"},{"location":"mcp/tools/#suspend_flux_reconciliation","title":"suspend_flux_reconciliation","text":"<p>Suspends the reconciliation of a Flux resource.</p> <p>Parameters:</p> <ul> <li><code>apiVersion</code> (required): The API version of the resource</li> <li><code>kind</code> (required): The kind of the resource</li> <li><code>name</code> (required): The name of the resource</li> <li><code>namespace</code> (required): The namespace of the resource</li> </ul> <p>Output:</p> <p>Confirmation message indicating the resource has been suspended.</p>"},{"location":"mcp/tools/#resume_flux_reconciliation","title":"resume_flux_reconciliation","text":"<p>Resumes the reconciliation of a previously suspended Flux resource.</p> <p>Parameters:</p> <ul> <li><code>apiVersion</code> (required): The API version of the resource</li> <li><code>kind</code> (required): The kind of the resource</li> <li><code>name</code> (required): The name of the resource</li> <li><code>namespace</code> (required): The namespace of the resource</li> </ul> <p>Output:</p> <p>Confirmation message indicating the resource has been resumed.</p>"},{"location":"mcp/tools/#apply-tool","title":"Apply Tool","text":"<p>This tool allows creating or updating Kubernetes resources in the cluster. If the resources already exist and are managed by Flux, the tool will error out unless explicitly told to overwrite them.</p>"},{"location":"mcp/tools/#apply_kubernetes_manifest","title":"apply_kubernetes_manifest","text":"<p>Applies a YAML manifest on the cluster using Kubernetes server-side apply.</p> <p>Parameters:</p> <ul> <li><code>yaml_content</code> (required): The multi-doc YAML content</li> <li><code>overwrite</code> (optional): Whether to overwrite resources managed by Flux (default: false)</li> </ul> <p>Output:</p> <p>The list of applied resources in the format <code>kind/namespace/name [created|updated|unchanged]</code>.</p>"},{"location":"mcp/tools/#deletion-tool","title":"Deletion Tool","text":"<p>This tool enables the removal of resources from your cluster.</p>"},{"location":"mcp/tools/#delete_kubernetes_resource","title":"delete_kubernetes_resource","text":"<p>Deletes a Kubernetes resource from the cluster.</p> <p>Parameters:</p> <ul> <li><code>apiVersion</code> (required): The API version of the resource</li> <li><code>kind</code> (required): The kind of the resource</li> <li><code>name</code> (required): The name of the resource</li> <li><code>namespace</code> (required for namespaced resources): The namespace of the resource</li> </ul> <p>Output:</p> <p>Confirmation message indicating the resource has been deleted.</p>"},{"location":"mcp/tools/#install-tool","title":"Install Tool","text":"<p>This tool enables automated installation of Flux Operator and Flux instances on Kubernetes clusters.</p>"},{"location":"mcp/tools/#install_flux_instance","title":"install_flux_instance","text":"<p>Installs Flux Operator and a Flux instance on the cluster from a manifest URL.</p> <p>Parameters:</p> <ul> <li><code>instance_url</code> (required): The URL pointing to the Flux Instance manifest file (supports HTTPS and OCI URLs)</li> <li><code>timeout</code> (optional): The installation timeout duration (default: 5m)</li> </ul> <p>Output:</p> <p>Returns a detailed installation log including deployed resources with their change status.</p> <p>Installation Steps:</p> <p>The tool performs the following operations:</p> <ol> <li>Downloads the Flux instance manifest from the provided URL</li> <li>Downloads the Flux Operator manifests from the distribution artifact</li> <li>Installs or upgrades the Flux Operator in the <code>flux-system</code> namespace</li> <li>Installs or upgrades the Flux instance according to the manifest configuration</li> <li>Waits for the Flux instance to become ready</li> <li>Configures automatic updates for the Flux Operator</li> </ol> <p>Example URLs:</p> <ul> <li>OCI Artifact: <code>oci://ghcr.io/org/manifests:latest#clusters/dev/flux-system/flux-instance.yaml</code></li> <li>GitHub Gist: <code>https://gist.github.com/user/id#file-flux-instance-yaml</code></li> <li>GitHub Repo: <code>https://github.com/org/repo/blob/main/clusters/dev/flux-system/flux-instance.yaml</code></li> <li>GitLab Repo: <code>https://gitlab.com/org/proj/-/blob/main/clusters/dev/flux-system/flux-instance.yaml</code></li> </ul>"},{"location":"mcp/tools/#documentation-tool","title":"Documentation Tool","text":"<p>This tool provides access to the latest Flux documentation.</p>"},{"location":"mcp/tools/#search_flux_docs","title":"search_flux_docs","text":"<p>Searches the Flux documentation for specific information, ensuring the AI assistant can provide up-to-date guidance.</p> <p>Parameters:</p> <ul> <li><code>query</code> (required): The search query</li> <li><code>limit</code> (optional): Maximum number of results to return (default: 1)</li> </ul> <p>Output:</p> <p>Relevant documentation from the Flux project that matches the search query.</p>"},{"location":"mcp/tools/#scopes-and-the-toolslist-request","title":"Scopes and the <code>tools/list</code> request","text":"<p>Note: The feature described in this section is available only with the Streamable HTTP transport mode and when authentication is configured.</p> <p>Scopes are a part of the Flux MCP Server authentication and authorization system. Credentials can have a set of scopes on them to indicate to the Flux MCP Server which operations are allowed for that credential. For responding to the <code>tools/list</code> request, the server checks the scopes of the credential to dynamically filter the list of available tools out of those remaining after considering if the MCP server is running in read-only mode. In other words, the tools advertised in the <code>tools/list</code> request will be those that are not eliminated by the read-only mode and that are not eliminated by the scopes granted to the credential.</p> <p>Furthermore, the Flux MCP Server leverages the <code>_meta</code> field of the <code>tools/list</code> response (as defined by the MCP specification) to advertise the available scopes in <code>_meta.scopes</code>. Those will be the scopes that can be useful for the tools available in the server taking the read-only mode into account.</p> <p>Each scope has the following fields:</p> <ul> <li><code>name</code>: The scope identifier. Will always have the prefix <code>toolbox:</code>.</li> <li><code>description</code>: A short human-readable description of what the scope allows.</li> <li><code>tools</code>: The list of tools the scope grants access to, discarding any tools that   are not available due to the read-only mode if enabled.</li> </ul> <p>The advertised scopes for a given instance of the Flux MCP Server can be inspected by running the following command:</p> <pre><code>flux-operator-mcp debug scopes &lt;Flux MCP URL&gt;\n</code></pre> <p>This command will make a <code>tools/list</code> request to the pointed MCP URL and will print in the JSON format the content of the <code>_meta.scopes</code> field returned in the response.</p>"},{"location":"operator/","title":"Flux Operator Introduction","text":"<p>The Flux Operator is a Kubernetes CRD controller that manages the lifecycle of CNCF Flux and the ControlPlane enterprise distribution. The operator extends Flux with self-service capabilities, deployment windows and preview environments for GitHub, GitLab and Azure DevOps pull requests testing.</p> <p>Flux MCP Server</p> <p>The Flux Operator project includes an experimental Model Context Protocol Server for AI-assisted GitOps. Check the Flux MCP Server documentation for more details.</p>"},{"location":"operator/#features","title":"Features","text":"<ul> <li> <p> Lifecycle Management</p> <p>The operator automates the installation, configuration and upgrade of the Flux controllers through a declarative API.  It manages the update of Flux CRDs and prevents disruption during the upgrade process.</p> </li> <li> <p> Advanced Configuration</p> <p>The operator allows the configuration of Flux multi-tenancy lockdown, sharding, vertical scaling, persistent storage, and the syncing of the cluster state from Git repositories, OCI artifacts and S3-compatible storage.</p> </li> <li> <p> Deep Insights</p> <p>The operator provides deep insights into the delivery pipelines managed by Flux, including detailed reports about the Flux controllers readiness status, reconcilers statistics, and cluster state sync.</p> </li> <li> <p> Enterprise Automation</p> <p>The operator streamlines the deployment of the ControlPlane Enterprise Distribution for Flux CD, and automates the patching of hotfixes and CVEs affecting the Flux controllers container images.</p> </li> </ul>"},{"location":"operator/#license","title":"License","text":"<p>The Flux Operator is an open-source project licensed under the AGPL-3.0 license.</p> <p>The project is developed by CNCF Flux core maintainers part of the ControlPlane team.</p>"},{"location":"operator/cli/","title":"Flux Operator CLI","text":"<p>The Flux Operator CLI is a command line tool that allows you to manage the Flux Operator resources in your Kubernetes clusters. It provides a convenient way to interact with the operator and perform various operations.</p>"},{"location":"operator/cli/#installation","title":"Installation","text":"<p>The Flux Operator CLI is available as a binary executable for Linux, macOS, and Windows. The binaries can be downloaded from GitHub releases page.</p> <p>If you are using macOS or Linux, you can install the CLI using Homebrew:</p> <pre><code>brew install controlplaneio-fluxcd/tap/flux-operator\n</code></pre> <p>To configure your shell to load <code>flux-operator</code> Bash completions add to your profile:</p> <pre><code>echo \"source &lt;(flux-operator completion bash)\" &gt;&gt; ~/.bash_profile\n</code></pre> <p>Zsh, Fish, and PowerShell are also supported with their own sub-commands.</p>"},{"location":"operator/cli/#container-image","title":"Container Image","text":"<p>The Flux Operator CLI is also available as a container image, which can be used in CI pipelines or Kubernetes Jobs. The image contains the <code>flux-operator</code> CLI binary and the <code>kubectl</code> binary.</p> <p>The multi-arch image (Linux AMD64/ARM64) is hosted on GitHub Container Registry at <code>ghcr.io/controlplaneio-fluxcd/flux-operator-cli</code>.</p> <pre><code>version=$(gh release view --repo controlplaneio-fluxcd/flux-operator --json tagName -q '.tagName')\ndocker run --rm -it --entrypoint=flux-operator ghcr.io/controlplaneio-fluxcd/flux-operator-cli:$version help\ndocker run --rm -it --entrypoint=kubectl ghcr.io/controlplaneio-fluxcd/flux-operator-cli:$version help\n</code></pre>"},{"location":"operator/cli/#commands","title":"Commands","text":"<p>The Flux Operator CLI provides commands to manage the Flux Operator resources. Except for the <code>build</code> commands, all others require access to the Kubernetes cluster and the Flux Operator to be installed.</p> <p>The CLI connects to the cluster using the <code>~.kube/config</code> file, similar to <code>kubectl</code>.</p> <p>All commands display help information and example usage when run with the <code>-h</code> or <code>--help</code> flag.</p>"},{"location":"operator/cli/#build-commands","title":"Build Commands","text":"<p>The <code>flux-operator build</code> commands are used to build and validate the Flux Operator resources. These commands do not require access to a Kubernetes cluster and can be run in any environment.</p> <p>The following commands are available:</p> <ul> <li><code>flux-operator build instance</code>: Generates the Flux Kubernetes manifests from a FluxInstance definition.<ul> <li><code>-f, --file</code>: Path to the FluxInstance YAML manifest (required).</li> </ul> </li> <li><code>flux-operator build rset</code>: Generates the Kubernetes manifests from a ResourceSet definition.<ul> <li><code>-f, --file</code>: Path to the ResourceSet YAML manifest (required).</li> <li><code>--inputs-from</code>: Path to the ResourceSet inputs YAML manifest.</li> <li><code>--inputs-from-provider</code>: Path to the ResourceSetInputProvider static type YAML manifest.</li> </ul> </li> </ul>"},{"location":"operator/cli/#get-commands","title":"Get Commands","text":"<p>The <code>flux-operator get</code> commands are used to retrieve information about the Flux Operator resources in the cluster.</p> <p>The following commands are available:</p> <ul> <li><code>flux-operator get instance</code>: Retrieves the FluxInstance resource in the cluster.</li> <li><code>flux-operator get rset</code>: Retrieves the ResourceSet resources in the cluster.</li> <li><code>flux-operator get rsip</code>: Retrieves the ResourceSetInputProvider resources in the cluster.</li> </ul> <p>Arguments:</p> <ul> <li><code>-n, --namespace</code>: Specifies the namespace to filter the resources.</li> <li><code>-A, --all-namespaces</code>: Retrieves resources from all namespaces.</li> </ul>"},{"location":"operator/cli/#get-all-command","title":"Get All Command","text":"<p>This command can be used to retrieve information about all Flux resources in the cluster, it supports filtering by resource kind, namespace and ready status.</p> <ul> <li><code>flux-operator get all</code>: Retrieves all Flux resources and their status.</li> </ul> <p>Arguments:</p> <ul> <li><code>--kind</code>: Specifies the kind of resources to filter (e.g. Kustomization, HelmRelease, etc.).</li> <li><code>--ready-status</code>: Filters resources by their ready status (True, False, Unknown or Suspended).</li> <li><code>-o, --output</code>: Specifies the output format (table, json, yaml). Default is table.</li> <li><code>-n, --namespace</code>: Specifies the namespace to filter the resources.</li> <li><code>-A, --all-namespaces</code>: Retrieves resources from all namespaces.</li> </ul>"},{"location":"operator/cli/#export-commands","title":"Export Commands","text":"<p>The <code>flux-operator export</code> commands are used to export the Flux Operator resources in YAML format. The exported resources can be used for backup, migration, or inspection purposes.</p> <p>The following commands are available:</p> <ul> <li><code>flux-operator export report</code>: Exports the FluxReport resource containing the distribution status and version information.</li> <li><code>flux-operator export resource &lt;kind&gt;/&lt;name&gt;</code>: Exports a Flux resource from the specified namespace.</li> </ul> <p>Arguments:</p> <ul> <li><code>-n, --namespace</code>: Specifies the namespace scope of the command.</li> </ul>"},{"location":"operator/cli/#reconcile-commands","title":"Reconcile Commands","text":"<p>The <code>flux-operator reconcile</code> commands are used to trigger the reconciliation of the Flux Operator resources.</p> <p>The following commands are available:</p> <ul> <li><code>flux-operator reconcile instance &lt;name&gt;</code>: Reconciles the FluxInstance resource in the cluster.</li> <li><code>flux-operator reconcile rset &lt;name&gt;</code>: Reconciles the ResourceSet resource in the cluster.</li> <li><code>flux-operator reconcile rsip &lt;name&gt;</code>: Reconciles the ResourceSetInputProvider resource in the cluster.</li> <li><code>flux-operator reconcile resource &lt;kind&gt;/&lt;name&gt;</code>: Reconciles a Flux resource in the specified namespace.</li> <li><code>flux-operator reconcile all</code>: Reconciles all Flux resources in the cluster (supports filtering by ready status).</li> </ul> <p>Arguments:</p> <ul> <li><code>-n, --namespace</code>: Specifies the namespace scope of the command.</li> <li><code>--wait</code>: Waits for the reconciliation to complete before returning.</li> </ul>"},{"location":"operator/cli/#suspendresume-commands","title":"Suspend/Resume Commands","text":"<p>The <code>flux-operator suspend</code> and <code>flux-operator resume</code> commands are used to suspend or resume the reconciliation of the Flux Operator resources.</p> <p>The following commands are available:</p> <ul> <li><code>flux-operator suspend instance &lt;name&gt;</code>: Suspends the reconciliation of the FluxInstance resource in the cluster.</li> <li><code>flux-operator resume instance &lt;name&gt;</code>: Resumes the reconciliation of the FluxInstance resource in the cluster.</li> <li><code>flux-operator suspend rset &lt;name&gt;</code>: Suspends the reconciliation of the ResourceSet resource in the cluster.</li> <li><code>flux-operator resume rset &lt;name&gt;</code>: Resumes the reconciliation of the ResourceSet resource in the cluster.</li> <li><code>flux-operator suspend rsip &lt;name&gt;</code>: Suspends the reconciliation of the ResourceSetInputProvider resource in the cluster.</li> <li><code>flux-operator resume rsip &lt;name&gt;</code>: Resumes the reconciliation of the ResourceSetInputProvider resource in the cluster.</li> <li><code>flux-operator suspend resource &lt;kind&gt;/&lt;name&gt;</code>: Suspends the reconciliation of the Flux resource in the cluster.</li> <li><code>flux-operator resume resource &lt;kind&gt;/&lt;name&gt;</code>: Resumes the reconciliation of the Flux resource in the cluster.</li> </ul> <p>Arguments:</p> <ul> <li><code>-n, --namespace</code>: Specifies the namespace scope of the command.</li> <li><code>--wait</code>: On resume, waits for the reconciliation to complete before returning.</li> </ul>"},{"location":"operator/cli/#delete-commands","title":"Delete Commands","text":"<p>The <code>flux-operator delete</code> commands are used to delete the Flux Operator resources from the cluster.</p> <p>The following commands are available:</p> <ul> <li><code>flux-operator delete instance &lt;name&gt;</code>: Deletes the FluxInstance resource from the cluster.</li> <li><code>flux-operator delete rset &lt;name&gt;</code>: Deletes the ResourceSet resource from the cluster.</li> <li><code>flux-operator delete rsip &lt;name&gt;</code>: Deletes the ResourceSetInputProvider resource from the cluster.</li> </ul> <p>Arguments:</p> <ul> <li><code>-n, --namespace</code>: Specifies the namespace scope of the command.</li> <li><code>--wait</code>: Waits for the resource to be deleted before returning (enabled by default).</li> <li><code>--with-suspend</code>: Suspends the resource before deleting it (leaving the managed resources in-place).</li> </ul>"},{"location":"operator/cli/#statistics-command","title":"Statistics Command","text":"<p>This command is used to retrieve statistics about the Flux resources including their reconciliation status and the amount of cumulative storage used for each source type.</p> <ul> <li><code>flux-operator stats</code>: Displays statistics about the Flux resources in the cluster.</li> </ul>"},{"location":"operator/cli/#trace-command","title":"Trace Command","text":"<p>This command is used to trace Kubernetes objects throughout the GitOps delivery pipeline to identify which Flux reconciler manages them and from which source they originate.</p> <ul> <li><code>flux-operator trace &lt;kind&gt;/&lt;name&gt;</code>: Trace a Kubernetes object to its Flux reconciler and source.</li> </ul> <p>Arguments:</p> <ul> <li><code>-n, --namespace</code>: Specifies the namespace scope of the command.</li> </ul>"},{"location":"operator/cli/#tree-commands","title":"Tree Commands","text":"<p>The <code>flux-operator tree</code> commands are used to visualize the Flux-managed Kubernetes objects in a tree format by recursively traversing the Flux resources such as ResourceSets, Kustomizations and HelmReleases.</p> <p>The following commands are available:</p> <ul> <li><code>flux-operator tree rset &lt;name&gt;</code>: Print a tree view of the ResourceSet managed objects.</li> <li><code>flux-operator tree ks &lt;name&gt;</code>: Print a tree view of the Flux Kustomization managed objects.</li> <li><code>flux-operator tree hr &lt;name&gt;</code>: Print a tree view of the Flux HelmRelease managed objects.</li> </ul> <p>Arguments:</p> <ul> <li><code>-n, --namespace</code>: Specifies the namespace scope of the command.</li> </ul>"},{"location":"operator/cli/#wait-commands","title":"Wait Commands","text":"<p>The <code>flux-operator wait</code> commands are used to wait for Flux Operator resources to become ready. These commands will poll the resource status until it reaches a ready state or times out. If the resource is not created or its status is not ready within the specified timeout, the command will return an error.</p> <p>The following commands are available:</p> <ul> <li><code>flux-operator wait instance &lt;name&gt;</code>: Wait for a FluxInstance to become ready.</li> <li><code>flux-operator wait rset &lt;name&gt;</code>: Wait for a ResourceSet to become ready.</li> <li><code>flux-operator wait rsip &lt;name&gt;</code>: Wait for a ResourceSetInputProvider to become ready.</li> </ul> <p>Arguments:</p> <ul> <li><code>-n, --namespace</code>: Specifies the namespace scope of the command.</li> <li><code>--timeout</code>: The length of time to wait before giving up (default 1m).</li> </ul>"},{"location":"operator/cli/#create-secret-commands","title":"Create Secret Commands","text":"<p>The <code>flux-operator create secret</code> commands are used to create Kubernetes secrets specific to Flux. These commands can be used to create or update secrets directly in the cluster, or to export them in YAML format.</p> <p>The following commands are available:</p> <ul> <li><code>flux-operator create secret basic-auth</code>: Create a Kubernetes Secret containing basic auth credentials.</li> <li><code>--username</code>: Set the username for basic authentication (required).</li> <li><code>--password</code>: Set the password for basic authentication (required if --password-stdin is not used).</li> <li><code>--password-stdin</code>: Read the password from stdin.</li> <li><code>flux-operator create secret githubapp</code>: Create a Kubernetes Secret containing GitHub App credentials.</li> <li><code>--app-id</code>: GitHub App ID (required).</li> <li><code>--app-installation-id</code>: GitHub App Installation ID (required).</li> <li><code>--app-private-key-file</code>: Path to GitHub App private key file (required).</li> <li><code>--app-base-url</code>: GitHub base URL for GitHub Enterprise Server (optional).</li> <li><code>flux-operator create secret proxy</code>: Create a Kubernetes Secret containing HTTP/S proxy credentials.</li> <li><code>--address</code>: Set the proxy address (required).</li> <li><code>--username</code>: Set the username for proxy authentication (optional).</li> <li><code>--password</code>: Set the password for proxy authentication (optional).</li> <li><code>--password-stdin</code>: Read the password from stdin.</li> <li><code>flux-operator create secret registry</code>: Create a Kubernetes Secret containing registry credentials.</li> <li><code>--server</code>: Set the registry server (required).</li> <li><code>--username</code>: Set the username for registry authentication (required).</li> <li><code>--password</code>: Set the password for registry authentication (required if --password-stdin is not used).</li> <li><code>--password-stdin</code>: Read the password from stdin.</li> <li><code>flux-operator create secret sops</code>: Create a Kubernetes Secret containing SOPS decryption keys.</li> <li><code>--age-key-file</code>: Path to Age private key file (can be used multiple times).</li> <li><code>--gpg-key-file</code>: Path to GPG private key file (can be used multiple times).</li> <li><code>--age-key-stdin</code>: Read Age private key from stdin.</li> <li><code>--gpg-key-stdin</code>: Read GPG private key from stdin.</li> <li><code>flux-operator create secret ssh</code>: Create a Kubernetes Secret containing SSH credentials.</li> <li><code>--private-key-file</code>: Path to SSH private key file (required).</li> <li><code>--public-key-file</code>: Path to SSH public key file (optional).</li> <li><code>--knownhosts-file</code>: Path to SSH known_hosts file (required).</li> <li><code>--password</code>: Password for encrypted SSH private key (optional).</li> <li><code>--password-stdin</code>: Read the password from stdin.</li> <li><code>flux-operator create secret tls</code>: Create a Kubernetes Secret containing TLS certs.</li> <li><code>--tls-crt-file</code>: Path to TLS client certificate file.</li> <li><code>--tls-key-file</code>: Path to TLS client private key file.</li> <li><code>--ca-crt-file</code>: Path to CA certificate file (optional).</li> </ul> <p>Arguments:</p> <ul> <li><code>-n, --namespace</code>: Specifies the namespace to create the secret in.</li> <li><code>--annotation</code>: Set annotations on the resource (can specify multiple annotations with commas: annotation1=value1,annotation2=value2).</li> <li><code>--label</code>: Set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2).</li> <li><code>--immutable</code>: Set the immutable flag on the Secret.</li> <li><code>--export</code>: Export secret in YAML format to stdout instead of creating it in the cluster.</li> </ul>"},{"location":"operator/cli/#version-command","title":"Version Command","text":"<p>This command is used to display the version of the CLI, of the Flux Operator and of the Flux distribution running in the cluster.</p> <ul> <li><code>flux-operator version</code>: Displays the version information for the CLI and the Flux Operator.<ul> <li><code>--client</code>:  If true, shows the client version only (no server required).</li> </ul> </li> </ul>"},{"location":"operator/cli/#install-command","title":"Install Command","text":"<p>The <code>flux-operator install</code> command provides a quick way to bootstrap a Kubernetes cluster with the Flux Operator and a Flux instance.</p> <p>This command performs the following steps:</p> <ol> <li>Downloads the Flux Operator distribution artifact from <code>oci://ghcr.io/controlplaneio-fluxcd/flux-operator-manifests</code>.</li> <li>Installs the Flux Operator in the <code>flux-system</code> namespace and waits for it to become ready.</li> <li>Installs the Flux instance in the <code>flux-system</code> namespace according to the provided configuration.</li> <li>Configures the pull secret for the instance sync source if credentials are provided.</li> <li>Configures Flux to bootstrap the cluster from a Git repository or OCI repository if a sync URL is provided.</li> <li>Configures automatic updates of the Flux Operator from the distribution artifact.</li> </ol> <p>This command is intended for development and testing purposes. On production environments, it is recommended to follow the installation guide.</p> <ul> <li><code>flux-operator install</code>: Installs the Flux Operator and a Flux instance in the cluster.<ul> <li><code>--instance-file, -f</code>: Path to FluxInstance YAML file (local file, OCI or HTTPS URL).</li> <li><code>--instance-distribution-version</code>: Flux distribution version.</li> <li><code>--instance-distribution-registry</code>: Container registry to pull Flux images from.</li> <li><code>--instance-distribution-artifact</code>: OCI artifact containing the Flux distribution manifests.</li> <li><code>--instance-components</code>: List of Flux components to install.</li> <li><code>--instance-components-extra</code>: Additional Flux components to install on top of the default set.</li> <li><code>--instance-cluster-type</code>: Cluster type (kubernetes, openshift, aws, azure, gcp).</li> <li><code>--instance-cluster-size</code>: Cluster size profile for vertical scaling (small, medium, large).</li> <li><code>--instance-cluster-domain</code>: Cluster domain used for generating the FQDN of services.</li> <li><code>--instance-cluster-multitenant</code>: Enable multitenant lockdown for Flux controllers.</li> <li><code>--instance-cluster-network-policy</code>: Restrict network access to the current namespace.</li> <li><code>--instance-sync-url</code>: URL of the source for cluster sync (Git repository URL or OCI repository address).</li> <li><code>--instance-sync-ref</code>: Source reference for cluster sync (Git ref name or OCI tag).</li> <li><code>--instance-sync-path</code>: Path to the manifests directory in the source.</li> <li><code>--instance-sync-creds</code>: Credentials for the source in the format <code>username:token</code>.</li> <li><code>--auto-update</code>: Enable automatic updates of the Flux Operator from the distribution artifact.</li> </ul> </li> </ul>"},{"location":"operator/cli/#uninstall-command","title":"Uninstall Command","text":"<p>The <code>flux-operator uninstall</code> command safely removes the Flux Operator and Flux instance from the cluster.</p> <p>This command performs the following steps:</p> <ol> <li>Deletes the cluster role bindings of Flux Operator and Flux controllers.</li> <li>Deletes the deployments of Flux Operator and Flux controllers.</li> <li>Removes finalizers from Flux Operator and Flux custom resources.</li> <li>Deletes the CustomResourceDefinitions of Flux Operator and Flux.</li> <li> <p>Deletes the namespace where Flux Operator is installed (unless <code>--keep-namespace</code> is specified).</p> </li> <li> <p><code>flux-operator -n flux-system uninstall</code>: Uninstalls the Flux Operator and Flux instance from the cluster.</p> <ul> <li><code>--keep-namespace</code>: Keep the namespace after uninstalling Flux Operator and Flux instance.</li> </ul> </li> </ol> <p>Note that the <code>uninstall</code> command will not delete any Kubernetes objects or Helm releases that were reconciled on the cluster by Flux. It is safe to run this command and re-install Flux Operator later to resume managing the existing resources.</p>"},{"location":"operator/flux-bootstrap-migration/","title":"Flux Bootstrap Migration","text":"<p>Assuming you have a cluster bootstrapped with the Flux CLI or the Terraform Provider, you can migrate to an operator-managed Flux with zero downtime.</p>"},{"location":"operator/flux-bootstrap-migration/#install-the-flux-operator","title":"Install the Flux Operator","text":"<p>Install the Flux Operator in the same namespace where Flux is deployed, for example using Helm:</p> <pre><code>helm install flux-operator oci://ghcr.io/controlplaneio-fluxcd/charts/flux-operator \\\n  --namespace flux-system\n</code></pre> <p>Or by using an alternative installation method described in the installation guide.</p>"},{"location":"operator/flux-bootstrap-migration/#create-a-flux-instance","title":"Create a Flux Instance","text":"<p>Create a <code>FluxInstance</code> resource named flux in the <code>flux-system</code> namespace using the same configuration as for <code>flux bootstrap</code>. </p> <p>For example, if you have bootstrapped the cluster with the following command:</p> <pre><code>flux bootstrap github \\\n  --owner=my-org \\\n  --repository=my-fleet \\\n  --branch=main \\\n  --path=clusters/my-cluster\n</code></pre> <p>The equivalent <code>FluxInstance</code> configuration would look like this:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\nspec:\n  distribution:\n    version: \"2.7.x\"\n    registry: \"ghcr.io/fluxcd\"\n  components:\n    - source-controller\n    - kustomize-controller\n    - helm-controller\n    - notification-controller\n  cluster:\n    type: kubernetes\n    multitenant: false\n    networkPolicy: true\n    domain: \"cluster.local\"\n  sync:\n    kind: GitRepository\n    url: \"ssh://git@github.com/my-org/my-fleet.git\"\n    ref: \"refs/heads/main\"\n    path: \"clusters/my-cluster\"\n    pullSecret: \"flux-system\"\n</code></pre> <p>Kustomize patches</p> <p>Note that if you have customized the Flux manifests, you should copy the Kustomize patches from <code>flux-system/kustomization.yaml</code> in the <code>FluxInstance</code> under <code>.spec.kustomize.patches</code>. For more information, see the instance customization guide.</p> <p>Apply the <code>FluxInstance</code> resource to the cluster:</p> <pre><code>kubectl apply -f flux-instance.yaml\n</code></pre> <p>Once the resource is reconciled, the operator will take over the management of the Flux components, the Flux GitRepository and Kustomization.</p> <p>To verify that the migration was successful, check the status of the <code>FluxInstance</code>:</p> <pre><code>kubectl -n flux-system get fluxinstance flux\n</code></pre> <p>Running the trace command should result in a \"Not managed by Flux\" message:</p> <pre><code>flux trace kustomization flux-system\n</code></pre>"},{"location":"operator/flux-bootstrap-migration/#cleanup-the-repository","title":"Cleanup the repository","text":"<p>To finalize the migration, remove the Flux manifests from the Git repository:</p> <ol> <li>Checkout the main branch of the Flux repository that was used to bootstrap the cluster.</li> <li>Delete the <code>flux-system</code> directory from the repository <code>clusters/my-cluster</code> directory.</li> <li>Optionally, place the <code>FluxInstance</code> YAML manifest in the <code>clusters/my-cluster</code> directory.</li> <li>Commit and push the changes to the Flux repository.</li> </ol>"},{"location":"operator/flux-bootstrap-migration/#automating-flux-operator-upgrades","title":"Automating Flux Operator upgrades","text":"<p>If the Flux Operator is installed with Helm, you can automate the upgrade process using a Flux <code>HelmRelease</code>:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSet\nmetadata:\n  name: flux-operator\n  namespace: flux-system\nspec:\n  inputs:\n    - version: \"*\"\n  resources:\n   - apiVersion: source.toolkit.fluxcd.io/v1\n     kind: OCIRepository\n     metadata:\n      name: &lt;&lt; inputs.provider.name &gt;&gt;\n      namespace: &lt;&lt; inputs.provider.namespace &gt;&gt;\n     spec:\n      interval: 30m\n      url: oci://ghcr.io/controlplaneio-fluxcd/charts/flux-operator\n      layerSelector:\n        mediaType: \"application/vnd.cncf.helm.chart.content.v1.tar+gzip\"\n        operation: copy\n      ref:\n        semver: &lt;&lt; inputs.version | quote &gt;&gt;\n   - apiVersion: helm.toolkit.fluxcd.io/v2\n     kind: HelmRelease\n     metadata:\n        name: &lt;&lt; inputs.provider.name &gt;&gt;\n        namespace: &lt;&lt; inputs.provider.namespace &gt;&gt;\n     spec:\n      interval: 30m\n      releaseName: &lt;&lt; inputs.provider.name &gt;&gt;\n      serviceAccountName: &lt;&lt; inputs.provider.name &gt;&gt;\n      chartRef:\n        kind: OCIRepository\n        name: &lt;&lt; inputs.provider.name &gt;&gt;\n</code></pre> <p>Commit and push the manifest to the Flux repository, and the operator will be automatically upgraded when a new Helm chart version is released.</p>"},{"location":"operator/flux-bootstrap-migration/#migration-from-git-to-oci-artifacts","title":"Migration from Git to OCI artifacts","text":"<p>To decouple the Flux reconciliation from Git and use OCI artifacts as the delivery mechanism for the cluster desired state, the following procedure can be followed:</p> <ol> <li>Migrate the Flux custom resources such as Flux <code>Kustomization</code> and <code>HelmRelease</code> to use <code>OCIRepository</code> as <code>sourceRef</code>.</li> <li>Create a repository in a container registry that both the CI tooling and Flux can access.</li> <li>Create a CI workflow that reacts to changes in the Git repository and publishes the Kubernetes manifests    to the OCI repository.</li> <li>Configure the <code>FluxInstance</code> to use the OCI repository as the source of the cluster's desired state.</li> </ol> <p>To exemplify the migration, we will use GitHub but the same procedure can be applied to GitLab, Azure DevOps and other providers.</p>"},{"location":"operator/flux-bootstrap-migration/#prepare-the-flux-manifests","title":"Prepare the Flux manifests","text":"<p>Create a new branch called <code>oci-artifacts</code> in the Git repository that was used for bootstrap.</p> <p>Update all the Flux <code>Kustomization</code> manifests to use <code>OCIRepository</code> instead of <code>GitRepository</code>:</p> <pre><code>apiVersion: kustomize.toolkit.fluxcd.io/v1\nkind: Kustomization\nspec:\n  sourceRef:\n    kind: OCIRepository\n    name: flux-system\n</code></pre> <p>If you have <code>HelmRelease</code> resources using a <code>GitRepository</code>, update them to use <code>OCIRepository</code>.</p> <p>Commit and push the changes to the <code>oci-artifacts</code> branch.</p>"},{"location":"operator/flux-bootstrap-migration/#publish-the-manifests-to-the-oci-repository","title":"Publish the manifests to the OCI repository","text":"<p>Create a GitHub Actions workflow that uses the Flux CLI to publish the manifests to GitHub Container Registry:</p> <pre><code>name: publish-artifact\n\non:\n  workflow_dispatch:\n  push:\n    branches:\n      - 'main'\n      - 'oci-artifacts'\n\npermissions:\n  packages: write\n\njobs:\n  flux-push:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Setup Flux CLI\n        uses: fluxcd/flux2/action@main       \n      - name: Push immutable artifact\n        run: |\n          flux push artifact \\\n            oci://ghcr.io/${{ github.repository }}/manifests:$(git rev-parse --short HEAD) \\\n            --source=\"$(git config --get remote.origin.url)\" \\\n            --revision=\"$(git branch --show-current)@sha1:$(git rev-parse HEAD)\" \\\n            --creds flux:${{ secrets.GITHUB_TOKEN }} \\\n            --path=\"./\"\n      - name: Tag artifact as latest\n        run: |\n          flux tag artifact \\\n            oci://ghcr.io/${{ github.repository }}/manifests:$(git rev-parse --short HEAD) \\\n            --creds flux:${{ secrets.GITHUB_TOKEN }} \\\n            --tag latest\n</code></pre> <p>Commit and push the workflow to the <code>oci-artifacts</code> branch.</p> <p>Run the workflow manually in the GitHub UI and verify that the manifests are published to the GitHub Container Registry with:</p> <pre><code>flux pull artifact oci://ghcr.io/my-org/my-fleet/manifests:latest \\\n    --creds flux:${GITHUB_TOKEN} \\\n    --output-dir ./manifests\n</code></pre>"},{"location":"operator/flux-bootstrap-migration/#create-the-image-pull-secret","title":"Create the image pull secret","text":"<p>Create an image pull secret in the <code>flux-system</code> namespace that contains a GitHub token with read access to the GitHub Container Registry:</p> <pre><code>flux create secret oci ghcr-auth \\\n    --url=ghcr.io \\\n    --username=flux \\\n    --password=${GITHUB_TOKEN}\n</code></pre>"},{"location":"operator/flux-bootstrap-migration/#update-the-fluxinstance-to-use-oci-artifacts","title":"Update the FluxInstance to use OCI artifacts","text":"<p>Update the <code>FluxInstance</code> to use <code>OCIRepository</code> and the image pull secret:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\nspec:\n  sync:\n    kind: OCIRepository\n    url: \"oci://ghcr.io/my-org/my-fleet/manifests\"\n    ref: \"latest\"\n    path: \"clusters/my-cluster\"\n    pullSecret: \"ghcr-auth\"\n</code></pre> <p>Commit and push the <code>FluxInstance</code> changes to the <code>oci-artifacts</code> branch and wait for the GitHub workflow to publish the manifests.</p> <p>Apply the <code>FluxInstance</code> to the cluster and verify that the operator has reconfigured Flux to use the <code>OCIRepository</code>:</p> <pre><code>kubectl apply -f flux-instance.yaml\nkubectl -n flux-system wait fluxinstance/flux --for=condition=Ready\n\nflux get source oci flux-system\nflux get kustomization flux-system\n</code></pre> <p>Finally, merge the <code>oci-artifacts</code> branch into <code>main</code> and delete the <code>oci-artifacts</code> branch. The GitHub Actions workflow will continue to publish the manifests to the GitHub Container Registry on every push to the <code>main</code> branch and Flux will reconcile the cluster state accordingly.</p>"},{"location":"operator/flux-config/","title":"Flux Controllers Configuration","text":"<p>The Flux Operator comes with a Kubernetes CRD called FluxInstance. A single custom resource of this kind can exist in a Kubernetes cluster with the name flux that must be created in the same namespace where the operator is deployed.</p> <p>The <code>FluxInstance</code> resource is used to install and configure the automated update of the Flux distribution.</p>"},{"location":"operator/flux-config/#default-configuration","title":"Default configuration","text":"<p>Example of a minimal <code>FluxInstance</code> resource:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\nspec:\n  distribution:\n    version: \"2.7.x\"\n    registry: \"ghcr.io/fluxcd\"\n    artifact: \"oci://ghcr.io/controlplaneio-fluxcd/flux-operator-manifests\"\n  cluster:\n    type: kubernetes\n    size: medium\n</code></pre> <p>Save the above manifest to a file and apply it with <code>kubectl</code>:</p> <pre><code>kubectl apply -f flux-instance.yaml\n</code></pre> <p>The operator will reconcile the <code>FluxInstance</code> resource and install the latest upstream Flux version in the <code>2.7</code> range with the specified components. To verify the installation status:</p> <pre><code>kubectl -n flux-system get fluxinstance flux\n</code></pre> <p>Every hour, the operator will check for Flux patch releases and apply them if available. To make the operator check for updates immediately:</p> <pre><code>kubectl -n flux-system annotate --overwrite \\\n  fluxinstance flux reconcile.fluxcd.io/requestedAt=\"$(date +%s)\"\n</code></pre> <p>To uninstall the Flux instance:</p> <pre><code>kubectl -n flux-system delete fluxinstance flux\n</code></pre>"},{"location":"operator/flux-config/#enterprise-distribution-configuration","title":"Enterprise Distribution configuration","text":"<p>To deploy the enterprise distribution of Flux, point the operator to the ControlPlane registry:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\nspec:\n  distribution:\n    version: \"2.7.x\"\n    registry: \"ghcr.io/controlplaneio-fluxcd/distroless\"\n    imagePullSecret: \"flux-enterprise-auth\"\n    artifact: \"oci://ghcr.io/controlplaneio-fluxcd/flux-operator-manifests\"\n</code></pre> <p>Automated CVE patching</p> <p>The operator will check for updates to the ControlPlane distribution by pulling the OCI artifact from <code>ghcr.io/controlplaneio-fluxcd</code> registry every hour. If a new patch version is available, the operator will update the Flux components by pinning the container images to the latest digest published in the ControlPlane registry.</p> <p>To access the ControlPlane registry, the <code>flux-enterprise-auth</code> Kubernetes secret must be created in the <code>flux-system</code> namespace and should contain the credentials to pull the enterprise images:</p> <pre><code>kubectl create secret docker-registry flux-enterprise-auth \\\n  --namespace flux-system \\\n  --docker-server=ghcr.io \\\n  --docker-username=flux \\\n  --docker-password=$ENTERPRISE_TOKEN\n</code></pre>"},{"location":"operator/flux-config/#custom-configuration","title":"Custom configuration","text":"<p>The Flux distribution can be customized by specifying the components to install, the cluster type, multitenancy, network policy, storage class and size, and kustomize patches.</p> <p>For example, to install the latest Flux version with the multi-tenancy lockdown enabled and persistent storage for the source-controller:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\n  annotations:\n    fluxcd.controlplane.io/reconcileEvery: \"1h\"\n    fluxcd.controlplane.io/reconcileTimeout: \"5m\"\nspec:\n  distribution:\n    version: \"2.7.x\"\n    registry: \"ghcr.io/fluxcd\"\n    artifact: \"oci://ghcr.io/controlplaneio-fluxcd/flux-operator-manifests\"\n  components:\n    - source-controller\n    - kustomize-controller\n    - helm-controller\n    - notification-controller\n    - image-reflector-controller\n    - image-automation-controller\n    - source-watcher\n  cluster:\n    type: kubernetes\n    size: large\n    multitenant: true\n    networkPolicy: true\n    domain: \"cluster.local\"\n  storage:\n    class: \"standard\"\n    size: \"10Gi\"\n  kustomize:\n    patches:\n      - target:\n          kind: Deployment\n        patch: |\n          - op: replace\n            path: /spec/template/spec/nodeSelector\n            value:\n              kubernetes.io/os: linux\n          - op: add\n            path: /spec/template/spec/tolerations\n            value:\n              - key: \"CriticalAddonsOnly\"\n                operator: \"Exists\"\n</code></pre> <p>To find out more about the available configuration options, refer to the FluxInstance API reference.</p>"},{"location":"operator/flux-kustomize/","title":"Flux Instance Customization","text":"<p>The FluxInstance allows for the customization of the Flux controller deployments and the Flux sync custom resources using Kustomize patches.</p>"},{"location":"operator/flux-kustomize/#kustomize-patches-usage","title":"Kustomize patches usage","text":"<p>You can make changes to all controllers using a single patch or target a specific controller:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nspec:\n  kustomize:\n    patches:\n      # target all controller deployments\n      - patch: |\n          # strategic merge or JSON patch\n        target:\n          kind: Deployment\n      # target multiple controller deployments by name\n      - patch: |\n          # strategic merge or JSON patch      \n        target:\n          kind: Deployment\n          name: \"(kustomize-controller|helm-controller)\"\n      # target a single controller service account by name\n      - patch: |\n          # strategic merge or JSON patch     \n        target:\n          kind: ServiceAccount\n          name: \"source-controller\"\n</code></pre> <p>Target namespace</p> <p>Note that the <code>patch.target</code> must not contain a <code>namespace</code> field, all patches are applied to the instance namespace.</p>"},{"location":"operator/flux-kustomize/#verifying-patches","title":"Verifying patches","text":"<p>To verify the patches, you can use The Flux Operator CLI to build the <code>FluxInstance</code> locally and print the generated manifests.</p> <pre><code>flux-operator build instance -f flux.yaml\n</code></pre> <p>See the Flux Operator CLI documentation for more details on how to use the CLI.</p>"},{"location":"operator/flux-kustomize/#examples","title":"Examples","text":"<p>The following examples demonstrate how to customize the Flux manifests.</p>"},{"location":"operator/flux-kustomize/#increase-concurrency-and-resources-limits","title":"Increase concurrency and resources limits","text":"<pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nspec:\n  kustomize:\n    patches:\n      - patch: |\n          - op: add\n            path: /spec/template/spec/containers/0/args/-\n            value: --concurrent=10\n          - op: add\n            path: /spec/template/spec/containers/0/args/-\n            value: --requeue-dependency=5s \n          - op: replace\n            path: /spec/template/spec/containers/0/resources/limits\n            value:\n              cpu: 2000m\n              memory: 2048Mi\n        target:\n          kind: Deployment\n          name: \"(kustomize-controller|helm-controller|source-controller)\"\n</code></pre>"},{"location":"operator/flux-kustomize/#node-affinity-and-tolerations","title":"Node affinity and tolerations","text":"<pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nspec:\n  kustomize:\n    patches:\n      - patch: |\n          apiVersion: apps/v1\n          kind: Deployment\n          metadata:\n            name: all\n          spec:\n            template:\n              metadata:\n                annotations:\n                  cluster-autoscaler.kubernetes.io/safe-to-evict: \"true\"\n              spec:\n                affinity:\n                  nodeAffinity:\n                    requiredDuringSchedulingIgnoredDuringExecution:\n                      nodeSelectorTerms:\n                        - matchExpressions:\n                            - key: role\n                              operator: In\n                              values:\n                                - flux\n                tolerations:\n                  - effect: NoSchedule\n                    key: role\n                    operator: Equal\n                    value: flux      \n        target:\n          kind: Deployment\n</code></pre>"},{"location":"operator/flux-kustomize/#https-proxy","title":"HTTP/S Proxy","text":"<pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nspec:\n  kustomize:\n    patches:\n      - patch: |\n          apiVersion: apps/v1\n          kind: Deployment\n          metadata:\n            name: all\n          spec:\n            template:\n              spec:\n                containers:\n                  - name: manager\n                    env:\n                      - name: \"HTTPS_PROXY\"\n                        value: \"https://proxy.example.com\"\n                      - name: \"NO_PROXY\"\n                        value: \".cluster.local.,.cluster.local,.svc\"      \n        target:\n          kind: Deployment\n</code></pre>"},{"location":"operator/flux-kustomize/#cluster-sync-semver-range","title":"Cluster sync semver range","text":"<pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nspec:\n  kustomize:\n    patches:\n      - patch: |\n          - op: replace\n            path: /spec/ref\n            value:\n              semver: \"&gt;=1.0.0-0\"\n        target:\n          kind: (GitRepository|OCIRepository)\n</code></pre>"},{"location":"operator/flux-kustomize/#cluster-sync-sops-decryption","title":"Cluster sync SOPS decryption","text":"<pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nspec:\n  kustomize:\n    patches:\n      - patch: |\n          - op: add\n            path: /spec/decryption\n            value:\n              provider: sops\n              secretRef:\n                name: flux-sops\n        target:\n          kind: Kustomization\n</code></pre>"},{"location":"operator/flux-kustomize/#cluster-sync-gitrepository-verification","title":"Cluster sync GitRepository verification","text":"<pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nspec:\n  kustomize:\n    patches:\n      - patch: |\n          - op: add\n            path: /spec/verify\n            value:\n              mode: HEAD\n              secretRef:\n                name: pgp-public-keys\n        target:\n          kind: GitRepository\n</code></pre>"},{"location":"operator/flux-kustomize/#cluster-sync-ocirepository-keyless-verification","title":"Cluster sync OCIRepository keyless verification","text":"<pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nspec:\n  kustomize:\n    patches:\n      - patch: |\n          - op: add\n            path: /spec/verify\n            value:\n              provider: cosign\n              matchOIDCIdentity:\n              - issuer: ^https://token\\.actions\\.githubusercontent\\.com$\n                subject: ^https://github\\.com/&lt;owner&gt;/&lt;repo&gt;/\\.github/workflows/push-flux-system\\.yml@refs/heads/main$\n        target:\n          kind: OCIRepository\n</code></pre> <p>For more examples, refer to the Flux bootstrap documentation.</p>"},{"location":"operator/flux-sharding/","title":"Flux Sharding Configuration","text":"<p>The Flux Operator supports sharding the workload across multiple instances of Flux controllers allowing you to horizontally scale the reconciliation of resources.</p> <p>This feature is useful when you have a large number of resources to manage and want to distribute the workload across multiple controller replicas. Another use case is to isolate the resources reconciliation for different teams and environments.</p>"},{"location":"operator/flux-sharding/#sharding-configuration","title":"Sharding Configuration","text":"<p>To enable sharding, add the following configuration to the <code>FluxInstance</code>:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\nspec:\n  distribution:\n    version: \"2.7.x\"\n    registry: \"ghcr.io/fluxcd\"\n  cluster:\n    size: large\n  sharding:\n    key: \"sharding.fluxcd.io/key\"\n    shards:\n      - \"shard1\"\n      - \"shard2\"\n</code></pre> <p>The <code>.spec.sharding.key</code> field specifies the sharding key label to use for the Flux controllers and the <code>.spec.sharding.shards</code> field specifies the list of shards.</p> <p>Based on the above configuration, the Flux Operator will create a separate set of controllers for each shard and will configure the controllers to reconcile only the resources that have the sharding key label set to the shard name.</p> <p>To list the Flux controllers and their shards:</p> <pre><code>$ kubectl -n flux-system get deploy -l app.kubernetes.io/part-of=flux\nNAME                          READY   UP-TO-DATE   AVAILABLE   AGE\nhelm-controller               1/1     1            1           77s\nhelm-controller-shard1        1/1     1            1           77s\nhelm-controller-shard2        1/1     1            1           77s\nkustomize-controller          1/1     1            1           77s\nkustomize-controller-shard1   1/1     1            1           77s\nkustomize-controller-shard2   1/1     1            1           77s\nnotification-controller       1/1     1            1           77s\nsource-controller             1/1     1            1           77s\nsource-controller-shard1      1/1     1            1           77s\nsource-controller-shard2      1/1     1            1           77s\n</code></pre> <p>Note that only the <code>source-controller</code>, <code>kustomize-controller</code> and <code>helm-controller</code> controllers support sharding.</p> <p>It is recommended to use the main controller instances to reconcile the cluster add-ons and the sharded controllers to reconcile the application workloads belonging to tenants.</p>"},{"location":"operator/flux-sharding/#sharding-with-persistent-storage","title":"Sharding with Persistent Storage","text":"<p>Enabling persistent storage for source-controller can speed up startup time and reduce the network traffic after a restart, as the controller will not need to re-download all the artifacts from the source repositories.</p> <p>To enable persistent storage for the source-controller shards, you can add the following configuration to the <code>FluxInstance</code>:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\nspec:\n  distribution:\n    version: \"2.7.x\"\n    registry: \"ghcr.io/fluxcd\"\n  cluster:\n    size: large\n  storage:\n    class: \"standard\"\n    size: \"10Gi\"\n  sharding:\n    key: \"sharding.fluxcd.io/key\"\n    shards:\n      - \"shard1\"\n      - \"shard2\"\n    storage: \"persistent\"\n</code></pre> <p>The operator will create a <code>PersistentVolumeClaim</code> for each shard including the main source-controller instance:</p> <pre><code>$ kubectl -n flux-system get pvc\nNAME                          STATUS\nsource-controller             Bound \nsource-controller-shard1      Bound\nsource-controller-shard2      Bound\n</code></pre>"},{"location":"operator/flux-sharding/#distributing-resources-across-shards","title":"Distributing Resources Across Shards","text":"<p>To assign a group of Flux resources to a particular shard, add the sharding key label to the resources, using the shard name as the value.</p> <p>Note that the Flux Kustomizations and HelmReleases must have the sharding key label set to the same shard name as their source GitRepository, OCIRepository, HelmRepository or HelmChart.</p>"},{"location":"operator/flux-sharding/#examples","title":"Examples","text":"<p>To assign a Flux Kustomization and its GitRepository source to the <code>shard1</code> controllers:</p> <pre><code>---\napiVersion: source.toolkit.fluxcd.io/v1\nkind: GitRepository\nmetadata:\n  name: podinfo\n  namespace: default\n  labels:\n    sharding.fluxcd.io/key: shard1\nspec:\n  interval: 10m\n  url: https://github.com/stefanprodan/podinfo\n  ref:\n    semver: 6.x\n---\napiVersion: kustomize.toolkit.fluxcd.io/v1\nkind: Kustomization\nmetadata:\n  name: podinfo\n  namespace: default\n  labels:\n    sharding.fluxcd.io/key: shard1\nspec:\n  interval: 10m\n  targetNamespace: default\n  sourceRef:\n    kind: GitRepository\n    name: podinfo\n  path: ./kustomize\n  prune: true\n</code></pre> <p>To assign a Flux HelmRelease and its OCIRepository source to the <code>shard2</code> controllers:</p> <pre><code>---\napiVersion: source.toolkit.fluxcd.io/v1\nkind: OCIRepository\nmetadata:\n  name: podinfo\n  namespace: default\n  labels:\n    sharding.fluxcd.io/key: shard2\nspec:\n  interval: 10m\n  url: oci://ghcr.io/stefanprodan/charts/podinfo\n  layerSelector:\n    mediaType: \"application/vnd.cncf.helm.chart.content.v1.tar+gzip\"\n    operation: copy\n  ref:\n    semver: \"&gt;6.0.0\"\n---\napiVersion: helm.toolkit.fluxcd.io/v2\nkind: HelmRelease\nmetadata:\n  name: podinfo\n  namespace: default\n  labels:\n    sharding.fluxcd.io/key: shard2\nspec:\n  interval: 10m\n  releaseName: podinfo\n  chartRef:\n    kind: OCIRepository\n    name: podinfo\n</code></pre> <p>To assign a Flux HelmRelease and its HelmChart &amp; HelmRepository source to the <code>shard2</code> controllers:</p> <pre><code>---\napiVersion: source.toolkit.fluxcd.io/v1\nkind: HelmRepository\nmetadata:\n  name: podinfo\n  namespace: default\n  labels:\n    sharding.fluxcd.io/key: shard2\nspec:\n  interval: 1h\n  url: https://stefanprodan.github.io/podinfo\n---\napiVersion: source.toolkit.fluxcd.io/v1\nkind: HelmChart\nmetadata:\n  name: podinfo\n  namespace: default\n  labels:\n    sharding.fluxcd.io/key: shard2\nspec:\n  interval: 30m\n  chart: podinfo\n  version: 6.x\n  sourceRef:\n    kind: HelmRepository\n    name: podinfo\n---\napiVersion: helm.toolkit.fluxcd.io/v2\nkind: HelmRelease\nmetadata:\n  name: podinfo\n  namespace: default\n  labels:\n    sharding.fluxcd.io/key: shard2\nspec:\n  interval: 10m\n  releaseName: podinfo\n  chartRef:\n    kind: HelmChart\n    name: podinfo\n</code></pre> <p>To list all the resources assigned to a particular shard, you can pass the label selector to the <code>flux</code> CLI:</p> <pre><code>$ flux get all -A -l sharding.fluxcd.io/key=shard2\n\nNAME                    REVISION        SUSPENDED   READY   MESSAGE                                     \nhelmrepository/podinfo  sha256:3dfe15d8 False       True    stored artifact: revision 'sha256:3dfe15d8' \n\nNAME                REVISION    SUSPENDED   READY   MESSAGE                                     \nhelmchart/podinfo   6.7.0       False       True    pulled 'podinfo' chart with version '6.7.0' \n\nNAME                REVISION    SUSPENDED   READY   MESSAGE                                                                             \nhelmrelease/podinfo 6.7.0       False       True    Helm install succeeded for release podinfo-helm/podinfo.v1 with chart podinfo@6.7.0\n</code></pre>"},{"location":"operator/flux-sharding/#sharding-per-tenant","title":"Sharding per Tenant","text":"<p>To isolate the resources reconciliation for different teams and environments, you can use the sharding feature to create separate controllers for each tenant.</p>"},{"location":"operator/flux-sharding/#kustomization-example","title":"Kustomization Example","text":"<p>To assign all the resources of a particular tenant to a specific shard, add the sharding key label to the Flux Kustomization responsible for reconciling the tenant resources:</p> <pre><code>apiVersion: kustomize.toolkit.fluxcd.io/v1\nkind: Kustomization\nmetadata:\n  name: tenant1\n  namespace: tenant1\n  labels:\n    sharding.fluxcd.io/key: shard1\nspec:\n  commonMetadata:\n    labels:\n      sharding.fluxcd.io/key: shard1\n  interval: 10m\n  sourceRef:\n    kind: GitRepository\n    name: tenant1\n  path: ./deploy\n  prune: true\n</code></pre> <p>The <code>commonMetadata.labels</code> field is used to propagate the sharding key label to the resources reconciled by the Kustomization, such as HelmReleases, OCIRepositories, HelmCharts, HelmRepositories, etc.</p>"},{"location":"operator/flux-sharding/#clusterpolicy-example","title":"ClusterPolicy Example","text":"<p>Another option to assign all the resources of a particular tenant to a specific shard is to use a mutating webhook to inject the sharding key label in the resources created for the tenant in their namespace.</p> <p>Example Kyverno policy to inject the sharding key label to all the Flux resources created in the <code>tenant1</code> namespace:</p> <pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: tenant1-shard1\nspec:\n  rules:\n    - name: add-shard-label\n      match:\n        any:\n          - resources:\n              namespaces:\n                - tenant1\n              kinds:\n                - Kustomization\n                - HelmRelease\n                - HelmChart\n                - HelmRepository\n                - GitRepository\n                - OCIRepository\n                - Bucket\n      mutate:\n        patchStrategicMerge:\n          metadata:\n            labels:\n              sharding.fluxcd.io/key: shard1\n</code></pre>"},{"location":"operator/flux-sync/","title":"Flux Cluster Sync Configuration","text":"<p>The <code>FluxInstance</code> resource can be configured to instruct the operator to generate a Flux source (<code>GitRepository</code>, <code>OCIRepository</code> or <code>Bucket</code>) and a Flux <code>Kustomization</code> to sync the cluster state with the source repository.</p> <p>The Flux objects are created in the same namespace where the <code>FluxInstance</code> is deployed using the namespace name as the Flux source and Kustomization name. The naming convention matches the one used by <code>flux bootstrap</code> to ensure compatibility with upstream, and to allow transitioning a bootstrapped cluster to a <code>FluxInstance</code> managed one.</p>"},{"location":"operator/flux-sync/#sync-from-a-git-repository","title":"Sync from a Git Repository","text":"<p>To sync the cluster state from a Git repository, add the following configuration to the <code>FluxInstance</code>:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\nspec:\n  distribution:\n    version: \"2.7.x\"\n    registry: \"ghcr.io/fluxcd\"\n  sync:\n    kind: GitRepository\n    url: \"https://gitlab.com/my-org/my-fleet.git\"\n    ref: \"refs/heads/main\"\n    path: \"clusters/my-cluster\"\n    pullSecret: \"flux-system\"\n</code></pre> <p>If the source repository is private, the Kubernetes secret must be created in the <code>flux-system</code> namespace and should contain the credentials to clone the repository:</p> <pre><code>flux create secret git flux-system \\\n  --url=https://gitlab.com/my-org/my-fleet.git \\\n  --username=git \\\n  --password=$GITLAB_TOKEN\n</code></pre>"},{"location":"operator/flux-sync/#sync-from-a-git-repository-using-github-app-auth","title":"Sync from a Git Repository using GitHub App auth","text":"<p>To sync the cluster state from a GitHub repository using GitHub App authentication:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\nspec:\n  distribution:\n    version: \"2.7.x\"\n    registry: \"ghcr.io/fluxcd\"\n  components:\n    - source-controller\n    - kustomize-controller\n    - helm-controller\n    - notification-controller\n    - image-reflector-controller\n    - image-automation-controller\n  sync:\n    kind: GitRepository\n    provider: github\n    url: \"https://github.com/my-org/my-fleet.git\"\n    ref: \"refs/heads/main\"\n    path: \"clusters/my-cluster\"\n    pullSecret: \"flux-system\"\n</code></pre> <p>The Kubernetes secret must be created in the <code>flux-system</code> namespace and should contain the GitHub App private key:</p> <pre><code>flux create secret githubapp flux-system \\\n  --app-id=1 \\\n  --app-installation-id=2 \\\n  --app-private-key=./path/to/private-key-file.pem\n</code></pre> <p>GitHub App Support</p> <p>Note that GitHub App support was added in Flux v2.5.0 and Flux Operator v0.16.0. For more information on how to create a GitHub App see the Flux GitRepository API reference. </p>"},{"location":"operator/flux-sync/#sync-from-an-azure-devops-repository-using-aks-workload-identity","title":"Sync from an Azure DevOps Repository using AKS Workload Identity","text":"<p>To sync the cluster state from Azure DevOps using AKS Workload Identity:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\nspec:\n  distribution:\n    version: \"2.7.x\"\n    registry: \"ghcr.io/fluxcd\"\n  components:\n    - source-controller\n    - kustomize-controller\n    - helm-controller\n    - notification-controller\n  sync:\n    kind: GitRepository\n    provider: azure\n    url: \"https://dev.azure.com/my-org/_git/my-fleet\"\n    ref: \"refs/heads/main\"\n    path: \"clusters/my-cluster\"\n  kustomize:\n    patches:\n    - patch: |-\n        apiVersion: v1\n        kind: ServiceAccount\n        metadata:\n          name: source-controller\n          annotations:\n            azure.workload.identity/client-id: &lt;AZURE_CLIENT_ID&gt;\n            azure.workload.identity/tenant-id: &lt;AZURE_TENANT_ID&gt;\n      target:\n        kind: ServiceAccount\n        name: source-controller\n    - patch: |-\n        apiVersion: apps/v1\n        kind: Deployment\n        metadata:\n          name: source-controller\n        spec:\n          template:\n            metadata:\n              labels:\n                azure.workload.identity/use: \"true\" \n      target:\n        kind: Deployment\n        name: source-controller\n</code></pre> <p>Workload Identity Support</p> <p>Note that Azure DevOps Workload Identity support was added in Flux v2.5.0 and Flux Operator v0.18.0. For more information on how to configure Azure DevOps Workload Identity see the Flux GitRepository API reference. </p>"},{"location":"operator/flux-sync/#sync-from-a-container-registry","title":"Sync from a Container Registry","text":"<p>To sync the cluster state from a container registry where the Kubernetes manifests are pushed as OCI artifacts using <code>flux push artifact</code>:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\nspec:\n  distribution:\n    version: \"2.x\"\n    registry: \"ghcr.io/fluxcd\"\n  sync:\n    kind: OCIRepository\n    url: \"oci://ghcr.io/my-org/my-fleet-manifests\"\n    ref: \"latest\"\n    path: \"clusters/my-cluster\"\n    pullSecret: \"flux-system\"\n</code></pre> <p>If the container registry is private, the Kubernetes secret must be created in the same namespace where the <code>FluxInstance</code> is deployed, and be of type <code>kubernetes.io/dockerconfigjson</code>:</p> <pre><code>flux create secret oci flux-system \\\n  --namespace flux-system \\\n  --url=ghcr.io \\\n  --username=flux \\\n  --password=$GITHUB_TOKEN\n</code></pre>"},{"location":"operator/flux-sync/#sync-from-a-container-registry-using-workload-identity","title":"Sync from a Container Registry using Workload Identity","text":"<p>To sync the cluster state from a managed container registry, for example, AWS ECR:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\nspec:\n  distribution:\n    version: \"2.x\"\n    registry: \"ghcr.io/fluxcd\"\n  sync:\n    kind: OCIRepository\n    provider: aws\n    url: \"oci://&lt;account&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com/fleet-manifests\"\n    ref: \"latest\"\n    path: \"clusters/my-cluster\"\n</code></pre> <p>Note that you need to create an EKS Pod Identity association for the <code>source-controller</code> Service Account to allow it to pull images from the ECR repository.</p>"},{"location":"operator/flux-sync/#sync-from-a-bucket","title":"Sync from a Bucket","text":"<p>To sync the cluster state from an S3 bucket where the Kubernetes manifests are stored as YAML files:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\nspec:\n  distribution:\n    version: \"2.x\"\n    registry: \"ghcr.io/fluxcd\"\n  sync:\n    kind: Bucket\n    url: \"minio.my-org.com\"\n    ref: \"my-bucket-fleet\"\n    path: \"clusters/my-cluster\"\n    pullSecret: \"bucket-auth\"\n</code></pre> <p>The Kubernetes secret must be created in the same namespace where the FluxInstance is deployed, with the following keys:</p> <pre><code>kubectl create secret generic bucket-auth \\\n  --namespace flux-system \\\n  --from-literal=accesskey=my-accesskey \\\n  --from-literal=secretkey=my-secretkey\n</code></pre> <p>To find out more about the available configuration options, refer to the FluxInstance API reference.</p>"},{"location":"operator/fluxinstance/","title":"Flux Instance CRD","text":"<p>FluxInstance is a declarative API for the installation, configuration and automatic upgrade of the Flux distribution.</p> <p>A single custom resource of this kind can exist in a Kubernetes cluster with the name <code>flux</code> that must be created in the same namespace where the flux-operator is deployed.</p>"},{"location":"operator/fluxinstance/#example","title":"Example","text":"<p>The following example shows a FluxInstance custom resource that installs the upstream Flux distribution with all available components, and configures the flux-operator to automatically upgrade Flux  to the latest stable version:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxInstance\nmetadata:\n  name: flux\n  namespace: flux-system\n  annotations:\n    fluxcd.controlplane.io/reconcile: \"enabled\"\n    fluxcd.controlplane.io/reconcileEvery: \"1h\"\n    fluxcd.controlplane.io/reconcileTimeout: \"5m\"\nspec:\n  distribution:\n    version: \"2.x\"\n    registry: \"ghcr.io/fluxcd\"\n  components:\n    - source-controller\n    - kustomize-controller\n    - helm-controller\n    - notification-controller\n    - image-reflector-controller\n    - image-automation-controller\n  cluster:\n    type: kubernetes\n    size: medium\n    multitenant: false\n    networkPolicy: true\n    domain: \"cluster.local\"\n  storage:\n    class: \"standard\"\n    size: \"10Gi\"\n  commonMetadata:\n    labels:\n      app.kubernetes.io/name: flux\n  kustomize:\n    patches:\n      - target:\n          kind: Deployment\n        patch: |\n          - op: replace\n            path: /spec/template/spec/nodeSelector\n            value:\n              kubernetes.io/os: linux\n          - op: add\n            path: /spec/template/spec/tolerations\n            value:\n              - key: \"CriticalAddonsOnly\"\n                operator: \"Exists\"\n</code></pre> <p>You can run this example by saving the manifest into <code>fluxinstance.yaml</code>.</p> <p>1. Apply the resource on the cluster:</p> <pre><code>kubectl apply -f fluxinstance.yaml\n</code></pre> <p>2. Run <code>kubectl get fluxinstance</code> to see the status of the resource:</p> <pre><code>$ kubectl -n flux-system get fluxinstance\nNAME   AGE   READY   STATUS                           REVISION\nflux   59s   True    Reconciliation finished in 52s   v2.3.0@sha256:4cc5babdb1279ad0177bf513292deadbfa3f7b7c3da0be7fa53b39ab434f7219\n</code></pre> <p>3. Run <code>kubectl describe fluxinstance</code> to see the reconciliation status components, conditions and events:</p> <pre><code>$ kubectl -n flux-system describe fluxinstance flux\nStatus:\n  Components:\n    Digest:      sha256:161da425b16b64dda4b3cec2ba0f8d7442973aba29bb446db3b340626181a0bc\n    Name:        source-controller\n    Repository:  ghcr.io/fluxcd/source-controller\n    Tag:         v1.3.0\n    Digest:      sha256:48a032574dd45c39750ba0f1488e6f1ae36756a38f40976a6b7a588d83acefc1\n    Name:        kustomize-controller\n    Repository:  ghcr.io/fluxcd/kustomize-controller\n    Tag:         v1.3.0\n    Digest:      sha256:a67a037faa850220ff94d8090253732079589ad9ff10b6ddf294f3b7cd0f3424\n    Name:        helm-controller\n    Repository:  ghcr.io/fluxcd/helm-controller\n    Tag:         v1.0.1\n    Digest:      sha256:c0fab940c7e578ea519097d36c040238b0cc039ce366fdb753947428bbf0c3d6\n    Name:        notification-controller\n    Repository:  ghcr.io/fluxcd/notification-controller\n    Tag:         v1.3.0\n    Digest:      sha256:aed795c7a8b85bca93f6d199d5a14bbefaf925ad5aa5316b32a716cfa4070d0b\n    Name:        image-reflector-controller\n    Repository:  ghcr.io/fluxcd/image-reflector-controller\n    Tag:         v0.32.0\n    Digest:      sha256:ab5097213194f3cd9f0e68d8a937d94c4fc7e821f6544453211e94815b282aa2\n    Name:        image-automation-controller\n    Repository:  ghcr.io/fluxcd/image-automation-controller\n    Tag:         v0.38.0\n  Conditions:\n    Last Transition Time:  2024-06-03T12:20:57Z\n    Message:               Reconciliation finished in 52s\n    Observed Generation:   1\n    Reason:                ReconciliationSucceeded\n    Status:                True\n    Type:                  Ready\n  Last Applied Revision:    v2.3.0@sha256:4cc5babdb1279ad0177bf513292deadbfa3f7b7c3da0be7fa53b39ab434f7219\n  Last Attempted Revision:  v2.3.0@sha256:4cc5babdb1279ad0177bf513292deadbfa3f7b7c3da0be7fa53b39ab434f7219\nEvents:\n  Type    Reason                   Age    From             Message\n  ----    ------                   ----   ----             -------\n  Normal  Progressing              6m20s  flux-controller  Installing revision v2.3.0@sha256:4cc5babdb1279ad0177bf513292deadbfa3f7b7c3da0be7fa53b39ab434f7219\n  Normal  ReconciliationSucceeded  5m9s   flux-controller  Reconciliation finished in 52s\n</code></pre> <p>4. Run <code>kubectl logs</code> on the flux-operator pod to see the reconciliation logs:</p> <pre><code>kubectl -n flux-system logs deployment/flux-operator\n</code></pre> <p>5. Run <code>kubectl events</code> to see the events generated by the flux-operator:</p> <pre><code>kubectl -n flux-system events --for FluxInstance/flux\n</code></pre> <p>6. Run <code>kubectl delete</code> to remove the FluxInstance resource and    to uninstall Flux without affecting any Flux-managed workloads:</p> <pre><code>kubectl -n flux-system delete FluxInstance/flux\n</code></pre>"},{"location":"operator/fluxinstance/#writing-a-fluxinstance-spec","title":"Writing a FluxInstance spec","text":"<p>As with all other Kubernetes config, a FluxInstance needs <code>apiVersion</code>, <code>kind</code>, and <code>metadata</code> fields. The name of a FluxInstance object must be a valid DNS subdomain name.</p> <p>A FluxInstance also needs a <code>.spec</code> section.</p>"},{"location":"operator/fluxinstance/#distribution-configuration","title":"Distribution configuration","text":"<p>The <code>.spec.distribution</code> field is required and specifies the Flux distribution to install.</p> <p>Example using the upstream Flux distribution:</p> <pre><code>spec:\n  distribution:\n    version: \"2.x\"\n    registry: \"ghcr.io/fluxcd\"\n</code></pre>"},{"location":"operator/fluxinstance/#distribution-version","title":"Distribution version","text":"<p>The <code>.spec.distribution.version</code> field is required and specifies the version of the Flux distribution to install. The version field value must be a valid semver range or an exact version.</p> <p>Example using a semver range to configure the automatic upgrade to the latest Flux minor version:</p> <pre><code>spec:\n  distribution:\n    version: \"2.x\"\n</code></pre> <p>Example using a semver range to configure the automatic upgrade to the latest Flux patch version of the <code>2.3</code> series:</p> <pre><code>spec:\n  distribution:\n    version: \"2.3.x\"\n</code></pre> <p>Example using an exact version to install a specific Flux version:</p> <pre><code>spec:\n  distribution:\n    version: \"2.3.0\"\n</code></pre>"},{"location":"operator/fluxinstance/#distribution-registry","title":"Distribution registry","text":"<p>The <code>.spec.distribution.registry</code> field is required and specifies the container registry where the Flux distribution images are pulled from.</p> <p>Example using the upstream Flux distribution registry:</p> <pre><code>spec:\n  distribution:\n    version: \"2.x\"\n    registry: \"ghcr.io/fluxcd\"\n</code></pre>"},{"location":"operator/fluxinstance/#distribution-registry-mirrors","title":"Distribution registry mirrors","text":"<p>The <code>.spec.distribution.variant</code> field is required, when specifying a third-party registry where the Flux distribution images are pulled from. This is useful for registry mirrors, for example in corporate environments.</p> <p>Valid values are <code>upstream-alpine</code>, <code>enterprise-alpine</code> and <code>enterprise-distroless</code>.</p> <p>Example using a hypothetical <code>ghcr.io</code> mirror:</p> <pre><code>spec:\n  distribution:\n    version: \"2.x\"\n    registry: \"my-ghcr-mirror.io/fluxcd\"\n    variant: \"upstream-alpine\"\n</code></pre> <p>Example using a hypothetical mirror of the ControlPlane enterprise registry:</p> <pre><code>spec:\n  distribution:\n    version: \"2.x\"\n    registry: \"my-ghcr-mirror.io/controlplaneio-fluxcd/distroless\"\n    variant: \"enterprise-distroless\"\n</code></pre>"},{"location":"operator/fluxinstance/#distribution-image-pull-secret","title":"Distribution image pull secret","text":"<p>The <code>.spec.distribution.imagePullSecret</code> field is optional and specifies the name of the Kubernetes secret that contains the credentials to pull the Flux distribution images from a private registry.</p> <p>Example using the ControlPlane enterprise registry:</p> <pre><code>spec:\n  distribution:\n    version: \"2.3.x\"\n    registry: \"ghcr.io/controlplaneio-fluxcd/distroless\"\n    imagePullSecret: \"flux-enterprise-auth\"\n</code></pre> <p>The image pull secret must be created in the same namespace where the FluxInstance is deployed and must be of type <code>kubernetes.io/dockerconfigjson</code>.</p> <p>Example generating a secret for the ControlPlane enterprise registry:</p> <pre><code>kubectl create secret docker-registry flux-enterprise-auth \\\n  --namespace flux-system \\\n  --docker-server=ghcr.io \\\n  --docker-username=flux \\\n  --docker-password=$ENTERPRISE_TOKEN\n</code></pre>"},{"location":"operator/fluxinstance/#distribution-artifact","title":"Distribution artifact","text":"<p>The <code>.spec.distribution.artifact</code> field is optional and specifies the OCI artifact URL containing the Flux distribution manifests. When specified, the operator will pull the artifact on a regular interval to determine the latest Flux version available including CVE patches and hotfixes.</p> <p>Example using the official distribution artifact:</p> <pre><code>spec:\n  distribution:\n    version: \"2.x\"\n    registry: \"ghcr.io/fluxcd\"\n    artifact: \"oci://ghcr.io/controlplaneio-fluxcd/flux-operator-manifests\"\n</code></pre>"},{"location":"operator/fluxinstance/#distribution-artifact-pull-secret","title":"Distribution artifact pull secret","text":"<p>The <code>.spec.distribution.artifactPullSecret</code> field is optional and specifies the name of the Kubernetes secret that contains the credentials to pull the Flux distribution manifests from a private registry.</p> <p>Example using a private registry:</p> <pre><code>spec:\n  distribution:\n    version: \"2.3.x\"\n    registry: \"ghcr.io/controlplaneio-fluxcd/distroless\"\n    artifact: \"oci://private.registry.com/controlplaneio-fluxcd/flux-operator-manifests\"\n    artifactPullSecret: \"flux-private-auth\"\n</code></pre> <p>The manifest pull secret must be created in the same namespace where the FluxInstance is deployed and must be of type <code>kubernetes.io/dockerconfigjson</code>.</p>"},{"location":"operator/fluxinstance/#components-configuration","title":"Components configuration","text":"<p>The <code>.spec.components</code> field is optional and specifies the list of Flux components to install.</p> <p>When not specified, the operator will install the default set of components: <code>source-controller</code>, <code>kustomize-controller</code>, <code>helm-controller</code> and <code>notification-controller</code>.</p> <p>The supported components are:</p> <pre><code>spec:\n  components:\n    - source-controller\n    - kustomize-controller\n    - helm-controller\n    - notification-controller\n    - image-reflector-controller\n    - image-automation-controller\n    - source-watcher\n</code></pre> <p>Note that the <code>source-watcher</code> component requires Flux v2.7.0 or later.</p>"},{"location":"operator/fluxinstance/#cluster-configuration","title":"Cluster configuration","text":"<p>The <code>.spec.cluster</code> field is optional and specifies the Kubernetes cluster configuration.</p> <p>Example using the OpenShift cluster configuration:</p> <pre><code>spec:\n  cluster:\n    type: openshift\n    size: medium\n    multitenant: true\n    multitenantWorkloadIdentity: true\n    objectLevelWorkloadIdentity: true\n    tenantDefaultServiceAccount: \"flux\"\n    tenantDefaultDecryptionServiceAccount: \"flux-decryption\"\n    tenantDefaultKubeConfigServiceAccount: \"flux-kubeconfig\"\n    networkPolicy: true\n    domain: \"cluster.local\"\n</code></pre>"},{"location":"operator/fluxinstance/#cluster-type","title":"Cluster type","text":"<p>The <code>.spec.cluster.type</code> field is optional and specifies the type of the Kubernetes cluster. This field is used to enable specific configuration for AKS, EKS, GKE and OpenShift clusters.</p> <p>The supported values are <code>kubernetes</code> (default), <code>openshift</code>, <code>azure</code>, <code>aws</code> and <code>gcp</code>.</p>"},{"location":"operator/fluxinstance/#cluster-size","title":"Cluster size","text":"<p>The <code>.spec.cluster.size</code> field is optional and specifies the size of the Kubernetes cluster. The size is used to determine the vertical scaling profile for the Flux controllers based on the number of applications and the deployment frequency.</p> <p>The supported values are <code>small</code>, <code>medium</code> and <code>large</code> which correspond to the following configuration for Flux <code>kustomize-controller</code> and <code>helm-controller</code>:</p> Size Concurrency CPU limit Memory limit Requeue deps small 5 1000m 512Mi 10s medium 10 2000m 1Gi 5s large 20 3000m 3Gi 5s <p>For all sizes, the <code>source-controller</code> is configured to cache artifacts and the concurrency is set between 2 and 10.</p> <p>The <code>small</code> size is suitable for edge clusters with limited resources (Raspberry Pi) or for clusters with tens of apps and moderate deployment frequency.</p> <p>The <code>medium</code> size is suitable for clusters with hundreds of apps, while the <code>large</code> size is for clusters with up to a thousand apps and high deployment frequency.</p> <p>When Flux manages thousands of apps, the recommended scaling strategy is to use sharding.</p>"},{"location":"operator/fluxinstance/#cluster-multitenant","title":"Cluster multitenant","text":"<p>The <code>.spec.cluster.multitenant</code> field is optional and specifies whether to enable Flux multi-tenancy lockdown. By default, it is <code>false</code> (disabled).</p> <p>The <code>.spec.cluster.tenantDefaultServiceAccount</code> is optional and specifies the default service account used by Flux when reconciling <code>Kustomization</code> and <code>HelmRelease</code> resources found in the tenant namespaces.</p>"},{"location":"operator/fluxinstance/#cluster-workload-identity","title":"Cluster workload identity","text":"<p>The workload identity configuration provides fine-grained control over service account usage across Flux controllers, enabling secure multi-tenant deployments in cloud environments.</p>"},{"location":"operator/fluxinstance/#object-level-workload-identity","title":"Object-level workload identity","text":"<p>The <code>.spec.cluster.objectLevelWorkloadIdentity</code> field is optional and specifies whether to enable the object-level workload identity feature gate and RBAC for the Flux controllers. This feature allows Flux resources to specify their own service accounts via the <code>spec.serviceAccountName</code> field.</p> <p>Version requirements:</p> <ul> <li>Flux v2.6.0 and later: Supported for <code>source-controller</code>, <code>kustomize-controller</code>,   <code>notification-controller</code>, <code>image-reflector-controller</code>, and <code>image-automation-controller</code></li> <li>Flux v2.7.0 and later: Additionally supported for <code>helm-controller</code></li> </ul> <p>Example:</p> <pre><code>spec:\n  cluster:\n    objectLevelWorkloadIdentity: true\n</code></pre>"},{"location":"operator/fluxinstance/#multitenant-workload-identity","title":"Multitenant workload identity","text":"<p>The <code>.spec.cluster.multitenantWorkloadIdentity</code> field is optional and enables workload identity multi-tenancy lockdown. When enabled, Flux controllers will use tenant-specific service accounts as defaults, preventing cross-tenant access in workload identity scenarios.</p> <p>Requirements:</p> <ul> <li>Requires <code>objectLevelWorkloadIdentity: true</code></li> <li>Available in Flux v2.7.0 and later</li> <li>Designed for cloud environments with workload identity (AWS IRSA, Azure Workload Identity, GCP Workload Identity)</li> </ul> <p>Example:</p> <pre><code>spec:\n  cluster:\n    objectLevelWorkloadIdentity: true\n    multitenantWorkloadIdentity: true\n</code></pre>"},{"location":"operator/fluxinstance/#service-account-configuration","title":"Service account configuration","text":"<p>When <code>multitenantWorkloadIdentity</code> is enabled, you can configure default service accounts for different controller operations:</p> <ul> <li><code>.spec.cluster.tenantDefaultServiceAccount</code> (optional): Default service account for   <code>source-controller</code>, <code>notification-controller</code>, <code>image-reflector-controller</code>, and   <code>image-automation-controller</code> operations. Defaults to <code>\"default\"</code>. (Also used by   <code>kustomize-controller</code> and <code>helm-controller</code> for Kubernetes API operations when   <code>.spec.cluster.multitenant</code> is set to <code>true</code>.)</li> <li><code>.spec.cluster.tenantDefaultDecryptionServiceAccount</code> (optional): Default service account   for <code>kustomize-controller</code> SOPS decryption operations. Defaults to <code>\"default\"</code>.</li> <li><code>.spec.cluster.tenantDefaultKubeConfigServiceAccount</code> (optional): Default service account   for <code>kustomize-controller</code> and <code>helm-controller</code> remote cluster access via   <code>spec.kubeConfig.configMapRef</code>. Defaults to <code>\"default\"</code>.</li> </ul> <p>Complete example:</p> <pre><code>spec:\n  cluster:\n    objectLevelWorkloadIdentity: true\n    multitenantWorkloadIdentity: true\n    tenantDefaultServiceAccount: \"flux-tenant\"\n    tenantDefaultDecryptionServiceAccount: \"flux-decryption\"\n    tenantDefaultKubeConfigServiceAccount: \"flux-kubeconfig\"\n</code></pre> <p>Use cases:</p> <ul> <li>Cloud workload identity: Each tenant namespace has service accounts bound to cloud IAM roles</li> <li>Secret management: Different service accounts for decryption operations (e.g. SOPS with cloud KMS)</li> <li>Multi-cluster: Separate service accounts for accessing remote clusters via cloud IAM</li> <li>Zero-trust: Prevent controllers from accessing resources outside their intended scope</li> </ul> <p>See the complete workload identity documentation for CNCF Flux here.</p>"},{"location":"operator/fluxinstance/#cluster-network-policy","title":"Cluster network policy","text":"<p>The <code>.spec.cluster.networkPolicy</code> field is optional and specifies whether to restrict network access to the Flux namespace from other namespaces. By default, network policy is enabled.</p>"},{"location":"operator/fluxinstance/#cluster-domain","title":"Cluster domain","text":"<p>The <code>.spec.cluster.domain</code> field is optional and specifies the cluster internal domain name. By default, the domain is set to <code>cluster.local</code>.</p>"},{"location":"operator/fluxinstance/#storage-configuration","title":"Storage configuration","text":"<p>The <code>.spec.storage</code> field is optional and specifies the persistent storage for Flux internal artifacts. When specified, the operator will create a persistent volume claim named <code>source-controller</code> with the specified storage class and size and mount it to the Flux source-controller <code>/data</code> volume.</p>"},{"location":"operator/fluxinstance/#storage-class","title":"Storage class","text":"<p>The <code>.spec.storage.class</code> field is required and specifies the storage class to use for the persistent volume claim.</p> <p>Example using the standard storage class:</p> <pre><code>spec:\n  storage:\n    class: \"standard\"\n    size: \"10Gi\"\n</code></pre>"},{"location":"operator/fluxinstance/#storage-size","title":"Storage size","text":"<p>The <code>.spec.storage.size</code> field is required and specifies the size of the persistent volume claim.</p>"},{"location":"operator/fluxinstance/#sharding-configuration","title":"Sharding configuration","text":"<p>The <code>.spec.sharding</code> field is optional and specifies the sharding configuration for the Flux controllers.</p> <p>Example:</p> <pre><code>spec:\n  sharding:\n    key: \"sharding.fluxcd.io/key\"\n    shards:\n      - \"shard1\"\n      - \"shard2\"\n    storage: persistent\n</code></pre> <p>For each shard, the operator will create a separate set of controllers, e.g.:</p> <pre><code>$ kubectl -n flux-system get deployments -l app.kubernetes.io/part-of=flux\nNAME\nsource-controller\nsource-controller-shard1\nsource-controller-shard2\nkustomize-controller\nkustomize-controller-shard1\nkustomize-controller-shard2\nhelm-controller\nhelm-controller-shard1\nhelm-controller-shard2\n</code></pre> <p>Note that only the <code>source-controller</code>, <code>kustomize-controller</code> and <code>helm-controller</code> controllers support sharding.</p> <p>To assign a resource to a specific shard, add the <code>sharding.fluxcd.io/key</code> label with the shard value, e.g.: <code>sharding.fluxcd.io/key: shard1</code>.</p>"},{"location":"operator/fluxinstance/#sharding-key","title":"Sharding key","text":"<p>The <code>.spec.sharding.key</code> field is optional and specifies the sharding key label to use for the Flux controllers. By default, the key is set to <code>sharding.fluxcd.io/key</code>.</p>"},{"location":"operator/fluxinstance/#shards","title":"Shards","text":"<p>The <code>.spec.sharding.shards</code> field is required and specifies the list of sharding values to use for the Flux controllers.</p>"},{"location":"operator/fluxinstance/#sharding-storage","title":"Sharding storage","text":"<p>The <code>.spec.sharding.storage</code> field is optional and specifies the storage type to use for the source-controller shards.</p> <p>The supported values are <code>ephemeral</code> (default) and <code>persistent</code>. When set to <code>persistent</code>, the operator will create a persistent volume claim for each shard using the storage class and size specified in the <code>.spec.storage</code> field.</p>"},{"location":"operator/fluxinstance/#common-metadata","title":"Common metadata","text":"<p>The <code>.spec.commonMetadata</code> field is optional and specifies common metadata to be applied to all Kubernetes resources part of the Flux instance.</p> <p>It has two optional fields:</p> <ul> <li><code>labels</code>: A map used for setting labels   on an object. Any existing label will be overridden if it matches with a key in   this map.</li> <li><code>annotations</code>: A map used for setting annotations   on an object. Any existing annotation will be overridden if it matches with a key   in this map.</li> </ul> <p>Example common metadata:</p> <pre><code>spec:\n  commonMetadata:\n    labels:\n      app.kubernetes.io/name: flux\n    annotations:\n      toolkit.fluxcd.io/tenant: sre-team\n</code></pre>"},{"location":"operator/fluxinstance/#kustomize-patches","title":"Kustomize patches","text":"<p>The <code>.spec.kustomize.patches</code> field is optional and specifies the Kustomize patches to apply to the Flux controllers.</p> <p>Example:</p> <pre><code>spec:\n  kustomize:\n    patches:\n      - target:\n          kind: Deployment\n          name: \"(kustomize-controller|helm-controller)\"\n        patch: |\n          - op: replace\n            path: /spec/template/spec/volumes/0\n            value:\n              name: temp\n              emptyDir:\n                medium: Memory\n</code></pre>"},{"location":"operator/fluxinstance/#reconciliation-configuration","title":"Reconciliation configuration","text":"<p>The reconciliation behaviour can be configured using the following annotations:</p> <ul> <li><code>fluxcd.controlplane.io/reconcile</code>: Enable or disable the reconciliation loop. Default is <code>enabled</code>, set to <code>disabled</code> to pause the reconciliation.</li> <li><code>fluxcd.controlplane.io/reconcileEvery</code>: Set the reconciliation interval. Default is <code>1h</code>.</li> <li><code>fluxcd.controlplane.io/reconcileArtifactEvery</code>: Set the artifact reconciliation interval. Default is <code>10m</code>.</li> <li><code>fluxcd.controlplane.io/reconcileTimeout</code>: Set the reconciliation timeout. Default is <code>5m</code>.</li> </ul> <p>To trigger an immediate reconciliation, the following annotation can be set to the current timestamp:</p> <ul> <li><code>reconcile.fluxcd.io/requestedAt</code>: Set to the current timestamp to trigger an immediate reconciliation.</li> <li><code>reconcile.fluxcd.io/forceAt</code>: Set to the current timestamp to trigger a forced reconciliation, migrating all Flux resources to their latest API version.</li> </ul> <p>To force a reconciliation with the Flux Operator CLI:</p> <pre><code>flux-operator -n flux-system reconcile instance flux --force\n</code></pre>"},{"location":"operator/fluxinstance/#sync-configuration","title":"Sync configuration","text":"<p>The <code>.spec.sync</code> field is optional and specifies the Flux sync configuration. When set, a Flux source and a Flux Kustomization are generated to sync the cluster state with the source repository.</p> <p>The Flux objects are created in the same namespace where the FluxInstance is deployed using the namespace name as the Flux source and Kustomization name. The naming convention matches the one used by <code>flux bootstrap</code> to ensure compatibility with upstream, and to allow transitioning a bootstrapped cluster to a FluxInstance managed one.</p> <p>Sync fields:</p> <ul> <li><code>kind</code>: The source kind, supported values are <code>GitRepository</code>, <code>OCIRepository</code> and <code>Bucket</code>.</li> <li><code>url</code>: The URL of the source repository, can be a Git repository HTTP/S or SSH address, an OCI repository address or a Bucket endpoint.</li> <li><code>ref</code>: The source reference, can be a Git ref name e.g. <code>refs/heads/main</code>, an OCI tag e.g. <code>latest</code> or a Bucket name.</li> <li><code>path</code>: The path to the source directory containing the kustomize overlay or plain Kubernetes manifests to sync from.</li> <li><code>pullSecret</code>: The name of the Kubernetes secret that contains the credentials to pull the source repository. This field is optional.</li> <li><code>provider</code>: The provider name used for OIDC-based authentication.    Supported values are <code>aws</code>, <code>azure</code> and <code>gcp</code> for <code>OCIRepository</code>/<code>Bucket</code>,    and <code>azure</code> or <code>github</code> for <code>GitRepository</code>. This field is optional.</li> <li><code>interval</code>: The sync interval. This field is optional, when not set the default is <code>1m</code>.</li> <li><code>name</code>: The name of the generated Flux source and Kustomization objects.    This field is optional, when not set the default is the FluxInstance namespace name.    Note that this field is considered immutable, and cannot be changed after the FluxInstance is created.</li> </ul>"},{"location":"operator/fluxinstance/#sync-from-git-over-https","title":"Sync from Git over HTTP/S","text":"<p>Example:</p> <pre><code>spec:\n  sync:\n    kind: GitRepository\n    url: \"https://gitlab.com/my-group/my-fleet.git\"\n    ref: \"refs/heads/main\"\n    path: \"clusters/my-cluster\"\n    pullSecret: \"git-token-auth\"\n</code></pre> <p>If the source repository is private, the Kubernetes secret must be created in the same namespace where the FluxInstance is deployed, and have the following format:</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: git-token-auth\n  namespace: flux-system\ntype: Opaque\nstringData:\n  username: \"git-username\"\n  password: \"git-token\"\n</code></pre> <p>To generate the secret with the Flux CLI:</p> <pre><code>flux create secret git git-token-auth \\\n  --namespace flux-system \\\n  --url=https://gitlab.com/my-group/my-fleet.git \\\n  --username=git-username \\\n  --password=git-token\n</code></pre>"},{"location":"operator/fluxinstance/#sync-from-git-over-ssh","title":"Sync from Git over SSH","text":"<p>Example:</p> <pre><code>spec:\n  sync:\n    kind: GitRepository\n    url: \"ssh://git@github.com/my-org/my-fleet.git\"\n    ref: \"refs/heads/main\"\n    path: \"clusters/my-cluster\"\n    pullSecret: \"git-ssh-auth\"\n</code></pre> <p>If the source repository is private, the Kubernetes secret must be created in the same namespace where the FluxInstance is deployed, and have the following format:</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: git-ssh-auth\n  namespace: flux-system\ntype: Opaque\nstringData:\n  identity: |\n    -----BEGIN OPENSSH PRIVATE KEY-----\n    ...\n    -----END OPENSSH PRIVATE KEY-----    \n  known_hosts: |\n    github.com ecdsa-sha2-nistp256 AAAA...  \n</code></pre> <p>To generate the secret with the Flux CLI:</p> <pre><code>flux create secret git git-ssh-auth \\\n  --namespace flux-system \\\n  --url=ssh://git@github.com/my-org/my-fleet.git \\\n  --private-key-file=my-private.key\n</code></pre>"},{"location":"operator/fluxinstance/#sync-from-oci-over-https","title":"Sync from OCI over HTTP/S","text":"<p>Example:</p> <pre><code>spec:\n  sync:\n    kind: OCIRepository\n    url: \"oci://ghcr.io/my-org/my-fleet-manifests\"\n    ref: \"latest\"\n    path: \"clusters/my-cluster\"\n    pullSecret: \"oci-token-auth\"\n</code></pre> <p>If the container registry is private, the Kubernetes secret must be created in the same namespace where the FluxInstance is deployed, and be of type <code>kubernetes.io/dockerconfigjson</code>:</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: oci-token-auth\n  namespace: flux-system\ntype: kubernetes.io/dockerconfigjson\ndata:\n  .dockerconfigjson: \"base64-encoded-docker-config\"\n</code></pre> <p>To generate the secret with the Flux CLI:</p> <pre><code>flux create secret oci oci-token-auth \\\n  --namespace flux-system \\\n  --url=ghcr.io \\\n  --username=ghcr-username \\\n  --password=ghcr-token\n</code></pre>"},{"location":"operator/fluxinstance/#sync-from-s3-compatible-storage-over-https","title":"Sync from S3-compatible storage over HTTP/S","text":"<p>Example:</p> <pre><code>spec:\n  sync:\n    kind: Bucket\n    url: \"minio.my-org.com\"\n    ref: \"my-bucket-fleet\"\n    path: \"clusters/my-cluster\"\n    pullSecret: \"bucket-auth\"\n</code></pre> <p>If the Bucket is private, the Kubernetes secret must be created in the same namespace where the FluxInstance is deployed, and have the following format:</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: bucket-auth\n  namespace: flux-system\ntype: Opaque\nstringData:\n  accesskey: \"my-accesskey\"\n  secretkey: \"my-secretkey\"\n</code></pre>"},{"location":"operator/fluxinstance/#resources-migration-configuration","title":"Resources migration configuration","text":"<p>The <code>.spec.migrateResources</code> field is optional and instructs the operator to migrate the Flux custom resources stored in Kubernetes etcd to the latest API version as specified in the Flux CRDs. The migration runs after the Flux distribution is upgraded from a minor version to another and only when a new API version is introduced.</p> <p>By default, the field value is set to <code>true</code>. Note that disabling the migration may result in upgrade failures due to deprecated API versions being removed in future Flux releases.</p>"},{"location":"operator/fluxinstance/#fluxinstance-status","title":"FluxInstance Status","text":""},{"location":"operator/fluxinstance/#conditions","title":"Conditions","text":"<p>A FluxInstance enters various states during its lifecycle, reflected as Kubernetes Conditions. It can be reconciling while applying the resources on the cluster, it can be ready, it can fail during reconciliation, or it can fail due to misconfiguration.</p> <p>The FluxInstance API is compatible with the kstatus specification, and reports <code>Reconciling</code> and <code>Stalled</code> conditions where applicable to provide better (timeout) support to solutions polling the Kustomization to become <code>Ready</code>.</p>"},{"location":"operator/fluxinstance/#reconciling-fluxinstance","title":"Reconciling FluxInstance","text":"<p>The flux-operator marks a FluxInstance as reconciling when it starts the reconciliation of the same. The Condition added to the FluxInstance's <code>.status.conditions</code> has the following attributes:</p> <ul> <li><code>type: Reconciling</code></li> <li><code>status: \"True\"</code></li> <li><code>reason: Progressing</code> | <code>reason: ProgressingWithRetry</code></li> </ul> <p>The Condition <code>message</code> is updated during the course of the reconciliation to report the action being performed at any particular moment such as building manifests, detecting drift, etc.</p> <p>The <code>Ready</code> Condition's <code>status</code> is also marked as <code>Unknown</code>.</p>"},{"location":"operator/fluxinstance/#ready-fluxinstance","title":"Ready FluxInstance","text":"<p>The flux-operator marks a FluxInstance as ready when the Flux configuration was built and applied on the cluster and all health checks are observed to be passing.</p> <p>When the FluxInstance is \"ready\", the flux-operator sets a Condition with the following attributes in the FluxInstance\u2019s <code>.status.conditions</code>:</p> <ul> <li><code>type: Ready</code></li> <li><code>status: \"True\"</code></li> <li><code>reason: ReconciliationSucceeded</code></li> </ul>"},{"location":"operator/fluxinstance/#failed-fluxinstance","title":"Failed FluxInstance","text":"<p>The flux-operator may get stuck trying to reconcile and apply a FluxInstance without completing. This can occur due to some of the following factors:</p> <ul> <li>The distribution artifact is not accessible.</li> <li>The distribution version is not available.</li> <li>The kustomization of the Flux components fails to build.</li> <li>Garbage collection fails.</li> <li>Running health checks fails.</li> </ul> <p>When this happens, the flux-operator sets the <code>Ready</code> Condition status to False and adds a Condition with the following attributes to the FluxInstance\u2019s <code>.status.conditions</code>:</p> <ul> <li><code>type: Ready</code></li> <li><code>status: \"False\"</code></li> <li><code>reason: ArtifactFailed | BuildFailed | HealthCheckFailed | ReconciliationFailed</code></li> </ul> <p>The <code>message</code> field of the Condition will contain more information about why the reconciliation failed.</p> <p>While the FluxInstance has one or more of these Conditions, the flux-operator will continue to attempt a reconciliation with an exponential backoff, until it succeeds and the FluxInstance is marked as ready.</p>"},{"location":"operator/fluxinstance/#stalled-fluxinstance","title":"Stalled FluxInstance","text":"<p>The flux-operator may fail the reconciliation of a FluxInstance object terminally due to a misconfiguration. When this happens, the flux-operator adds the <code>Stalled</code> Condition to the FluxInstance\u2019s <code>.status.conditions</code> with the following attributes:</p> <ul> <li><code>type: Stalled</code></li> <li><code>status: \"True\"</code></li> <li><code>reason: BuildFailed</code></li> </ul> <p>Misconfigurations can include:</p> <ul> <li>The build of the Flux manifests fails. In this case the condition reason is <code>BuildFailed</code>.</li> </ul> <p>When this happens, the flux-operator will not attempt to reconcile the FluxInstance until the misconfiguration is fixed. The <code>Ready</code> Condition status is also set to <code>False</code>.</p>"},{"location":"operator/fluxinstance/#history","title":"History","text":"<p>With <code>.status.history</code> the operator tracks the reconciliation attempts over time, providing insights into the FluxInstance's behavior which can be used for audit, anomaly detection and debugging purposes.</p> <p>The history is stored as a list of snapshots, ordered by last reconciliation time. Each snapshot contains:</p> <ul> <li><code>digest</code>: A SHA256 digest that uniquely identifies the Flux configuration being reconciled</li> <li><code>firstReconciled</code>: The timestamp when this particular configuration was first reconciled</li> <li><code>lastReconciled</code>: The timestamp of the most recent reconciliation attempt for this configuration</li> <li><code>lastReconciledDuration</code>: How long the most recent reconciliation attempt took</li> <li><code>lastReconciledStatus</code>: The status of the most recent reconciliation (e.g., <code>ReconciliationSucceeded</code>, <code>BuildFailed</code>, <code>ReconciliationFailed</code>)</li> <li><code>totalReconciliations</code>: The total number of reconciliations for this configuration</li> <li><code>metadata</code>: Additional information about the reconciliation, including the Flux semantic version being applied</li> </ul> <p>The operator deduplicates entries based on the digest and status. The history is automatically truncated to keep only the 5 most recent entries.</p> <p>Example:</p> <pre><code>status:\n  history:\n    - digest: sha256:43ad78c94b2655429d84f21488f29d7cca9cd45b7f54d2b27e16bbec8eff9228\n      firstReconciled: \"2025-07-15T10:11:00Z\"\n      lastReconciled: \"2025-07-15T11:12:00Z\"\n      lastReconciledDuration: 2.818583s\n      lastReconciledStatus: ReconciliationSucceeded\n      totalReconciliations: 2\n      metadata:\n        flux: \"v2.6.4\"\n    - digest: sha256:ec8dbfe61777b65001190260cf873ffe454451bd2e464bd6f9a154cffcdcd7e5\n      firstReconciled: \"2025-06-14T13:10:00Z\"\n      lastReconciled: \"2025-07-15T10:00:00Z\"\n      lastReconciledDuration: 4.813292s\n      lastReconciledStatus: ReconciliationSucceeded\n      totalReconciliations: 120\n      metadata:\n        flux: \"v2.6.3\"\n</code></pre>"},{"location":"operator/fluxinstance/#components-status","title":"Components status","text":"<p>In order to provide visibility into the Flux components that are installed, the flux-operator records the status of each component in the <code>.status.components</code> field, including the image repository, tag and digest.</p> <p>Example:</p> <pre><code>Status:\n  Components:\n    Digest:      sha256:161da425b16b64dda4b3cec2ba0f8d7442973aba29bb446db3b340626181a0bc\n    Name:        source-controller\n    Repository:  ghcr.io/fluxcd/source-controller\n    Tag:         v1.3.0\n    Digest:      sha256:48a032574dd45c39750ba0f1488e6f1ae36756a38f40976a6b7a588d83acefc1\n    Name:        kustomize-controller\n    Repository:  ghcr.io/fluxcd/kustomize-controller\n    Tag:         v1.3.0\n</code></pre>"},{"location":"operator/fluxinstance/#inventory-status","title":"Inventory Status","text":"<p>In order to perform operations such as drift detection, garbage collection, upgrades, etc., the flux-operator needs to keep track of all Kubernetes objects that are reconciled as part of a FluxInstance. To do this, it maintains an inventory containing the list of Kubernetes resource object references that have been successfully applied and records it in <code>.status.inventory</code>. The inventory records are in the format <code>id: &lt;namespace&gt;_&lt;name&gt;_&lt;group&gt;_&lt;kind&gt;, v: &lt;version&gt;</code>.</p> <p>Example:</p> <pre><code>status:\n  inventory:\n    entries:\n      - id: flux-system_source-controller__ServiceAccount\n        v: v1\n      - id: flux-system_source-controller__Service\n        v: v1\n      - id: flux-system_source-controller_apps_Deployment\n        v: v1\n</code></pre>"},{"location":"operator/fluxinstance/#last-applied-revision","title":"Last applied revision","text":"<p><code>.status.lastAppliedRevision</code> is the last revision of the Flux distribution that was successfully applied to the cluster.</p> <p>The revision is in the format <code>&lt;version&gt;@sha256:&lt;digest&gt;</code>. </p> <p>The version is the Flux distribution exact semver version that was applied to the cluster.</p> <p>The digest is the SHA256 hash of the Flux distribution manifests and customisations that was applied to the cluster.</p>"},{"location":"operator/fluxinstance/#last-attempted-revision","title":"Last attempted revision","text":"<p><code>.status.lastAttemptedRevision</code> is the last revision of the Flux distribution that was attempted to be applied to the cluster.</p> <p>Example:</p> <pre><code>Status:\n  Last Applied Revision:    v2.3.0@sha256:4cc5babdb1279ad0177bf513292deadbfa3f7b7c3da0be7fa53b39ab434f7219\n  Last Attempted Revision:  v2.3.0@sha256:4cc5babdb1279ad0177bf513292deadbfa3f7b7c3da0be7fa53b39ab434f7219\n</code></pre>"},{"location":"operator/fluxinstance/#fluxinstance-metrics","title":"FluxInstance Metrics","text":"<p>The Flux Operator exports metrics for the FluxInstance resource. These metrics are refreshed every time the operator reconciles the instance.</p> <p>Metrics:</p> <pre><code>flux_instance_info{uid, kind, name, exported_namespace, ready, suspended, registry, revision}\n</code></pre> <p>Labels:</p> <ul> <li><code>uid</code>: The Kubernetes unique identifier of the resource.</li> <li><code>kind</code>: The kind of the resource (e.g. <code>FluxInstance</code>).</li> <li><code>name</code>: The name of the resource (e.g. <code>flux</code>).</li> <li><code>exported_namespace</code>: The namespace where the resource is deployed (e.g. <code>flux-system</code>).</li> <li><code>ready</code>: The readiness status of the resource (e.g. <code>True</code>, <code>False</code> or <code>Unkown</code>).</li> <li><code>reason</code>: The reason for the readiness status (e.g. <code>Progressing</code>, <code>BuildFailed</code>, <code>HealthCheckFailed</code>, etc.).</li> <li><code>suspended</code>: The suspended status of the resource (e.g. <code>True</code> or <code>False</code>).</li> <li><code>registry</code>: The container registry used by the instance (e.g. <code>ghcr.io/fluxcd</code>).</li> <li><code>revision</code>: The Flux revision installed by the instance (e.g. <code>v2.3.0@sha256:75aa209c6a...</code>).</li> </ul> <p>Example:</p> <pre><code>flux_instance_info{\n   exported_namespace=\"flux-system\",\n   kind=\"FluxInstance\",\n   name=\"flux\",\n   ready=\"True\",\n   reason=\"ReconciliationSucceeded\",\n   registry=\"ghcr.io/fluxcd\",\n   revision=\"v2.3.0@sha256:75aa209c6a2e25b97114ccf092246d02ab4363bc136edefc239d2a88da882b63\",\n   suspended=\"False\",\n   uid=\"16ca7202-9319-445b-99d0-617c25bda182\"\n}\n</code></pre>"},{"location":"operator/fluxreport/","title":"Flux Report CRD","text":"<p>FluxReport is an API that reflects the observed state of a Flux installation. Its purpose is to aid in monitoring and troubleshooting Flux by providing information about the installed components and their readiness, the distribution details, reconcilers statistics, cluster sync status, etc.</p> <p>A single custom resource of this kind can exist in a Kubernetes cluster with the name <code>flux</code>. The resource is automatically generated in the same namespace where the flux-operator is deployed and is updated by the operator at regular intervals.</p>"},{"location":"operator/fluxreport/#example","title":"Example","text":"<p>The following example shows a FluxReport custom resource generated on a cluster where a FluxInstance was deployed:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: FluxReport\nmetadata:\n  name: flux\n  namespace: flux-system\nspec:\n  cluster:\n    platform: linux/arm64\n    serverVersion: v1.33.0\n    nodes: 5\n  components:\n    - image: ghcr.io/fluxcd/helm-controller:v1.0.1@sha256:a67a037faa850220ff94d8090253732079589ad9ff10b6ddf294f3b7cd0f3424\n      name: helm-controller\n      ready: true\n      status: 'Current Deployment is available. Replicas: 1'\n    - image: ghcr.io/fluxcd/kustomize-controller:v1.3.0@sha256:48a032574dd45c39750ba0f1488e6f1ae36756a38f40976a6b7a588d83acefc1\n      name: kustomize-controller\n      ready: true\n      status: 'Current Deployment is available. Replicas: 1'\n    - image: ghcr.io/fluxcd/notification-controller:v1.3.0@sha256:c0fab940c7e578ea519097d36c040238b0cc039ce366fdb753947428bbf0c3d6\n      name: notification-controller\n      ready: true\n      status: 'Current Deployment is available. Replicas: 1'\n    - image: ghcr.io/fluxcd/source-controller:v1.3.0@sha256:161da425b16b64dda4b3cec2ba0f8d7442973aba29bb446db3b340626181a0bc\n      name: source-controller\n      ready: true\n      status: 'Current Deployment is available. Replicas: 1'\n  distribution:\n    entitlement: Issued by controlplane\n    managedBy: flux-operator\n    status: Installed\n    version: v2.3.0\n  operator:\n    apiVersion: fluxcd.controlplane.io/v1\n    platform: linux/arm64\n    version: v0.24.0\n  reconcilers:\n    - apiVersion: fluxcd.controlplane.io/v1\n      kind: ResourceSet\n      stats:\n        failing: 0\n        running: 5\n        suspended: 1\n    - apiVersion: fluxcd.controlplane.io/v1\n      kind: ResourceSetInputProvider\n      stats:\n        failing: 1\n        running: 5\n        suspended: 1\n    - apiVersion: helm.toolkit.fluxcd.io/v2\n      kind: HelmRelease\n      stats:\n        failing: 1\n        running: 42\n        suspended: 3\n    - apiVersion: kustomize.toolkit.fluxcd.io/v1\n      kind: Kustomization\n      stats:\n        failing: 0\n        running: 5\n        suspended: 0\n    - apiVersion: notification.toolkit.fluxcd.io/v1\n      kind: Receiver\n      stats:\n        failing: 0\n        running: 1\n        suspended: 0\n    - apiVersion: notification.toolkit.fluxcd.io/v1beta3\n      kind: Alert\n      stats:\n        failing: 0\n        running: 1\n        suspended: 0\n    - apiVersion: notification.toolkit.fluxcd.io/v1beta3\n      kind: Provider\n      stats:\n        failing: 0\n        running: 1\n        suspended: 0\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: GitRepository\n      stats:\n        failing: 0\n        running: 2\n        suspended: 0\n        totalSize: 3.7 MiB\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: HelmChart\n      stats:\n        failing: 1\n        running: 55\n        suspended: 0\n        totalSize: 15.7 MiB\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: HelmRepository\n      stats:\n        failing: 0\n        running: 7\n        suspended: 3\n        totalSize: 40.5 MiB\n    - apiVersion: source.toolkit.fluxcd.io/v1beta2\n      kind: Bucket\n      stats:\n        failing: 0\n        running: 0\n        suspended: 0\n    - apiVersion: source.toolkit.fluxcd.io/v1beta2\n      kind: OCIRepository\n      stats:\n        failing: 0\n        running: 1\n        suspended: 0\n        totalSize: 78.1 KiB\n  sync:\n    ready: true\n    id: kustomization/flux-system\n    path: clusters/production\n    source: https://github.com/my-org/my-fleet.git\n    status: 'Applied revision: refs/heads/main@sha1:a90cd1ac35de01c175f7199315d3f4cd60195911'\nstatus:\n  conditions:\n    - lastTransitionTime: \"2024-06-20T19:59:30Z\"\n      message: Reporting finished in 272ms\n      observedGeneration: 4\n      reason: ReconciliationSucceeded\n      status: \"True\"\n      type: Ready\n</code></pre> <p>1. Export the report in YAML format:</p> <pre><code>kubectl -n flux-system get fluxreport/flux -o yaml\n</code></pre> <p>2. Trigger a reconciliation of the report:</p> <pre><code>kubectl -n flux-system annotate --overwrite fluxreport/flux \\\n reconcile.fluxcd.io/requestedAt=\"$(date +%s)\"\n</code></pre> <p>3. Change the report reconciliation interval:</p> <pre><code>kubectl -n flux-system annotate --overwrite fluxreport/flux \\\n fluxcd.controlplane.io/reconcileEvery=5m\n</code></pre> <p>4. Pause the report reconciliation:</p> <pre><code>kubectl -n flux-system annotate --overwrite fluxreport/flux \\\n fluxcd.controlplane.io/reconcile=disabled\n</code></pre> <p>5. Resume the reconciliation of the report:</p> <pre><code> kubectl -n flux-system annotate --overwrite fluxreport/flux \\\n  fluxcd.controlplane.io/reconcile=enabled\n</code></pre>"},{"location":"operator/fluxreport/#reading-a-fluxreport","title":"Reading a FluxReport","text":"<p>As with all other Kubernetes config, a FluxReport is identified by <code>apiVersion</code>, <code>kind</code>, and <code>metadata</code> fields. The <code>spec</code> field contains detailed information about the Flux installation, including statistic data for the Flux custom resources that are reconciled by the Flux controllers.</p>"},{"location":"operator/fluxreport/#cluster-information","title":"Cluster information","text":"<p>The <code>.spec.cluster</code> field contains information about the Kubernetes cluster, including the server version, platform, and the number of nodes.</p>"},{"location":"operator/fluxreport/#distribution-information","title":"Distribution information","text":"<p>The <code>.spec.distribution</code> field contains information about the Flux distribution, including the version, installation status, entitlement issuer, and the tool that is managing the distribution.</p> <p>Example distribution information for when Flux was installed using the bootstrap command:</p> <pre><code>spec:\n  distribution:\n    entitlement: Issued by controlplane\n    managedBy: 'flux bootstrap'\n    status: Installed\n    version: v2.3.0\n</code></pre>"},{"location":"operator/fluxreport/#components-information","title":"Components information","text":"<p>The <code>.spec.components</code> field contains information about the Flux controllers, including the controller name, the image repository, tag, and digest, and the deployment readiness status.</p> <p>Example:</p> <pre><code>spec:\n  components:\n    - image: ghcr.io/fluxcd/kustomize-controller:v1.3.0@sha256:48a032574dd45c39750ba0f1488e6f1ae36756a38f40976a6b7a588d83acefc1\n      name: kustomize-controller\n      ready: true\n      status: 'Current Deployment is available. Replicas: 1'\n    - image: ghcr.io/fluxcd/source-controller:v1.3.0@sha256:161da425b16b64dda4b3cec2ba0f8d7442973aba29bb446db3b340626181a0bc\n      name: source-controller\n      ready: true\n      status: 'Current Deployment is available. Replicas: 1'\n</code></pre>"},{"location":"operator/fluxreport/#operator-information","title":"Operator information","text":"<p>The <code>.spec.operator</code> field contains information about the Flux Operator, including the API version, platform, and version of the operator.</p>"},{"location":"operator/fluxreport/#reconcilers-statistics","title":"Reconcilers statistics","text":"<p>The <code>.spec.reconcilers</code> field contains statistics about the Flux custom resources that are reconciled by the Flux controllers, including the API version, kind, and the number of resources in each state: failing, running, and suspended. For source type resources, the storage size of the locally cached artifacts is also reported.</p> <p>Example:</p> <pre><code>spec:\n  reconcilers:\n    - apiVersion: kustomize.toolkit.fluxcd.io/v1\n      kind: Kustomization\n      stats:\n       failing: 1\n       running: 5\n       suspended: 5\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: GitRepository\n      stats:\n       failing: 1\n       running: 2\n       suspended: 3\n       totalSize: 5.5 MiB\n</code></pre>"},{"location":"operator/fluxreport/#cluster-sync-status","title":"Cluster sync status","text":"<p>The <code>.spec.sync</code> field contains information about the cluster sync status, including the Flux Kustomization name, source URL, the applied revision, and the sync readiness status.</p> <p>Example:</p> <pre><code>spec:\n  sync:\n    ready: true\n    id: kustomization/flux-system\n    path: tests/v2.3/sources\n    source: https://github.com/controlplaneio-fluxcd/distribution.git\n    status: 'Applied revision: refs/heads/main@sha1:a90cd1ac35de01c175f7199315d3f4cd60195911'\n</code></pre>"},{"location":"operator/fluxreport/#generating-a-fluxreport","title":"Generating a FluxReport","text":"<p>The FluxReport is automatically generated by the operator for the following conditions:</p> <ul> <li>At startup, when the operator is installed or upgraded.</li> <li>When the FluxInstance is created or updated.</li> <li>When the <code>reconcile.fluxcd.io/requestedAt</code> annotation is set on the FluxReport resource.</li> <li>At regular intervals, controlled by the <code>fluxcd.controlplane.io/reconcileEvery</code> annotation.</li> </ul>"},{"location":"operator/fluxreport/#reconciliation-configuration","title":"Reconciliation configuration","text":"<p>The reconciliation behaviour can be configured using the following annotations:</p> <ul> <li><code>fluxcd.controlplane.io/reconcile</code>: Enable or disable the reconciliation loop. Default is <code>enabled</code>, set to <code>disabled</code> to pause the reconciliation.</li> <li><code>fluxcd.controlplane.io/reconcileEvery</code>: Set the reconciliation interval. Default is <code>5m</code>.</li> </ul> <p>The default reconciliation interval of the report can be changed with the <code>--reporting-interval</code> flag or by setting the <code>REPORTING_INTERVAL</code> environment variable in the operator deployment.</p>"},{"location":"operator/fluxreport/#flux-resource-metrics","title":"Flux Resource Metrics","text":"<p>The Flux Operator exports metrics for all Flux resources found in the cluster. These metrics are refreshed at the same time with the update of the FluxReport.</p> <p>Metrics:</p> <pre><code>flux_resource_info{uid, kind, name, exported_namespace, ready, suspended, ...}\n</code></pre> <p>Common labels:</p> <ul> <li><code>uid</code>: The Kubernetes unique identifier of the resource.</li> <li><code>kind</code>: The kind of the resource (e.g. <code>GitRepository</code>, <code>Kustomization</code>, etc.).</li> <li><code>name</code>: The name of the resource (e.g. <code>flux-system</code>).</li> <li><code>exported_namespace</code>: The namespace of the resource (e.g. <code>flux-system</code>).</li> <li><code>ready</code>: The readiness status of the resource (e.g. <code>True</code>, <code>False</code> or <code>Unkown</code>).</li> <li><code>reason</code>: The reason for the readiness status (e.g. <code>Progressing</code>, <code>BuildFailed</code>, <code>HealthCheckFailed</code>, etc.).</li> <li><code>suspended</code>: The suspended status of the resource (e.g. <code>True</code> or <code>False</code>).</li> </ul> <p>Specific labels per resource kind:</p> Resource Kind Labels Kustomization <code>revision</code>, <code>source_name</code>, <code>path</code> GitRepository <code>revision</code>, <code>url</code>, <code>ref</code> OCIRepository <code>revision</code>, <code>url</code>, <code>ref</code> Bucket <code>revision</code>, <code>url</code>, <code>ref</code> HelmRelease <code>revision</code>, <code>source_name</code> HelmChart <code>revision</code>, <code>source_name</code> HelmRepository <code>revision</code>, <code>url</code> Receiver <code>url</code> ImageRepository <code>url</code> ImagePolicy <code>source_name</code> ImageUpdateAutomation <code>source_name</code> <p>Example:</p> <pre><code>flux_resource_info{\n    exported_namespace=\"flux-system\",\n    kind=\"Kustomization\",\n    name=\"flux-system\",\n    path=\"production/clusters\",\n    ready=\"True\",\n    reason=\"ReconciliationSucceeded\",\n    revision=\"refs/heads/main@sha1:d3c6dfa21465cc540d214811f46694fee0ce700d\",\n    source_name=\"flux-system\",\n    suspended=\"False\",\n    uid=\"359219f3-0793-4cf0-89a1-990ef1ac8098\"\n}\n</code></pre>"},{"location":"operator/install/","title":"Flux Operator Installation","text":"<p>The Flux Operator is designed to run in a Kubernetes cluster on Linux nodes (AMD64 or ARM64) and is compatible with all major Kubernetes distributions. The operator is written in Go and statically compiled as a single binary with no external dependencies.</p>"},{"location":"operator/install/#install-methods","title":"Install methods","text":"<p>The Flux Operator can be installed with Helm, Terraform, Operator Lifecycle Manager (OLM), or kubectl. It is recommended to install the operator in a dedicated namespace, such as <code>flux-system</code>.</p>"},{"location":"operator/install/#helm","title":"Helm","text":"<p>The Flux Operator can be installed using the Helm chart available in GitHub Container Registry:</p> <pre><code>helm install flux-operator oci://ghcr.io/controlplaneio-fluxcd/charts/flux-operator \\\n  --namespace flux-system \\\n  --create-namespace\n</code></pre>"},{"location":"operator/install/#terraform","title":"Terraform","text":"<p>Installing the Flux Operator with Terraform is possible using the Helm provider:</p> <pre><code>resource \"helm_release\" \"flux_operator\" {\n  name             = \"flux-operator\"\n  namespace        = \"flux-system\"\n  repository       = \"oci://ghcr.io/controlplaneio-fluxcd/charts\"\n  chart            = \"flux-operator\"\n  create_namespace = true\n}\n\nresource \"helm_release\" \"flux_instance\" {\n  depends_on = [helm_release.flux_operator]\n\n  name       = \"flux\"\n  namespace  = \"flux-system\"\n  repository = \"oci://ghcr.io/controlplaneio-fluxcd/charts\"\n  chart      = \"flux-instance\"\n\n  values = [\n    file(\"values/components.yaml\")\n  ]\n}\n</code></pre> <p>For more information of how to configure the Flux instance with Terraform, see the Flux Operator terraform module example.</p>"},{"location":"operator/install/#operator-lifecycle-manager","title":"Operator Lifecycle Manager","text":"<p>The Flux Operator can be installed on OpenShift using the bundle published on OperatorHub at operatorhub.io/operator/flux-operator.</p> <p>Example subscription manifest:</p> <pre><code>apiVersion: operators.coreos.com/v1alpha1\nkind: Subscription\nmetadata:\n  name: flux-operator\n  namespace: flux-system\nspec:\n  channel: stable\n  name: flux-operator\n  source: operatorhubio-catalog\n  sourceNamespace: olm\n  config:\n    env:\n      - name: DEFAULT_SERVICE_ACCOUNT\n        value: \"flux-operator\"\n      - name: DEFAULT_WORKLOAD_IDENTITY_SERVICE_ACCOUNT\n        value: \"flux-operator\"\n      - name: REPORTING_INTERVAL\n        value: \"30s\"\n</code></pre> <p>The Flux Operator is also available in the Openshift and OKD production-ready catalog.</p>"},{"location":"operator/install/#kubectl","title":"Kubectl","text":"<p>The Flux Operator can be installed with <code>kubectl</code> by applying the Kubernetes manifests published on the releases page:</p> <pre><code>kubectl apply -f https://github.com/controlplaneio-fluxcd/flux-operator/releases/latest/download/install.yaml\n</code></pre>"},{"location":"operator/install/#uninstall","title":"Uninstall","text":"<p>Before uninstalling the Flux Operator, make sure to delete the <code>FluxInstance</code> resources with:</p> <pre><code>kubectl -n flux-system delete fluxinstances --all\n</code></pre> <p>The operator will uninstall Flux from the cluster without affecting the Flux-managed workloads.</p> <p>Verify that the Flux controllers have been removed:</p> <pre><code>kubectl -n flux-system get deployments\n</code></pre> <p>Uninstall the Flux Operator with your preferred method, e.g. Helm:</p> <pre><code>helm -n flux-system uninstall flux-operator\n</code></pre>"},{"location":"operator/monitoring/","title":"Flux Monitoring and Reporting","text":"<p>The Flux Operator supervises the Flux controllers and provides a unified view of all the Flux resources that define the GitOps workflows for the target cluster. The operator generates reports, emits events, and exports Prometheus metrics to help with monitoring and troubleshooting Flux.</p>"},{"location":"operator/monitoring/#flux-status-reporting","title":"Flux Status Reporting","text":"<p>The Flux Operator automatically generates a report that reflects the observed state of the Flux installation. The report provides information about the installed components and their readiness, the Flux distribution details, reconcilers statistics, cluster sync status and more.</p> <p>The report is generated as a custom resource of kind <code>FluxReport</code>, named <code>flux</code>, located in the same namespace where the operator is running.</p> <p>Flux installation method</p> <p>The report is available no matter the tool used to install Flux, be it the <code>flux</code> CLI, Terraform, Helm or the Flux Operator itself. For the report to be accurate, the operator must be running in the same namespace where the Flux controllers are deployed.</p> <p>To view the report in YAML format run:</p> <pre><code>kubectl -n flux-system get fluxreport/flux -o yaml\n</code></pre> <p>The operator updates the report at regular intervals, by default every five minutes. To manually trigger the reconciliation of the report, run:</p> <pre><code>kubectl -n flux-system annotate --overwrite fluxreport/flux \\\n reconcile.fluxcd.io/requestedAt=\"$(date +%s)\"\n</code></pre> <p>Find more information about the reporting features in the Flux Report API documentation.</p>"},{"location":"operator/monitoring/#flux-instance-events","title":"Flux Instance Events","text":"<p>The Flux Operator emits events to the Kubernetes API server to report on the status of the Flux instance. The events are useful to monitor the Flux lifecycle and troubleshoot upgrade issues.</p> <p>To list the events related to the Flux instance, run:</p> <pre><code>kubectl -n flux-system events --for fluxinstance/flux\n</code></pre> <p>The Flux Operator integrates with notification-controller. To receive notifications with the events issued by the operator, you can configure alerting as follows:</p> <pre><code>apiVersion: notification.toolkit.fluxcd.io/v1beta3\nkind: Provider\nmetadata:\n  name: slack-bot\n  namespace: flux-system\nspec:\n  type: slack\n  channel: general\n  address: https://slack.com/api/chat.postMessage\n  secretRef:\n    name: slack-bot-token\n---\napiVersion: notification.toolkit.fluxcd.io/v1beta3\nkind: Alert\nmetadata:\n  name: flux-operator\n  namespace: flux-system\nspec:\n  providerRef:\n    name: slack-bot\n  eventSeverity: info\n  eventSources:\n    - kind: FluxInstance\n      name: flux\n</code></pre> <p>Besides Slack, the notification-controller supports other providers like Microsoft Teams, Datadog, Grafana, etc., for more information see the alert provider documentation.</p>"},{"location":"operator/monitoring/#prometheus-metrics","title":"Prometheus Metrics","text":"<p>The Flux Operator exports metrics in the Prometheus format for monitoring and alerting purposes. The metrics are exposed inside the cluster by the <code>flux-operator</code> Kubernetes Service on the <code>8080</code> port.</p> <p>On clusters where the Prometheus Operator is installed, the metrics can be scraped by creating a <code>ServiceMonitor</code> resource as follows:</p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: flux-operator\n  namespace: flux-system\n  labels:\n    release: kube-prometheus-stack\nspec:\n  namespaceSelector:\n    matchNames:\n      - flux-system\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: flux-operator\n  endpoints:\n    - targetPort: 8080\n      path: /metrics\n      interval: 30s\n</code></pre> <p>It is recommended to change the reporting interval to <code>30s</code> when using the Prometheus metrics exported by the operator:</p> <pre><code>helm upgrade flux-operator oci://ghcr.io/controlplaneio-fluxcd/charts/flux-operator \\\n  --namespace flux-system \\\n  --set reporting.interval=30s\n</code></pre> <p>Helm Chart</p> <p>The Flux Operator Helm chart includes a <code>ServiceMonitor</code> resource that can be enabled by setting the <code>serviceMonitor.create</code> value to <code>true</code>.</p> <p>On clusters with Prometheus auto-discovery enabled, the metrics are automatically scraped from the <code>flux-operator</code> pods that have the <code>prometheus.io/scrape: \"true\"</code> annotation.</p>"},{"location":"operator/monitoring/#flux-instance-metrics","title":"Flux Instance Metrics","text":"<p>The Flux Operator exports metrics for the FluxInstance resource. These metrics are refreshed every time the operator reconciles the instance.</p> <p>Metrics:</p> <pre><code>flux_instance_info{uid, kind, name, exported_namespace, ready, suspended, registry, revision}\n</code></pre> <p>Labels:</p> <ul> <li><code>uid</code>: The Kubernetes unique identifier of the resource.</li> <li><code>kind</code>: The kind of the resource (e.g. <code>FluxInstance</code>).</li> <li><code>name</code>: The name of the resource (e.g. <code>flux</code>).</li> <li><code>exported_namespace</code>: The namespace where the resource is deployed (e.g. <code>flux-system</code>).</li> <li><code>ready</code>: The readiness status of the resource (e.g. <code>True</code>, <code>False</code> or <code>Unkown</code>).</li> <li><code>reason</code>: The reason for the readiness status (e.g. <code>Progressing</code>, <code>BuildFailed</code>, <code>HealthCheckFailed</code>, etc.).</li> <li><code>suspended</code>: The suspended status of the resource (e.g. <code>True</code> or <code>False</code>).</li> <li><code>registry</code>: The container registry used by the instance (e.g. <code>ghcr.io/fluxcd</code>).</li> <li><code>revision</code>: The Flux revision installed by the instance (e.g. <code>v2.3.0@sha256:75aa209c6a...</code>).</li> </ul>"},{"location":"operator/monitoring/#flux-resourceset-metrics","title":"Flux ResourceSet Metrics","text":"<p>The Flux Operator exports metrics for the ResourceSet APIs that can be used to monitor the reconciliation status.</p> <p>Metrics:</p> <pre><code>flux_resourceset_info{uid, kind, name, exported_namespace, resources, ready, suspended, revision}\nflux_resourcesetinputprovider_info{uid, kind, name, exported_namespace, ready, suspended, url}\n</code></pre> <p>Labels:</p> <ul> <li><code>uid</code>: The Kubernetes unique identifier of the resource.</li> <li><code>kind</code>: The kind of the resource (e.g. <code>ResourceSet</code>).</li> <li><code>name</code>: The name of the resource (e.g. <code>podinfo</code>).</li> <li><code>exported_namespace</code>: The namespace where the resource is deployed (e.g. <code>apps</code>).</li> <li><code>ready</code>: The readiness status of the resource (e.g. <code>True</code>, <code>False</code> or <code>Unkown</code>).</li> <li><code>reason</code>: The reason for the readiness status (e.g. <code>ReconciliationSucceeded</code>, <code>BuildFailed</code>, <code>HealthCheckFailed</code>, etc.).</li> <li><code>suspended</code>: The suspended status of the resource (e.g. <code>True</code> or <code>False</code>).</li> </ul>"},{"location":"operator/monitoring/#flux-resource-metrics","title":"Flux Resource Metrics","text":"<p>The Flux Operator exports metrics for all Flux resources found in the cluster. These metrics are refreshed at the same time with the update of the FluxReport.</p> <p>Metrics:</p> <pre><code>flux_resource_info{uid, kind, name, exported_namespace, ready, suspended, ...}\n</code></pre> <p>Common labels:</p> <ul> <li><code>uid</code>: The Kubernetes unique identifier of the resource.</li> <li><code>kind</code>: The kind of the resource (e.g. <code>GitRepository</code>, <code>Kustomization</code>, etc.).</li> <li><code>name</code>: The name of the resource (e.g. <code>flux-system</code>).</li> <li><code>exported_namespace</code>: The namespace of the resource (e.g. <code>flux-system</code>).</li> <li><code>ready</code>: The readiness status of the resource (e.g. <code>True</code>, <code>False</code> or <code>Unkown</code>).</li> <li><code>reason</code>: The reason for the readiness status (e.g. <code>Progressing</code>, <code>BuildFailed</code>, <code>HealthCheckFailed</code>, etc.).</li> <li><code>suspended</code>: The suspended status of the resource (e.g. <code>True</code> or <code>False</code>).</li> </ul> <p>Specific labels per resource kind:</p> Resource Kind Labels Kustomization <code>revision</code>, <code>source_name</code>, <code>path</code> GitRepository <code>revision</code>, <code>url</code>, <code>ref</code> OCIRepository <code>revision</code>, <code>url</code>, <code>ref</code> Bucket <code>revision</code>, <code>url</code>, <code>ref</code> HelmRelease <code>revision</code>, <code>source_name</code> HelmChart <code>revision</code>, <code>source_name</code> HelmRepository <code>revision</code>, <code>url</code> Receiver <code>url</code> ImageRepository <code>url</code> ImagePolicy <code>source_name</code> ImageUpdateAutomation <code>source_name</code>"},{"location":"operator/monitoring/#controller-runtime-metrics","title":"Controller Runtime Metrics","text":"<p>The Flux Operator exports Kubernetes controller runtime metrics and Go runtime metrics.</p> <p>Relevant metrics for troubleshooting:</p> <ul> <li><code>controller_runtime_reconcile_errors_total{controller}</code>: Total number of reconciliation errors per controller.</li> <li><code>rest_client_requests_total{code, method}</code>: Number of Kubernetes API requests, partitioned by status code and method.</li> <li><code>go_memstats_alloc_bytes</code>: Number of bytes allocated and still in use.</li> <li><code>go_goroutines</code>: Number of goroutines that currently exist.</li> <li><code>workqueue_longest_running_processor_seconds</code>: Longest time a workqueue item has been processed.</li> </ul>"},{"location":"operator/resourceset/","title":"ResourceSet CRD","text":"<p>ResourceSet is a declarative API for generating a group of Kubernetes objects based on a matrix of input values and a set of templated resources.</p>"},{"location":"operator/resourceset/#example","title":"Example","text":"<p>The following example shows a ResourceSet that generates an application instance consisting of a Flux HelmRelease and OCIRepository for each tenant with a specific version and replica count.</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSet\nmetadata:\n  name: podinfo\n  namespace: default\n  annotations:\n    fluxcd.controlplane.io/reconcile: \"enabled\"\n    fluxcd.controlplane.io/reconcileEvery: \"30m\"\n    fluxcd.controlplane.io/reconcileTimeout: \"5m\"\nspec:\n  commonMetadata:\n    labels:\n      app.kubernetes.io/name: podinfo\n  inputs:\n    - tenant: \"team1\"\n      app:\n       version: \"6.7.x\"\n       replicas: 2\n    - tenant: \"team2\"\n      app:\n       version: \"6.6.x\"\n       replicas: 3\n  resources:\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: OCIRepository\n      metadata:\n        name: podinfo-&lt;&lt; inputs.tenant &gt;&gt;\n        namespace: default\n      spec:\n        interval: 10m\n        url: oci://ghcr.io/stefanprodan/charts/podinfo\n        ref:\n          semver: &lt;&lt; inputs.app.version | quote &gt;&gt;\n    - apiVersion: helm.toolkit.fluxcd.io/v2\n      kind: HelmRelease\n      metadata:\n        name: podinfo-&lt;&lt; inputs.tenant &gt;&gt;\n        namespace: default\n      spec:\n        interval: 1h\n        releaseName: podinfo-&lt;&lt; inputs.tenant &gt;&gt;\n        chartRef:\n          kind: OCIRepository\n          name: podinfo-&lt;&lt; inputs.tenant &gt;&gt;\n        values:\n          replicaCount: &lt;&lt; inputs.app.replicas | int &gt;&gt;\n</code></pre> <p>You can run this example by saving the manifest into <code>podinfo.yaml</code>.</p> <p>1. Apply the ResourceSet on the cluster:</p> <pre><code>kubectl apply -f podinfo.yaml\n</code></pre> <p>2. Wait for the ResourceSet to reconcile the generated resources:</p> <pre><code>kubectl wait resourceset/podinfo --for=condition=ready --timeout=5m\n</code></pre> <p>3. Run <code>kubectl get resourceset</code> to see the status of the resource:</p> <pre><code>$ kubectl get resourceset\nNAME      AGE   READY   STATUS\npodinfo   59s   True    Reconciliation finished in 52s\n</code></pre> <p>4. Run <code>kubectl describe resourceset</code> to see the reconciliation status conditions and events:</p> <pre><code>$ kubectl describe resourceset podinfo\nStatus:\n  Conditions:\n    Last Transition Time:  2024-09-24T09:58:53Z\n    Message:               Reconciliation finished in 52s\n    Observed Generation:   1\n    Reason:                ReconciliationSucceeded\n    Status:                True\n    Type:                  Ready\nEvents:\n  Type    Reason          Age   From           Message\n  ----    ------          ----  ----           -------\n  Normal  ApplySucceeded  72s   flux-operator  HelmRelease/default/podinfo-team1 created\n                                               HelmRelease/default/podinfo-team2 created\n                                               OCIRepository/default/podinfo-team1 created\n                                               OCIRepository/default/podinfo-team2 created\n  Normal  ReconciliationSucceeded  72s  flux-operator  Reconciliation finished in 52s\n</code></pre> <p>5. Run <code>kubectl events</code> to see the events generated by the flux-operator:</p> <pre><code>kubectl events --for resourceset/podinfo\n</code></pre> <p>6. Run <code>kubectl delete</code> to remove the ResourceSet and its generated resources:</p> <pre><code>kubectl delete resourceset podinfo\n</code></pre>"},{"location":"operator/resourceset/#writing-a-resourceset-spec","title":"Writing a ResourceSet spec","text":"<p>As with all other Kubernetes config, a ResourceSet needs <code>apiVersion</code>, <code>kind</code>, <code>metadata.name</code> and <code>metadata.namespace</code> fields. The name of a ResourceSet object must be a valid DNS subdomain name. A ResourceSet also needs a <code>.spec</code> section.</p>"},{"location":"operator/resourceset/#inputs-configuration","title":"Inputs configuration","text":"<p>The <code>.spec.inputs</code> field is optional and specifies a list of input values to be used in the resources templates.</p> <p>An input value is a key-value pair of strings and structs, where the key is the input name which can be referenced in the resource templates using the <code>&lt;&lt; inputs.name &gt;&gt;</code> syntax.</p> <p>Example of static inputs:</p> <pre><code>spec:\n  inputs:\n   - tenant: team1\n     role: restricted\n   - tenant: team2\n     role: privileged\n</code></pre> <p>The <code>.spec.inputsFrom</code> field is optional and specifies a list of ResourceSetInputProvider references to objects that provide input values to the ResourceSet. It has the following subfields (exactly one of them must be set):</p> <ul> <li><code>apiVersion</code>: The API version of the referenced object. Must be   <code>fluxcd.controlplane.io/v1</code>. Optional.</li> <li><code>kind</code>: The kind of the referenced object. Must be   <code>ResourceSetInputProvider</code>. Optional.</li> <li><code>.name</code>: The name of a <code>ResourceSetInputProvider</code> object in the same namespace   as the <code>ResourceSet</code>. Optional.</li> <li><code>.selector</code>: A label selector to select multiple <code>ResourceSetInputProvider</code>   objects in the same namespace as the <code>ResourceSet</code>. Optional.</li> </ul> <p>Example of inputs generated from GitHub Pull Requests:</p> <pre><code>spec:\n  inputsFrom:\n    - apiVersion: fluxcd.controlplane.io/v1\n      kind: ResourceSetInputProvider\n      name: podinfo-pull-requests\n</code></pre> <p>Example of inputs generated from multiple <code>ResourceSetInputProvider</code> objects via Label Selectors:</p> <pre><code>spec:\n  inputsFrom:\n    - apiVersion: fluxcd.controlplane.io/v1\n      kind: ResourceSetInputProvider\n      selector:\n        matchLabels:\n          app: podinfo\n        matchExpressions:\n          - key: environment\n            operator: In\n            values:\n              - dev\n              - staging\n</code></pre> <p>At runtime, the operator will fetch the input values every time the <code>ResourceSetInputProvider</code> reconciler detects a change in the upstream source.</p> <p>When both <code>.spec.inputs</code> and <code>.spec.inputsFrom</code> are set, the resulting inputs are the flattened concatenation of the <code>.spec.inputs</code> input sets with the input sets from each selected <code>ResourceSetInputProvider</code> object.</p>"},{"location":"operator/resourceset/#input-strategy","title":"Input strategy","text":"<p>By default, the resulting inputs are the flattened concatenation of the <code>.spec.inputs</code> input sets with the input sets from each selected <code>ResourceSetInputProvider</code> object. The <code>.spec.inputStrategy</code> field can be set to change this default behavior.</p> <p>The <code>.spec.inputStrategy</code> field has the following subfields:</p> <ul> <li><code>.name</code>: The name of the input strategy. If <code>.spec.inputStrategy</code> is not set, the behavior   matches setting <code>.spec.inputStrategy.name</code> to <code>Flatten</code>. Supported values are <code>Flatten</code> and   <code>Permute</code>.</li> </ul> <p>When <code>.spec.inputStrategy.name</code> is set to <code>Permute</code>, the resulting inputs are the Cartesian product of the input sets from each selected <code>ResourceSetInputProvider</code> object, and from the <code>ResourceSet</code> object itself if <code>.spec.inputs</code> is set. Therefore, the total amount of permutations, i.e. input sets, is the product of the number of input sets from each source, i.e. <code>A_1 x A_2 x ... x A_n</code>, where <code>A_i</code> is the number of input sets from the <code>i</code>-th source.</p> <p>Note: The combinatorial explosion of the <code>Permute</code> strategy can lead to a very large number of permutations and can impact the performance of the operator. It is recommended to use this strategy together with <code>ResourceSetInputProvider</code> filters to export only a single input set per <code>ResourceSetInputProvider</code> object. If the number of permutations exceeds <code>10000</code>, the operator will fail the reconciliation of the <code>ResourceSet</code> with a <code>Stalled</code> condition.</p> <p>When merging the input sets from each object, the <code>Permute</code> strategy places each input set under a key that is the normalized name of the object providing the input set. The normalization process is as follows:</p> <ol> <li>Uppercase letters are converted to lowercase.</li> <li>Spaces and punctuation (including <code>-</code>) are converted to underscores (<code>_</code>).</li> <li>All characters not in the set [a-z0-9_] are removed.</li> <li>The remaining string is split by underscores and the resulting non-empty words are rejoined with underscores.</li> </ol> <p>The name normalization applied by the <code>Permute</code> strategy ensures that the resulting key is compatible with the templating engine used in the resources templates.</p> <p>Example of the <code>Permute</code> strategy with two <code>ResourceSetInputProvider</code> objects, one selecting a single Git tag and the other selecting a single OCI tag:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSet\nmetadata:\n  name: my-rset\n  namespace: default\nspec:\n  inputStrategy:\n    name: Permute\n  inputs:\n    - id: id1\n      someField: foo\n    - id: id2\n      someField: bar\n  inputsFrom:\n    - kind: ResourceSetInputProvider\n      name: git-tag\n    - kind: ResourceSetInputProvider\n      name: oci-tag\n  resources:\n    - apiVersion: v1\n      kind: ConfigMap\n      metadata:\n        name: my-cm-&lt;&lt; inputs.id &gt;&gt;\n        namespace: default\n      data:\n        rsetID: &lt;&lt; inputs.my_rset.id | quote &gt;&gt;\n        rsipGitID: &lt;&lt; inputs.git_tag.id | quote &gt;&gt;\n        rsipOCIID: &lt;&lt; inputs.oci_tag.id | quote &gt;&gt;\n        someField: &lt;&lt; inputs.my_rset.someField | quote &gt;&gt;\n        sha: &lt;&lt; inputs.git_tag.sha | quote &gt;&gt;\n        digest: &lt;&lt; inputs.oci_tag.digest | quote &gt;&gt;\n</code></pre> <p>In the example above, the resulting input sets are similar to the following:</p> <pre><code>- id: \"768965678\"\n  my_rset:\n    id: id1\n    someField: foo\n  git_tag:\n    id: \"8765674567\"\n    sha: bf5d6e01cf802734853f6f3417b237e3ad0ba35d\n  oci_tag:\n    id: \"9876543210\"\n    digest: sha256:d4ec9861522d4961b2acac5a070ef4f92d732480dff2062c2f3a1dcf9a5d1e91\n- id: \"234567654\"\n  my_rset:\n    id: id2\n    someField: bar\n  git_tag:\n    id: \"8765674567\"\n    sha: bf5d6e01cf802734853f6f3417b237e3ad0ba35d\n  oci_tag:\n    id: \"9876543210\"\n    digest: sha256:d4ec9861522d4961b2acac5a070ef4f92d732480dff2062c2f3a1dcf9a5d1e91\n</code></pre> <p>This will generate two <code>ConfigMap</code> resources, one whose name will be <code>my-cm-768965678</code>, and the other <code>my-cm-234567654</code>, each containing the rendered <code>.data</code> according to the input set.</p>"},{"location":"operator/resourceset/#resources-configuration","title":"Resources configuration","text":"<p>The <code>.spec.resources</code> field is optional and specifies the list of Kubernetes resource to be generated and reconciled on the cluster.</p> <p>The resources can be templated using the <code>&lt;&lt; inputs.name &gt;&gt;</code> syntax. The templating engine is based on Go text template. The <code>&lt;&lt;  &gt;&gt;</code> delimiters are used instead of <code>{{  }}</code> to avoid conflicts with Helm templating and allow ResourceSets to be included in Helm charts.</p> <p>Example of templated resources:</p> <pre><code>spec:\n  inputs:\n    - tenant: team1\n      role: admin\n    - tenant: team2\n      role: cluster-admin\n  resources:\n    - apiVersion: v1\n      kind: Namespace\n      metadata:\n        name: &lt;&lt; inputs.tenant &gt;&gt;\n    - apiVersion: v1\n      kind: ServiceAccount\n      metadata:\n        name: flux\n        namespace: &lt;&lt; inputs.tenant &gt;&gt;\n    - apiVersion: rbac.authorization.k8s.io/v1\n      kind: RoleBinding\n      metadata:\n        name: flux\n        namespace: &lt;&lt; inputs.tenant &gt;&gt;\n      subjects:\n        - kind: ServiceAccount\n          name: flux\n          namespace: &lt;&lt; inputs.tenant &gt;&gt;\n          roleRef:\n            kind: ClusterRole\n            name: &lt;&lt; inputs.role &gt;&gt;\n            apiGroup: rbac.authorization.k8s.io\n</code></pre> <p>The above example will generate a <code>Namespace</code>, <code>ServiceAccount</code> and <code>RoleBinding</code> for each tenant with the specified role.</p>"},{"location":"operator/resourceset/#templating-functions","title":"Templating functions","text":"<p>The templating engine supports slim-sprig functions.</p> <p>It is recommended to use the <code>quote</code> function when templating strings to avoid issues with special characters e.g. <code>&lt;&lt; inputs.version | quote &gt;&gt;</code>.</p> <p>When templating integers, use the <code>int</code> function to convert the string to an integer e.g. <code>&lt;&lt; inputs.replicas | int &gt;&gt;</code>.</p> <p>When using integer or boolean inputs as metadata label values, use the <code>quote</code> function to convert the value to a string e.g. <code>&lt;&lt; inputs.enabled | quote &gt;&gt;</code>.</p> <p>When templating nested fields, use the <code>toYaml</code>  and <code>nindent</code> functions to properly format the string e.g.:</p> <pre><code>spec:\n  inputs:\n    - tenant: team1\n      layerSelector:\n        mediaType: \"application/vnd.cncf.helm.chart.content.v1.tar+gzip\"\n        operation: copy\n  resources:\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: OCIRepository\n      metadata:\n        name: &lt;&lt; inputs.tenant &gt;&gt;\n      spec:\n        layerSelector: &lt;&lt; inputs.layerSelector | toYaml | nindent 4 &gt;&gt;\n</code></pre> <p>To assign a default value when an input field is not specified, use <code>get</code> combined with <code>default</code>. E.g. using the namespace input as a default value for name:</p> <pre><code>spec:\n  inputs:\n    - namespace: team1\n  resources:\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: OCIRepository\n      metadata:\n        name: &lt;&lt; get inputs \"name\" | default inputs.namespace &gt;&gt;\n        namespace: &lt;&lt; inputs.namespace &gt;&gt;\n</code></pre> <p>In addition to the slim-sprig functions, a <code>slugify</code> function is available to normalize a string for use in a Kubernetes label value e.g. <code>&lt;&lt; inputs.tenant | slugify &gt;&gt;</code>.</p>"},{"location":"operator/resourceset/#resource-deduplication","title":"Resource deduplication","text":"<p>The flux-operator deduplicates resources based on the <code>apiVersion</code>, <code>kind</code>, <code>metadata.name</code> and <code>metadata.namespace</code> fields.</p> <p>This allows defining shared resources that are applied only once, regardless of the number of inputs.</p> <p>Example of a shared Flux source:</p> <pre><code>spec:\n  inputs:\n    - tenant: \"team1\"\n      replicas: \"2\"\n    - tenant: \"team2\"\n      replicas: \"3\"\n  resources:\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: OCIRepository\n      metadata:\n        name: podinfo\n        namespace: default\n      spec:\n        interval: 10m\n        url: oci://ghcr.io/stefanprodan/charts/podinfo\n        ref:\n          semver: '*'\n    - apiVersion: helm.toolkit.fluxcd.io/v2\n      kind: HelmRelease\n      metadata:\n        name: podinfo-&lt;&lt; inputs.tenant &gt;&gt;\n        namespace: default\n      spec:\n        interval: 1h\n        releaseName: podinfo-&lt;&lt; inputs.tenant &gt;&gt;\n        chartRef:\n          kind: OCIRepository\n          name: podinfo\n        values:\n          replicaCount: &lt;&lt; inputs.replicas | int &gt;&gt;\n</code></pre> <p>In the above example, the <code>OCIRepository</code> resource is created only once and referred by all <code>HelmRelease</code> resources.</p>"},{"location":"operator/resourceset/#copying-data-from-existing-configmaps-and-secrets","title":"Copying data from existing ConfigMaps and Secrets","text":"<p>To generate resources with data copied from existing ConfigMaps and Secrets, the <code>fluxcd.controlplane.io/copyFrom: namespace/name</code> annotation must be set in the ConfigMap or Secret template.</p> <p>Example of copying data from an existing ConfigMap and Secret:</p> <pre><code>spec:\n  inputs:\n    - tenant: \"team1\"\n    - tenant: \"team2\"\n  resources:\n    - apiVersion: v1\n      kind: Namespace\n      metadata:\n        name: &lt;&lt; inputs.tenant &gt;&gt;\n    - apiVersion: v1\n      kind: ConfigMap\n      metadata:\n        name: runtime-info\n        namespace: &lt;&lt; inputs.tenant &gt;&gt;\n        annotations:\n          fluxcd.controlplane.io/copyFrom: \"flux-system/runtime-info\"\n    - apiVersion: v1\n      kind: Secret\n      metadata:\n        name: docker-auth\n        namespace: &lt;&lt; inputs.tenant &gt;&gt;\n        annotations:\n          fluxcd.controlplane.io/copyFrom: \"flux-system/docker-auth\"\n</code></pre> <p>In the above example, a ConfigMap and a Secret are generated for each tenant with the data copied from the <code>runtime-info</code> and <code>docker-auth</code> ConfigMap and Secret from the <code>flux-system</code> namespace. If the source data changes, the operator will update the generated resources accordingly on the next reconciliation interval.</p> <p>Note that on multi-tenant clusters, the service account used by the ResourceSet must have the necessary permissions to read the ConfigMaps and Secrets from the source namespace.</p> <p>To trigger a reconciliation of the ResourceSet when changes occur in the source ConfigMap or Secret, you can set the following label on the source ConfigMap or Secret:</p> <pre><code>metadata:\n  labels:\n    reconcile.fluxcd.io/watch: Enabled\n</code></pre> <p>Note that neither this label nor any other metadata is copied to the generated ConfigMaps and Secrets, you must label every ConfigMap or Secret that you want to watch for changes.</p> <p>An alternative to labeling every ConfigMap or Secret is setting the <code>--watch-configs-label-selector=owner!=helm</code> flag in flux-operator, which allows watching all ConfigMaps and Secrets except for Helm storage Secrets.</p>"},{"location":"operator/resourceset/#conditional-resource-exclusion","title":"Conditional resource exclusion","text":"<p>To exclude a resource based on input values, the <code>fluxcd.controlplane.io/reconcile</code> annotation can be set to <code>disabled</code> on the resource metadata. This will prevent the resource from being reconciled by the operator.</p> <p>Example of excluding a resource based on an input value:</p> <pre><code>spec:\n  inputs:\n    - tenant: \"team1\"\n    - tenant: \"team2\"\n  resources:\n    - apiVersion: v1\n      kind: Namespace\n      metadata:\n        name: &lt;&lt; inputs.tenant &gt;&gt;\n    - apiVersion: v1\n      kind: ServiceAccount\n      metadata:\n        name: flux\n        namespace: &lt;&lt; inputs.tenant &gt;&gt;\n        annotations:\n          fluxcd.controlplane.io/reconcile: &lt;&lt; if eq inputs.tenant \"team1\" &gt;&gt;enabled&lt;&lt; else &gt;&gt;disabled&lt;&lt; end &gt;&gt;\n</code></pre> <p>In the above example, the <code>ServiceAccount</code> resource is generated only for the <code>team1</code> tenant.</p>"},{"location":"operator/resourceset/#built-in-input-fields","title":"Built-in input fields","text":"<p>When computing all the input sets for generating the resource matrix, the operator adds a few built-in fields to each input set. Users cannot override these fields.</p> <p>Every input set contains a built-in <code>inputs.id</code> field that is a unique identifier for the input set amongst all the input sets generated for the ResourceSet. This field can be used in the resource templates to generate unique resource names.</p> <p>Every input set also contains the reference of the object providing those inputs:</p> <ul> <li><code>inputs.provider.apiVersion</code>: The API version of the object providing the inputs.</li> <li><code>inputs.provider.kind</code>: The kind of the object providing the inputs.</li> <li><code>inputs.provider.name</code>: The name of the object providing the inputs.</li> <li><code>inputs.provider.namespace</code>: The namespace of the object providing the inputs.</li> </ul> <p>In the case of inline inputs provided directly in the <code>ResourceSet</code> object through the <code>.spec.inputs</code> field, <code>inputs.provider.apiVersion</code> is <code>fluxcd.controlplane.io/v1</code> and <code>inputs.provider.kind</code> is <code>ResourceSet</code>.</p> <p>In the case of inputs provided through a <code>ResourceSetInputProvider</code> referenced in the <code>.spec.inputsFrom</code> field of a <code>ResourceSet</code>, <code>inputs.provider.apiVersion</code> is <code>fluxcd.controlplane.io/v1</code> and <code>inputs.provider.kind</code> is <code>ResourceSetInputProvider</code>.</p> <p>If the <code>.spec.inputStrategy.name</code> field is set to <code>Permute</code>, the built-in fields above are nested under a key that is the normalized name of the object providing the inputs, i.e.:</p> <ul> <li><code>inputs.&lt;normalized object name&gt;.id</code></li> <li><code>inputs.&lt;normalized object name&gt;.provider.apiVersion</code></li> <li><code>inputs.&lt;normalized object name&gt;.provider.kind</code></li> <li><code>inputs.&lt;normalized object name&gt;.provider.name</code></li> <li><code>inputs.&lt;normalized object name&gt;.provider.namespace</code></li> </ul> <p>And <code>inputs.id</code> will be derived from the permutation configuration, making each permutation have a unique ID.</p>"},{"location":"operator/resourceset/#resources-template","title":"Resources template","text":"<p>The <code>.spec.resourcesTemplate</code> field is optional and offers an alternative to the <code>.spec.resources</code>. The <code>.spec.resourcesTemplate</code> is a single string that contains the multi-document YAML of the resources definitions. This field can be used for complex templating scenarios with the trade-off of reduced readability.</p> <p>Note that when both <code>.spec.resources</code> and <code>.spec.resourcesTemplate</code> are set, the resulting resources are the union of the two. If duplicate resources are defined in both fields, the resources from <code>.spec.resources</code> take precedence.</p> <p>Example of a template containing conditional and repeated blocks:</p> <pre><code>spec:\n  inputs:\n    - bundle: addons\n      decryption: false\n      components:\n        - ingress-nginx\n        - cert-manager\n    - bundle: apps\n      decryption: true\n      components:\n        - frontend\n        - backend\n  resourcesTemplate: |\n    ---\n    apiVersion: source.toolkit.fluxcd.io/v1\n    kind: OCIRepository\n    metadata:\n      name: &lt;&lt; inputs.bundle &gt;&gt;\n      namespace: flux-system\n    spec:\n      interval: 10m\n      url: oci://registry.example.com/&lt;&lt; inputs.bundle &gt;&gt;\n    &lt;&lt;- range $component := inputs.components &gt;&gt;\n    ---\n    apiVersion: kustomize.toolkit.fluxcd.io/v1\n    kind: Kustomization\n    metadata:\n      name: &lt;&lt; $component &gt;&gt;\n      namespace: flux-system\n    spec:\n      interval: 1h\n      prune: true\n      &lt;&lt;- if inputs.decryption &gt;&gt;\n      decryption:\n        provider: sops\n        secretRef:\n          name: &lt;&lt; inputs.bundle &gt;&gt;-sops\n      &lt;&lt;- end &gt;&gt;\n      sourceRef:\n        kind: OCIRepository\n        name: &lt;&lt; inputs.bundle &gt;&gt;\n      path: ./&lt;&lt; $component &gt;&gt;\n    &lt;&lt;- end &gt;&gt;\n</code></pre> <p>The above example generates two <code>OCIRepository</code> resources (one for each bundle) and four <code>Kustomization</code> resources (one for each component in each bundle).</p>"},{"location":"operator/resourceset/#common-metadata","title":"Common metadata","text":"<p>The <code>.spec.commonMetadata</code> field is optional and specifies common metadata to be applied to all resources.</p> <p>It has two optional fields:</p> <ul> <li><code>labels</code>: A map used for setting labels   on an object. Any existing label will be overridden if it matches with a key in   this map.</li> <li><code>annotations</code>: A map used for setting annotations   on an object. Any existing annotation will be overridden if it matches with a key   in this map.</li> </ul> <p>Example common metadata:</p> <pre><code>spec:\n  commonMetadata:\n    labels:\n      app.kubernetes.io/name: podinfo\n    annotations:\n      fluxcd.controlplane.io/prune: disabled\n</code></pre> <p>In the above example, all resources generated by the ResourceSet will not be pruned by the garbage collection process as the <code>fluxcd.controlplane.io/prune</code> annotation is set to <code>disabled</code>.</p>"},{"location":"operator/resourceset/#dependency-management","title":"Dependency management","text":"<p><code>.spec.dependsOn</code> is an optional list used to refer to Kubernetes objects that the ResourceSet depends on. If specified, then the ResourceSet is reconciled after the referred objects exist in the cluster.</p> <p>A dependency is a reference to a Kubernetes object with the following fields:</p> <ul> <li><code>apiVersion</code>: The API version of the referred object (required).</li> <li><code>kind</code>: The kind of the referred object (required).</li> <li><code>name</code>: The name of the referred object (required).</li> <li><code>namespace</code>: The namespace of the referred object (optional).</li> <li><code>ready</code>: A boolean indicating if the referred object must have the <code>Ready</code> status condition set to <code>True</code> (optional, default is <code>false</code>).</li> <li><code>readyExpr</code>: A CEL expression that evaluates to a boolean indicating if the referred object is ready (optional).</li> </ul> <p>Example of conditional reconciliation based on the existence of CustomResourceDefinitions and the readiness of a ResourceSet:</p> <pre><code>spec:\n  dependsOn:\n    - apiVersion: apiextensions.k8s.io/v1\n      kind: CustomResourceDefinition\n      name: helmreleases.helm.toolkit.fluxcd.io\n      ready: true\n    - apiVersion: apiextensions.k8s.io/v1\n      kind: CustomResourceDefinition\n      name: servicemonitors.monitoring.coreos.com\n    - apiVersion: fluxcd.controlplane.io/v1\n      kind: ResourceSet\n      name: cluster-addons\n      namespace: flux-system\n      ready: true\n</code></pre> <p>Note that is recommended to define dependencies on CustomResourceDefinitions if the ResourceSet deploys Flux HelmReleases which contain custom resources.</p> <p>When the dependencies are not met, the flux-operator will reevaluate the requirements every five seconds and reconcile the ResourceSet when the dependencies are satisfied. Failed dependencies are reported in the ResourceSet <code>Ready</code> status condition, in log messages and Kubernetes events.</p>"},{"location":"operator/resourceset/#cel-readiness-expressions","title":"CEL readiness expressions","text":"<p>The <code>readyExpr</code> field allows for more complex readiness checks and can be used for gating the reconciliation of a ResourceSet based on the evaluation of the CEL expression.</p> <p>The expression is evaluated in the context of the referred object and has access to all the fields of the object, including the status conditions and the status subfields. The expression must evaluate to a boolean value, any syntax or runtime errors will be reported in the ResourceSet status conditions.</p> <p>Example readiness expression:</p> <pre><code>spec:\n  dependsOn:\n    - apiVersion: cluster.x-k8s.io/v1beta1\n      kind: Cluster\n      name: my-cluster\n      namespace: dev\n      ready: true\n      readyExpr: |\n        metadata.generation == status.observedGeneration &amp;&amp;\n        status.controlPlaneReady == true\n    - apiVersion: v1\n      kind: Secret\n      name: my-gate\n      namespace: dev\n      ready: true\n      readyExpr: |\n        string(base64.decode(data.gate)) == 'opened'\n</code></pre> <p>For testing the CEL expressions, you can use the CEL playground.</p>"},{"location":"operator/resourceset/#reconciliation-configuration","title":"Reconciliation configuration","text":"<p>The reconciliation behavior of a ResourceSet can be configured using the following annotations:</p> <ul> <li><code>fluxcd.controlplane.io/reconcile</code>:   Enable or disable the reconciliation loop. Default is <code>enabled</code>, set to <code>disabled</code> to pause the reconciliation.</li> <li><code>fluxcd.controlplane.io/reconcileEvery</code>:   Set the reconciliation interval used for drift detection and correction. Default is <code>1h</code>.</li> <li><code>fluxcd.controlplane.io/reconcileTimeout</code>:   Set the reconciliation timeout including health checks. Default is <code>5m</code>.</li> <li><code>fluxcd.controlplane.io/force</code>:   When set to <code>enabled</code>, the controller will replace the generated resources that contain immutable field changes.   This annotation can also be used on individual resources to force their reconciliation.</li> </ul>"},{"location":"operator/resourceset/#health-check-configuration","title":"Health check configuration","text":"<p>The <code>.spec.wait</code> field is optional and instructs the flux-operator to perform a health check on all applied resources and waits for them to become ready. The health check is disabled by default and can be enabled by setting the <code>.spec.wait</code> field to <code>true</code>.</p> <p>The health check is performed for the following resources types:</p> <ul> <li>Kubernetes built-in kinds: Deployment, DaemonSet, StatefulSet,   PersistentVolumeClaim, Service, Ingress, CustomResourceDefinition.</li> <li>Flux kinds: HelmRelease, OCIRepository, Kustomization, GitRepository, etc.</li> <li>Custom resources that are compatible with kstatus.</li> </ul> <p>By default, the wait timeout is <code>5m</code> and can be changed with the <code>fluxcd.controlplane.io/reconcileTimeout</code> annotation, set on the ResourceSet object.</p>"},{"location":"operator/resourceset/#role-based-access-control","title":"Role-based access control","text":"<p>The <code>.spec.serviceAccountName</code> field is optional and specifies the name of the Kubernetes ServiceAccount used by the flux-operator to reconcile the ResourceSet. The ServiceAccount must exist in the same namespace as the ResourceSet and must have the necessary permissions to create, update and delete the resources defined in the ResourceSet.</p> <p>On multi-tenant clusters, it is recommended to use a dedicated ServiceAccount per tenant namespace with the minimum required permissions. To enforce a ServiceAccount for all ResourceSets, the <code>--default-service-account=flux-operator</code> flag can be set in the flux-operator container arguments. With this flag set, only the ResourceSets created in the same namespace as the flux-operator will run with cluster-admin permissions.</p> <p>When installing the Flux Operator with Helm, you can change the default service account name with:</p> <pre><code>helm install flux-operator oci://ghcr.io/controlplaneio-fluxcd/charts/flux-operator \\\n  --namespace flux-system \\\n  --create-namespace \\\n  --set multitenancy.enabled=true \\\n  --set multitenancy.defaultServiceAccount=flux-operator\n</code></pre> <p>When installing the Flux Operator on OpenShift from OperatorHub, the default service account name can be changed by setting the <code>DEFAULT_SERVICE_ACCOUNT</code> environment variable using the OLM Subscription <code>.spec.config.env</code> field.</p>"},{"location":"operator/resourceset/#garbage-collection","title":"Garbage collection","text":"<p>The operator performs garbage collection of the resources previously generated by a ResourceSet that are no longer present in the current revision. Garbage collection is also performed when a ResourceSet object is deleted, triggering a removal of all Kubernetes objects previously applied on the cluster.</p> <p>The garbage collection process removes stale resources in stages, first it deletes the Flux custom resources and waits for the Flux Kustomizations and HelmReleases to be finalized by the controllers. After the Flux resources are removed (max wait is one minute), the operator proceeds with the deletion of the remaining Kubernetes objects. This ensures that the Flux controllers have a chance to clean up the resources they manage before the operator deletes the Kubernetes ServiceAccount and RoleBinding used by Flux impersonation.</p> <p>After the garbage collection process is completed, the operator issues a Kubernetes event containing the list of removed resources and the duration of the cleanup.</p> <p>The garbage collection is enabled by default and can be disabled for certain resources by setting the <code>fluxcd.controlplane.io/prune</code> annotation to <code>disabled</code>. To fully disable the garbage collection for a ResourceSet, the annotation must be set on all resources using the <code>.spec.commonMetadata</code> field.</p>"},{"location":"operator/resourceset/#resourceset-status","title":"ResourceSet Status","text":""},{"location":"operator/resourceset/#conditions","title":"Conditions","text":"<p>A ResourceSet enters various states during its lifecycle, reflected as Kubernetes Conditions. It can be reconciling while applying the resources on the cluster, it can be ready, it can fail during reconciliation, or it can fail due to misconfiguration.</p> <p>The ResourceSet API is compatible with the kstatus specification, and reports <code>Reconciling</code> and <code>Stalled</code> conditions where applicable to provide better (timeout) support to solutions polling the ResourceSet to become <code>Ready</code>.</p>"},{"location":"operator/resourceset/#reconciling-resourceset","title":"Reconciling ResourceSet","text":"<p>The flux-operator marks a ResourceSet as reconciling when it starts the reconciliation of the same. The Condition added to the ResourceSet's <code>.status.conditions</code> has the following attributes:</p> <ul> <li><code>type: Reconciling</code></li> <li><code>status: \"True\"</code></li> <li><code>reason: Progressing</code> | <code>reason: ProgressingWithRetry</code></li> </ul> <p>The Condition <code>message</code> is updated during the course of the reconciliation to report the action being performed at any particular moment such as building manifests, detecting drift, etc.</p> <p>The <code>Ready</code> Condition's <code>status</code> is also marked as <code>Unknown</code>.</p>"},{"location":"operator/resourceset/#ready-resourceset","title":"Ready ResourceSet","text":"<p>The flux-operator marks a ResourceSet as ready when the resources were built and applied on the cluster and all health checks are observed to be passing.</p> <p>When the ResourceSet is \"ready\", the flux-operator sets a Condition with the following attributes in the ResourceSet\u2019s <code>.status.conditions</code>:</p> <ul> <li><code>type: Ready</code></li> <li><code>status: \"True\"</code></li> <li><code>reason: ReconciliationSucceeded</code></li> </ul>"},{"location":"operator/resourceset/#failed-resourceset","title":"Failed ResourceSet","text":"<p>The flux-operator may get stuck trying to reconcile and apply a ResourceSet without completing. This can occur due to some of the following factors:</p> <ul> <li>The dependencies are not ready.</li> <li>The templating of the resources fails.</li> <li>The resources are invalid and cannot be applied.</li> <li>Garbage collection fails.</li> <li>Running health checks fails.</li> </ul> <p>When this happens, the flux-operator sets the <code>Ready</code> Condition status to False and adds a Condition with the following attributes to the ResourceSet\u2019s <code>.status.conditions</code>:</p> <ul> <li><code>type: Ready</code></li> <li><code>status: \"False\"</code></li> <li><code>reason: DependencyNotReady | BuildFailed | ReconciliationFailed | HealthCheckFailed</code></li> </ul> <p>The <code>message</code> field of the Condition will contain more information about why the reconciliation failed.</p> <p>While the ResourceSet has one or more of these Conditions, the flux-operator will continue to attempt a reconciliation with an exponential backoff, until it succeeds and the ResourceSet is marked as ready.</p>"},{"location":"operator/resourceset/#stalled-resourceset","title":"Stalled ResourceSet","text":"<p>The flux-operator may fail the reconciliation of a ResourceSet object terminally due to a misconfiguration. When this happens, the flux-operator adds the <code>Stalled</code> Condition to the ResourceSet\u2019s <code>.status.conditions</code> with the following attributes:</p> <ul> <li><code>type: Stalled</code></li> <li><code>status: \"True\"</code></li> <li><code>reason: InvalidCELExpression | BuildFailed</code></li> </ul> <p>Misconfigurations can include:</p> <ul> <li>The <code>.spec.dependsOn[].readyExpr</code> expression is invalid. In this case the condition reason is <code>InvalidCELExpression</code>.</li> <li>The templating of the resources fails. In this case the condition reason is <code>BuildFailed</code>.</li> </ul> <p>When this happens, the flux-operator will not attempt to reconcile the ResourceSet until the misconfiguration is fixed. The <code>Ready</code> Condition status is also set to <code>False</code>.</p>"},{"location":"operator/resourceset/#history","title":"History","text":"<p>With <code>.status.history</code> the operator tracks the reconciliation attempts over time, providing insights into the ResourceSet's behavior which can be used for audit, anomaly detection and debugging purposes.</p> <p>The history is stored as a list of snapshots, ordered by last reconciliation time. Each snapshot contains:</p> <ul> <li><code>digest</code>: A SHA256 digest that uniquely identifies the set of generated resources being reconciled</li> <li><code>firstReconciled</code>: The timestamp when this particular configuration was first reconciled</li> <li><code>lastReconciled</code>: The timestamp of the most recent reconciliation attempt for this configuration</li> <li><code>lastReconciledDuration</code>: How long the most recent reconciliation attempt took</li> <li><code>lastReconciledStatus</code>: The status of the most recent reconciliation (e.g., <code>ReconciliationSucceeded</code>, <code>BuildFailed</code>, <code>ReconciliationFailed</code>)</li> <li><code>totalReconciliations</code>: The total number of reconciliations for this configuration</li> <li><code>metadata</code>: Additional information about the reconciliation, including the number of generated resources and inputs processed</li> </ul> <p>The operator deduplicates entries based on the digest and status. The history is automatically truncated to keep only the 5 most recent entries.</p> <p>Example:</p> <pre><code>status:\n  history:\n    - digest: sha256:43ad78c94b2655429d84f21488f29d7cca9cd45b7f54d2b27e16bbec8eff9228\n      firstReconciled: \"2025-07-15T10:11:00Z\"\n      lastReconciled: \"2025-07-15T14:30:00Z\"\n      lastReconciledDuration: 2.818583s\n      lastReconciledStatus: ReconciliationSucceeded\n      totalReconciliations: 5\n      metadata:\n        inputs: \"2\"\n        resources: \"4\"\n    - digest: sha256:ec8dbfe61777b65001190260cf873ffe454451bd2e464bd6f9a154cffcdcd7e5\n      firstReconciled: \"2025-07-14T13:10:00Z\"\n      lastReconciled: \"2025-07-15T10:10:00Z\"\n      lastReconciledDuration: 4.813292s\n      lastReconciledStatus: ReconciliationFailed\n      totalReconciliations: 120\n      metadata:\n        inputs: \"1\"\n        resources: \"2\"\n</code></pre> <p>Note that for <code>BuildFailed</code> errors, the digest is calculated from the resource templates, as the final resources are not available.</p>"},{"location":"operator/resourceset/#inventory","title":"Inventory","text":"<p>In order to perform operations such as drift detection, garbage collection, upgrades, etc., the flux-operator needs to keep track of all Kubernetes objects that are reconciled as part of a ResourceSet. To do this, it maintains an inventory containing the list of Kubernetes resource object references that have been successfully applied and records it in <code>.status.inventory</code>. The inventory records are in the format <code>Id: &lt;namespace&gt;_&lt;name&gt;_&lt;group&gt;_&lt;kind&gt;, V: &lt;version&gt;</code>.</p> <p>Example:</p> <pre><code>status:\n  inventory:\n    entries:\n      - id: apps_podinfo_helm.toolkit.fluxcd.io_HelmRelease\n        v: v2\n      - id: apps_podinfo_source.toolkit.fluxcd.io_OCIRepository\n        v: v1\n</code></pre>"},{"location":"operator/resourceset/#resourceset-metrics","title":"ResourceSet Metrics","text":"<p>The Flux Operator exports Prometheus metrics for the ResourceSet objects that can be used to monitor the reconciliation status.</p> <p>Metrics:</p> <pre><code>flux_resourceset_info{uid, kind, name, exported_namespace, ready, suspended, revision}\n</code></pre> <p>Labels:</p> <ul> <li><code>uid</code>: The Kubernetes unique identifier of the resource.</li> <li><code>kind</code>: The kind of the resource (e.g. <code>ResourceSet</code>).</li> <li><code>name</code>: The name of the resource (e.g. <code>podinfo</code>).</li> <li><code>exported_namespace</code>: The namespace where the resource is deployed (e.g. <code>apps</code>).</li> <li><code>ready</code>: The readiness status of the resource (e.g. <code>True</code>, <code>False</code> or <code>Unkown</code>).</li> <li><code>reason</code>: The reason for the readiness status (e.g. <code>ReconciliationSucceeded</code>, <code>BuildFailed</code>, <code>HealthCheckFailed</code>, etc.).</li> <li><code>suspended</code>: The suspended status of the resource (e.g. <code>True</code> or <code>False</code>).</li> <li><code>resources</code>: The number of resources generated by the ResourceSet.</li> <li><code>revision</code>: The revision last applied on the cluster (e.g. <code>sha256:75aa209c6a...</code>).</li> </ul>"},{"location":"operator/resourcesetinputprovider/","title":"ResourceSetInputProvider CRD","text":"<p>ResourceSetInputProvider is a declarative API for generating a set of input values for use within ResourceSet definitions. The input values are fetched from external services such as GitHub or GitLab, and can be used to parameterize the resources templates defined in ResourceSets.</p>"},{"location":"operator/resourcesetinputprovider/#example","title":"Example","text":"<p>The following example shows a provider that fetches input values from GitHub Pull Requests labeled with <code>deploy/flux-preview</code>:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSetInputProvider\nmetadata:\n  name: flux-appx-prs\n  namespace: default\n  annotations:\n    fluxcd.controlplane.io/reconcile: \"enabled\"\n    fluxcd.controlplane.io/reconcileEvery: \"5m\"\nspec:\n  type: GitHubPullRequest\n  url: https://github.com/controlplaneio-fluxcd/flux-appx\n  filter:\n    labels:\n      - \"deploy/flux-preview\"\n  defaultValues:\n    chart: \"charts/flux-appx\"\n</code></pre> <p>You can run this example by saving the manifest into <code>flux-appx-prs.yaml</code>.</p> <p>1. Apply the ResourceSetInputProvider on the cluster:</p> <pre><code>kubectl apply -f flux-appx-prs.yaml.yaml\n</code></pre> <p>2. Wait for the ResourceSetInputProvider to reconcile:</p> <pre><code>kubectl wait rsip/flux-appx-prs --for=condition=ready --timeout=5m\n</code></pre> <p>3. Run <code>kubectl get -o yaml</code> to see the exported inputs generated in the ResourceSetInputProvider status:</p> <pre><code>$ kubectl get rsip/flux-appx-prs -o yaml | yq .status.exportedInputs\n- author: stefanprodan\n  branch: kubernetes/helm-set-limits\n  chart: charts/flux-appx\n  id: \"4\"\n  sha: bf5d6e01cf802734853f6f3417b237e3ad0ba35d\n  title: 'kubernetes(helm): Add default resources limits'\n- author: stefanprodan\n  branch: feat/ui-footer\n  chart: charts/flux-appx\n  id: \"3\"\n  sha: 8492c0b5b2094fe720776c8ace1b9690ff258f53\n  title: 'feat(ui): Add footer'\n- author: stefanprodan\n  branch: feat/ui-color-scheme\n  chart: charts/flux-appx\n  id: \"2\"\n  sha: 8166bdecd6b078b9e5dd14fa3b7b67a847f76893\n  title: 'feat(ui): Default color scheme'\n</code></pre> <p>4. Run <code>kubectl delete</code> to remove the provider from the cluster:</p> <pre><code>kubectl delete rsip/flux-appx-prs\n</code></pre>"},{"location":"operator/resourcesetinputprovider/#writing-a-resourcesetinputprovider-spec","title":"Writing a ResourceSetInputProvider spec","text":"<p>As with all other Kubernetes config, a ResourceSet needs <code>apiVersion</code>, <code>kind</code>, <code>metadata.name</code> and <code>metadata.namespace</code> fields. The name of a ResourceSet object must be a valid DNS subdomain name. A ResourceSet also needs a <code>.spec</code> section.</p>"},{"location":"operator/resourcesetinputprovider/#type","title":"Type","text":"<p>The <code>.spec.type</code> field is required and specifies the type of the provider.</p> <p>The following types are supported:</p> <ul> <li><code>Static</code>: exports a single input map with the values from the field <code>.spec.defaultValues</code>.</li> <li><code>GitHubPullRequest</code>: fetches input values from opened GitHub Pull Requests.</li> <li><code>GitHubBranch</code>: fetches input values from GitHub repository branches.</li> <li><code>GitHubTag</code>: fetches input values from GitHub repository tags.</li> <li><code>GitLabMergeRequest</code>: fetches input values from opened GitLab Merge Requests.</li> <li><code>GitLabBranch</code>: fetches input values from GitLab project branches.</li> <li><code>GitLabTag</code>: fetches input values from GitLab project tags.</li> <li><code>AzureDevOpsPullRequest</code>: fetches input values from opened Azure DevOps Pull Requests.</li> <li><code>AzureDevOpsBranch</code>: fetches input values from Azure DevOps repository branches.</li> <li><code>AzureDevOpsTag</code>: fetches input values from AzureDevOps project tags.</li> <li><code>OCIArtifactTag</code>: fetches input values from OCI artifact tags from generic container registries.</li> <li><code>ACRArtifactTag</code>: fetches input values from Azure Container Registry OCI artifact tags.</li> <li><code>ECRArtifactTag</code>: fetches input values from Elastic Container Registry OCI artifact tags.</li> <li><code>GARArtifactTag</code>: fetches input values from Google Artifact Registry OCI artifact tags.</li> </ul> <p>For the <code>Static</code> type, the flux-operator will export in <code>.status.exportedInputs</code> a single input map with the values from the field <code>.spec.defaultValues</code> and the additional value:</p> <ul> <li><code>id</code>: the Adler-32 checksum of the ResourceSetInputProvider UID (type string).</li> </ul> <p>For all non-static types, the flux-operator will export in <code>.status.exportedInputs</code> a set of input values for each Pull/Merge Request or Branch that matches the filter criteria.</p> <p>For Pull/Merge Requests the exported inputs structure is:</p> <ul> <li><code>id</code>: the ID number of the PR/MR (type string).</li> <li><code>sha</code>: the commit SHA of the PR/MR (type string).</li> <li><code>branch</code>: the branch name of the PR/MR (type string).</li> <li><code>author</code>: the author username of the PR/MR (type string).</li> <li><code>title</code>: the title of the PR/MR (type string).</li> </ul> <p>For Git Branches the exported inputs structure is:</p> <ul> <li><code>id</code>: the Adler-32 checksum of the branch name (type string).</li> <li><code>branch</code>: the branch name (type string).</li> <li><code>sha</code>: the commit SHA corresponding to the branch HEAD (type string).</li> </ul> <p>For Git Tags the exported inputs structure is:</p> <ul> <li><code>id</code>: the Adler-32 checksum of the tag name (type string).</li> <li><code>tag</code>: the tag name (type string).</li> <li><code>sha</code>: the commit SHA corresponding to the tag in the format <code>&lt;hash&gt;</code> (type string).</li> </ul> <p>For OCI Artifact Tags the exported inputs structure is:</p> <ul> <li><code>id</code>: the Adler-32 checksum of the tag name (type string).</li> <li><code>tag</code>: the tag name (type string).</li> <li><code>digest</code>: the SHA256 digest corresponding to the tag in the format <code>sha256:&lt;hash&gt;</code> (type string).</li> </ul> <p>The ACR, ECR and GAR Artifact Tag providers export the same inputs as the OCI Artifact Tag provider, with the difference on the authentication method used to connect to the registry. For these providers, secret-less authentication is used.</p>"},{"location":"operator/resourcesetinputprovider/#url","title":"URL","text":"<p>The <code>.spec.url</code> field is required for external providers. For Git services, the URL should contain GitHub repository or the GitLab project address, including the HTTP/S scheme (<code>(http|https)://</code>). For OCI services, the URL should contain the OCI repository address, including the OCI scheme (<code>oci://</code>).</p>"},{"location":"operator/resourcesetinputprovider/#filter","title":"Filter","text":"<p>The <code>.spec.filter</code> field is optional and specifies the filter criteria for the input values.</p> <p>The following filters are supported:</p> <ul> <li><code>limit</code>: limit the number of input values fetched (default is 100).</li> <li><code>labels</code>: filter GitHub Pull Requests or GitLab Merge Requests by labels.</li> <li><code>includeBranch</code>: regular expression to include branches by name.</li> <li><code>excludeBranch</code>: regular expression to exclude branches by name.</li> <li><code>includeTag</code>: regular expression to include tags by name.</li> <li><code>excludeTag</code>: regular expression to exclude tags by name.</li> <li><code>semver</code>: sematic version range to filter and sort tags.</li> </ul> <p>Example of a filter configuration for GitLab Merge Requests:</p> <pre><code>spec:\n  filter:\n    limit: 10\n    labels:\n      - \"deploy::flux-preview\"\n    includeBranch: \"^feat/.*\"\n    excludeBranch: \"^feat/not-this-one$\"\n</code></pre> <p>Example of a filter configuration for filtering tags by inclusion and exclusion:</p> <pre><code>spec:\n  filter:\n    includeTag: \"^v[0-9]+\\\\.[0-9]+\\\\.[0-9]+$\" # include tags like v1.2.3\n    excludeTag: \"^v0\" # exclude tags like v0.1.0\n</code></pre> <p>Example of a filter configuration for fetching only the latest tag according to semver:</p> <pre><code>spec:\n  filter:\n    limit: 1\n    semver: \"&gt;=1.0.0\"\n</code></pre>"},{"location":"operator/resourcesetinputprovider/#skip","title":"Skip","text":"<p>The <code>.spec.skip</code> field is optional and specifies the skip criteria for skipping input updates. This field can be used to wait until certain PR/MR is ready.</p> <p>The following skips are supported:</p> <ul> <li><code>labels</code>: skip input update by labels if one of the label matched. When the label starts with <code>!</code> it will skip if the label is not present.</li> </ul> <p>Example of a skip configuration:</p> <pre><code>spec:\n  filter:\n    labels:\n      - \"deploy:flux-preview\"\n  skip:\n    labels:\n      - \"deploy/flux-preview-pause\"\n      - \"!test-build-push/passed\"\n</code></pre>"},{"location":"operator/resourcesetinputprovider/#default-values","title":"Default values","text":"<p>The <code>.spec.defaultValues</code> field is optional and specifies the default values for the exported inputs. This field can be used to set values that are common to all the exported inputs.</p> <p>Example:</p> <pre><code>spec:\n  defaultValues:\n    env: \"staging\"\n    tenants:\n      - \"tenant1\"\n      - \"tenant2\"\n</code></pre>"},{"location":"operator/resourcesetinputprovider/#authentication-configuration","title":"Authentication configuration","text":""},{"location":"operator/resourcesetinputprovider/#secret-based","title":"Secret-based","text":"<p>The <code>.spec.secretRef</code> field is optional and specifies the Kubernetes Secret containing the authentication credentials used for connecting to the external service. Note that the secret must be created in the same namespace as the ResourceSetInputProvider.</p> <p>This field is not supported by the following provider types:</p> <ul> <li><code>Static</code></li> <li><code>ACRArtifactTag</code></li> <li><code>ECRArtifactTag</code></li> <li><code>GARArtifactTag</code></li> </ul> <p>For Git services, the secret should contain the <code>username</code> and <code>password</code> keys, with the password set to a personal access token that grants access for listing Pull Requests or Merge Requests and Git branches.</p> <p>For the <code>OCIArtifactTag</code> provider type, the secret should contain a Kubernetes Docker config JSON secret, i.e. as if created by the <code>kubectl create secret docker-registry</code> command. If the <code>.spec.serviceAccountName</code> field is specified, all the image pull secrets configured on the ServiceAccount are also included in the registry keychain used for the reconciliation, alongside the secret specified in <code>.spec.secretRef</code>. All of them have to be on the format produced by the <code>kubectl create secret docker-registry</code> command.</p> <p>Example of Git secret:</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: github-pat\n  namespace: default\nstringData:\n  username: flux\n  password: &lt;GITHUB PAT&gt;\n</code></pre> <p>Example of <code>OCIArtifactTag</code> Docker config secret:</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: docker-config\n  namespace: default\ntype: kubernetes.io/dockerconfigjson\nstringData:\n  .dockerconfigjson: |\n    {\n      \"auths\": {\n        \"&lt;REGISTRY HOST&gt;\": {\n          \"username\": \"flux\",\n          \"password\": \"&lt;PASSWORD&gt;\"\n        }\n      }\n    }\n</code></pre> <p>Example secret reference:</p> <pre><code>spec:\n  serviceAccountName: oci-pull-secrets-sa # optional, for OCIArtifactTag provider type only\n  secretRef:\n    name: github-pat # or oci-pull-secret for OCIArtifactTag provider type\n</code></pre>"},{"location":"operator/resourcesetinputprovider/#secret-less","title":"Secret-less","text":"<p>The <code>.spec.serviceAccountName</code> field is optional and specifies the name of the Kubernetes ServiceAccount in the same namespace configured with workload identity to access a cloud provider service. This is called object-level workload identity. In order to force the use of object-level workload identity, the <code>--default-workload-identity-service-account</code> flag can be set in the operator. If this flag is specified and a ResourceSetInputProvider object does not have the field <code>.spec.serviceAccountName</code>, the operator will use the default service account specified by the flag for reconciling this object.</p> <p>When installing the Flux Operator with Helm, you can change the default workload identity service account name with:</p> <pre><code>helm install flux-operator oci://ghcr.io/controlplaneio-fluxcd/charts/flux-operator \\\n  --namespace flux-system \\\n  --create-namespace \\\n  --set multitenancy.enabledForWorkloadIdentity=true \\\n  --set multitenancy.defaultWorkloadIdentityServiceAccount=flux-operator\n</code></pre> <p>When installing the Flux Operator on OpenShift from OperatorHub, the default workload identity service account name can be changed by setting the <code>DEFAULT_WORKLOAD_IDENTITY_SERVICE_ACCOUNT</code> environment variable using the OLM Subscription <code>.spec.config.env</code> field.</p> <p>The <code>.spec.serviceAccountName</code> field can only be used with the following provider types for workload identity:</p> <ul> <li><code>AzureDevOpsPullRequest</code></li> <li><code>AzureDevOpsBranch</code></li> <li><code>AzureDevOpsTag</code></li> <li><code>ACRArtifactTag</code></li> <li><code>ECRArtifactTag</code></li> <li><code>GARArtifactTag</code></li> </ul> <p>When this field is not present and one of the types above is specified (and, in the case of Azure DevOps, <code>.spec.secretRef</code> is also not specified), the operator will attempt to authenticate using the environment credentials, i.e. either the identity of the node or the operator ServiceAccount. This is called controller-level workload identity.</p> <p>For configuring a Kubernetes ServiceAccount with workload identity, see the following documentation:</p> <ul> <li>Azure</li> <li>AWS (controller-level)</li> <li>AWS (object-level)</li> <li>GCP</li> </ul> <p>For configuring the required permissions to access the cloud services, see the following documentation:</p> <ul> <li>Azure DevOps (the <code>Readers</code> ADO group is sufficient)</li> <li>Azure Container Registry</li> <li>Amazon Elastic Container Registry</li> <li>Amazon Elastic Container Registry Public</li> <li>Google Artifact Registry</li> </ul> <p>For configuring the operator to use controller-level workload identity, patches like the ones described in the documentation below can be applied to the operator deployment:</p> <ul> <li>Azure</li> <li>AWS</li> <li>GCP</li> </ul> <p>For configuring the identity of your nodes to access container registry services, see the following documentation:</p> <ul> <li>Authenticate with ACR from AKS</li> <li>Authenticate with ECR from EKS:<ul> <li>Create IAM Roles for EKS worker nodes</li> <li>Allow the EKS worker IAM Roles to pull images from ECR</li> </ul> </li> <li>Authenticate with GAR from GKE</li> </ul> <p>See also the cross-cloud documentation:</p> <ul> <li>Cross-cloud support</li> </ul>"},{"location":"operator/resourcesetinputprovider/#github-app-authentication","title":"GitHub App authentication","text":"<p>For GitHub, GitHub App authentication is also supported. Instead of adding the basic auth keys <code>username</code> and <code>password</code> to the referenced Secret, you can add the following GitHub App keys:</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: github-app\n  namespace: default\nstringData:\n  githubAppID: \"&lt;GITHUB APP ID&gt;\"\n  githubAppInstallationID: \"&lt;GITHUB APP INSTALLATION ID&gt;\"\n  githubAppBaseURL: &lt;github-enterprise-api-url&gt; # optional, for self-hosted GitHub Enterprise\n  githubAppPrivateKey: |\n    -----BEGIN RSA PRIVATE KEY-----\n    ...\n    -----END RSA PRIVATE KEY-----\n</code></pre> <p>Example secret reference:</p> <pre><code>spec:\n  secretRef:\n    name: github-app\n</code></pre> <p>The GitHub App ID and Installation ID are integer numbers, so remember to quote them in the secret if using the <code>stringData</code> field as all values in this field must be strings.</p> <p>A simpler alternative is creating the secret using the Flux CLI command <code>flux create secret githubapp</code>.</p>"},{"location":"operator/resourcesetinputprovider/#tls-certificate-configuration","title":"TLS certificate configuration","text":"<p>The <code>.spec.certSecretRef</code> field is optional and specifies the Kubernetes Secret containing the TLS certificate used for connecting to the external service. Note that the secret must be created in the same namespace as the ResourceSetInputProvider.</p> <p>This field is not supported by the following provider types:</p> <ul> <li><code>Static</code></li> <li><code>ACRArtifactTag</code></li> <li><code>ECRArtifactTag</code></li> <li><code>GARArtifactTag</code></li> </ul> <p>For Git services that use self-signed certificates, or the <code>OCIArtifactTag</code> provider type, the secret should contain either or both of the <code>ca.crt</code> key with a CA certificate, and the pair <code>tls.crt</code> and <code>tls.key</code> keys with an mTLS client certificate and key.</p> <p>Example secret:</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: provider-certs\n  namespace: default\nstringData:\n  ca.crt: | # supported for both Git and OCIArtifactTag providers\n    -----BEGIN CERTIFICATE-----\n    MIIDpDCCAoygAwIBAgIUI7z\n    ...\n    -----END CERTIFICATE-----\n  tls.crt: | # supported only for the OCIArtifactTag provider\n    -----BEGIN CERTIFICATE-----\n    MIIDpDCCAoygIUI7zgAwIBA\n    ...\n    -----END CERTIFICATE-----\n  tls.key: | # supported only for the OCIArtifactTag provider\n    -----BEGIN PRIVATE KEY-----\n    MIIEvQIBADABAQCv1qlHtnk\n    ...\n    -----END PRIVATE KEY-----\n</code></pre> <p>Example certificate reference:</p> <pre><code>spec:\n  certSecretRef:\n    name: provider-certs\n</code></pre>"},{"location":"operator/resourcesetinputprovider/#schedule","title":"Schedule","text":"<p>The <code>.spec.schedule</code> field is optional and can be used to specify a list of <code>Schedule</code> objects.</p> <p>Each <code>Schedule</code> object has the following fields:</p> <ul> <li><code>.cron</code>: a required string representing the cron schedule in the format accepted by   cron.</li> <li><code>.timeZone</code>: a string representing the time zone   in which the cron schedule should be interpreted. This field is optional and defaults to <code>UTC</code>.</li> <li><code>.window</code>: an optional string representing the time window duration in which reconciliations are   allowed to run. The format is a Go duration string, such as <code>1h30m</code> or <code>2h45m</code>. Defaults to <code>0s</code>,   meaning no window is applied. The duration must be either zero or at least twice the   timeout.</li> </ul> <p>Example:</p> <pre><code>spec:\n  schedule:\n    # Every day-of-week from Monday through Thursday\n    # between 10:00 to 16:00\n    - cron: \"0 10 * * 1-4\"\n      timeZone: \"Europe/London\"\n      window: \"6h\"\n    # Every Friday from 10:00 to 13:00\n    - cron: \"0 10 * * 5\"\n      timeZone: \"Europe/London\"\n      window: \"3h\"\n</code></pre> <p>When multiple schedules are specified, flux-operator will:</p> <ul> <li>Reconcile the ResourceSetInputProvider if at least one of the schedules matches the current time.</li> <li>Use the earliest next scheduled time across all schedules to determine the next scheduled time.</li> </ul> <p>When a schedule is specified with <code>window: 0s</code>, flux-operator will make the best effort to reconcile the ResourceSetInputProvider at the scheduled time; but it may not be able to guarantee that the reconciliation will start exactly at that time, especially if the operator is too busy or if the cluster is under heavy load.</p> <p>If multiple schedules are specified and at least one has a zero-duration window, flux-operator will always reconcile the ResourceSetInputProvider upon any requests, e.g., updating the <code>.spec</code>, when the CLI is used to trigger a reconciliation, or when the operator is restarted.</p> <p>When a schedule is specified with a non-zero duration window, flux-operator will only reconcile the ResourceSetInputProvider when the time point <code>time.Now().Add(obj.GetTimeout())</code> falls within the time window defined by the schedule. This check is performed not only at the start of the reconciliation, but also when scheduling the next reconciliation according to the interval defined by the <code>fluxcd.controlplane.io/reconcileEvery</code> annotation.</p> <p>To force a one-off out-of-schedule reconciliation, annotate the ResourceSetInputProvider with <code>reconcile.fluxcd.io/requestedAt: \"&lt;current timestamp&gt;\"</code> and <code>reconcile.fluxcd.io/forceAt: \"&lt;current timestamp&gt;\"</code>. The value of both annotations must be the exact same string, otherwise the reconciliation will not be triggered. This can be done easily using the <code>flux-operator</code> CLI:</p> <pre><code>flux-operator reconcile inputprovider &lt;name&gt; --force\n</code></pre> <p>If an out-of-schedule reconciliation is triggered without being forced, the flux-operator will only print an info log and and emit a <code>Normal</code> event with the reason <code>SkippedDueToSchedule</code> to indicate that the reconciliation was skipped due to the schedule configuration. The <code>.status.conditions</code> will not be updated in this case, and the ResourceSetInputProvider will not be reconciled until the next scheduled time.</p>"},{"location":"operator/resourcesetinputprovider/#reconciliation-configuration","title":"Reconciliation configuration","text":"<p>The reconciliation of behaviour of a ResourceSet can be configured using the following annotations:</p> <ul> <li><code>fluxcd.controlplane.io/reconcile</code>: Enable or disable the reconciliation loop. Default is <code>enabled</code>, set to <code>disabled</code> to pause the reconciliation.</li> <li><code>fluxcd.controlplane.io/reconcileEvery</code>: Set the reconciliation interval used for calling external services. Default is <code>10m</code>.</li> <li><code>fluxcd.controlplane.io/reconcileTimeout</code>: Set the timeout for calling external services. Default is <code>2m</code>.</li> </ul>"},{"location":"operator/resourcesetinputprovider/#resourcesetinputprovider-status","title":"ResourceSetInputProvider Status","text":""},{"location":"operator/resourcesetinputprovider/#conditions","title":"Conditions","text":"<p>A ResourceSetInputProvider enters various states during its lifecycle, reflected as Kubernetes Conditions. It can be reconciling while fetching data from external services, it can be ready, it can fail during reconciliation, or it can fail due to misconfiguration.</p> <p>The ResourceSetInputProvider API is compatible with the kstatus specification, and reports <code>Reconciling</code> and <code>Stalled</code> conditions where applicable to provide better (timeout) support to solutions polling the ResourceSetInputProvider to become <code>Ready</code>.</p>"},{"location":"operator/resourcesetinputprovider/#reconciling-resourcesetinputprovider","title":"Reconciling ResourceSetInputProvider","text":"<p>The flux-operator marks a ResourceSetInputProvider as reconciling when it starts the reconciliation of the same. The Condition added to the ResourceSetInputProvider's <code>.status.conditions</code> has the following attributes:</p> <ul> <li><code>type: Reconciling</code></li> <li><code>status: \"True\"</code></li> <li><code>reason: Progressing</code> | <code>reason: ProgressingWithRetry</code></li> </ul> <p>The Condition <code>message</code> is updated during the course of the reconciliation to report the action being performed at any particular moment such as fetching data from external services.</p> <p>The <code>Ready</code> Condition's <code>status</code> is also marked as <code>Unknown</code>.</p>"},{"location":"operator/resourcesetinputprovider/#ready-resourcesetinputprovider","title":"Ready ResourceSetInputProvider","text":"<p>The flux-operator marks a ResourceSetInputProvider as ready when the data fetching from external services is successful.</p> <p>When the ResourceSet is \"ready\", the flux-operator sets a Condition with the following attributes in the ResourceSet\u2019s <code>.status.conditions</code>:</p> <ul> <li><code>type: Ready</code></li> <li><code>status: \"True\"</code></li> <li><code>reason: ReconciliationSucceeded</code></li> </ul>"},{"location":"operator/resourcesetinputprovider/#failed-resourcesetinputprovider","title":"Failed ResourceSetInputProvider","text":"<p>The flux-operator may get stuck trying to reconcile and apply a ResourceSetInputProvider without completing. This can occur due to some of the following factors:</p> <ul> <li>The authentication to the external service fails.</li> <li>The external service is unreachable.</li> <li>The data fetched from the external service is invalid.</li> </ul> <p>When this happens, the flux-operator sets the <code>Ready</code> Condition status to False and adds a Condition with the following attributes to the ResourceSet\u2019s <code>.status.conditions</code>:</p> <ul> <li><code>type: Ready</code></li> <li><code>status: \"False\"</code></li> <li><code>reason: ReconciliationFailed</code></li> </ul> <p>The <code>message</code> field of the Condition will contain more information about why the reconciliation failed.</p> <p>While the ResourceSetInputProvider has one or more of these Conditions, the flux-operator will continue to attempt a reconciliation with an exponential backoff, until it succeeds and the ResourceSetInputProvider is marked as ready.</p>"},{"location":"operator/resourcesetinputprovider/#stalled-resourcesetinputprovider","title":"Stalled ResourceSetInputProvider","text":"<p>The flux-operator may fail the reconciliation of a ResourceSetInputProvider object terminally due to a misconfiguration. When this happens, the flux-operator adds the <code>Stalled</code> Condition to the ResourceSetInputProvider\u2019s <code>.status.conditions</code> with the following attributes:</p> <ul> <li><code>type: Stalled</code></li> <li><code>status: \"True\"</code></li> <li><code>reason: InvalidDefaultValues | InvalidSchedule | InvalidExportedInputs</code></li> </ul> <p>Misconfigurations can include:</p> <ul> <li>The <code>.spec.defaultValues</code> has invalid values. In this case the condition reason is <code>InvalidDefaultValues</code>.</li> <li>The <code>.spec.schedule</code> has invalid configuration. In this case the condition reason is <code>InvalidSchedule</code>.</li> <li>For the <code>Static</code> provider type only, the default values can be parsed but cannot be exported as inputs. In this case the condition reason is <code>InvalidExportedInputs</code>.</li> </ul> <p>When this happens, the flux-operator will not attempt to reconcile the ResourceSetInputProvider until the misconfiguration is fixed. The <code>Ready</code> Condition status is also set to <code>False</code>.</p>"},{"location":"operator/resourcesetinputprovider/#exported-inputs-status","title":"Exported inputs status","text":"<p>After a successful reconciliation, the ResourceSetInputProvider status contains a list of exported inputs that can be used in the ResourceSet templates.</p> <p>Example for GitHub Pull Request:</p> <pre><code>status:\n  exportedInputs:\n  - author: stefanprodan\n    branch: kubernetes/helm-set-limits\n    id: \"4\"\n    sha: bf5d6e01cf802734853f6f3417b237e3ad0ba35d\n    title: 'kubernetes(helm): Add default resources limits'\n  - author: stefanprodan\n    branch: feat/ui-footer\n    id: \"3\"\n    sha: 8492c0b5b2094fe720776c8ace1b9690ff258f53\n    title: 'feat(ui): Add footer'\n  - author: stefanprodan\n    branch: feat/ui-color-scheme\n    id: \"2\"\n    sha: 8166bdecd6b078b9e5dd14fa3b7b67a847f76893\n    title: 'feat(ui): Default color scheme'\n</code></pre> <p>Example for GitHub latest semver tag:</p> <pre><code>status:\n  exportedInputs:\n  - id: \"48955639\"\n    tag: \"6.0.4\"\n    sha: 11cf36d83818e64aaa60d523ab6438258ebb6009\n</code></pre> <p>Example for OCI latest semver tag:</p> <pre><code>status:\n  exportedInputs:\n  - id: \"48955639\"\n    tag: \"6.0.4\"\n    sha: sha256:d4ec9861522d4961b2acac5a070ef4f92d732480dff2062c2f3a1dcf9a5d1e91\n</code></pre>"},{"location":"operator/resourcesetinputprovider/#schedule-status","title":"Schedule status","text":"<p>When the next reconciliation of the ResourceSetInputProvider is due to a schedule the field <code>.status.nextSchedule</code> holds information about the next scheduled reconciliation. For example:</p> <pre><code>status:\n  nextSchedule:\n    cron: 0 8 * * 1-5\n    timeZone: Europe/London\n    when: \"2025-06-29T00:00:00Z\"\n    window: 8h\n</code></pre> <p>During a window, the flux-operator will schedule reconciliations based on the interval defined by the <code>fluxcd.controlplane.io/reconcileEvery</code> annotation (or its default value). During this time, the <code>.status.nextSchedule</code> field will not be present.</p>"},{"location":"operator/resourcesetinputprovider/#resourcesetinputprovider-metrics","title":"ResourceSetInputProvider Metrics","text":"<p>The Flux Operator exports Prometheus metrics for the ResourceSetInputProvider objects that can be used to monitor the reconciliation status.</p> <p>Metrics:</p> <pre><code>flux_resourcesetinputprovider_info{uid, kind, name, exported_namespace, ready, suspended, url}\n</code></pre> <p>Labels:</p> <ul> <li><code>uid</code>: The Kubernetes unique identifier of the resource.</li> <li><code>kind</code>: The kind of the resource (e.g. <code>ResourceSetInputProvider</code>).</li> <li><code>name</code>: The name of the resource (e.g. <code>podinfo-prs</code>).</li> <li><code>exported_namespace</code>: The namespace where the resource is deployed (e.g. <code>podinfo-review</code>).</li> <li><code>ready</code>: The readiness status of the resource (e.g. <code>True</code>, <code>False</code> or <code>Unkown</code>).</li> <li><code>reason</code>: The reason for the readiness status (e.g. <code>ReconciliationSucceeded</code> or <code>ReconciliationFailed</code>).</li> <li><code>suspended</code>: The suspended status of the resource (e.g. <code>True</code> or <code>False</code>).</li> <li><code>url</code>: The provider address (e.g. <code>https://github.com/stefanprodan/podinfo</code>).</li> </ul>"},{"location":"operator/resourcesets/app-definition/","title":"Using ResourceSets for Application Definitions","text":"<p>The ResourceSet API allows bundling a set of Kubernetes resources (Flux HelmRelease, OCIRepository, Alert, Provider, Receiver, Kubernetes Namespace, ServiceAccount, etc) into a single deployable unit that can be templated and parameterized.</p> <p>Use cases of ResourceSet include:</p> <p>Multi-instance provisioning - Generate multiple instances of the same application in a cluster with different configurations.</p> <p>Multi-cluster provisioning - Generate multiple instances of the same application for each target cluster that are deployed by Flux from a management cluster.</p> <p>Multi-tenancy provisioning - Generate a set of resources (Namespace, ServiceAccount, RoleBinding, Flux GitRepository, Kustomization) for each tenant with specific roles and permissions to simplify the onboarding of new tenants and their applications on a shared cluster.</p> <p>Dependency management - Define dependencies between apps to ensure that the resources are applied in the correct order. The dependencies are more flexible  than in Flux, they can be for other ResourceSets, CRDs, or any other Kubernetes object. When defining dependencies, these can be for checking the existence of a resource or for waiting for a resource to be ready. To evaluate the readiness of a dependent resource, users can specify a CEL expression that is evaluated against the resource status.</p>"},{"location":"operator/resourcesets/app-definition/#multi-instance-example","title":"Multi-instance example","text":"<p>While bundling resources is possible with Flux HelmReleases and Kustomize overlays, the ResourceSet API can drastically reduce the amount of files and overlays needed to manage multiple instances of the same application.</p> <p>With Kustomize overlays the following structure is needed to deploy an app instance per tenant with different Helm values:</p> <pre><code>apps/\n\u2514\u2500\u2500 app1\n    \u251c\u2500\u2500 base\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 flux-helm-release.yaml\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 flux-oci-repository.yaml\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 kustomization.yaml\n    \u251c\u2500\u2500 overlays\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 tenant1\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 kustomization.yaml\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 values-patch.yaml\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 version-patch.yaml\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 tenant2\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 kustomization.yaml\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 values-patch.yaml\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 version-patch.yaml\n    \u2514\u2500\u2500 bundle\n        \u2514\u2500\u2500 kustomization.yaml\n</code></pre> <p>Using a ResourceSet, the same can be achieved with a single file:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSet\nmetadata:\n  name: app1\n  namespace: apps\nspec:\n  inputs:\n    - tenant: \"tenant1\"\n      app:\n       version: \"6.7.x\"\n       replicas: 2\n    - tenant: \"tenant2\"\n      app:\n       version: \"6.6.x\"\n       replicas: 3\n  resources:\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: OCIRepository\n      metadata:\n        name: app1-&lt;&lt; inputs.tenant &gt;&gt;\n        namespace: apps\n      spec:\n        interval: 10m\n        url: oci://my.registry/org/charts/app1\n        ref:\n          semver: &lt;&lt; inputs.app.version | quote &gt;&gt;\n    - apiVersion: helm.toolkit.fluxcd.io/v2\n      kind: HelmRelease\n      metadata:\n        name: app1-&lt;&lt; inputs.tenant &gt;&gt;\n        namespace: apps\n      spec:\n        interval: 1h\n        releaseName: app1-&lt;&lt; inputs.tenant &gt;&gt;\n        chartRef:\n          kind: OCIRepository\n          name: app1-&lt;&lt; inputs.tenant &gt;&gt;\n        values:\n          replicaCount: &lt;&lt; inputs.app.replicas | int &gt;&gt;\n</code></pre>"},{"location":"operator/resourcesets/app-definition/#decoupled-example","title":"Decoupled example","text":"<p>You may want to separate the inputs from the <code>ResourceSet</code> manifest to allow, for example, different teams to manage the inputs independently, and also without requiring every instance to be listed in the <code>ResourceSet</code> manifest. This can be done by declaring the inputs in separate <code>ResourceSetInputProvider</code> resources with the <code>spec.type</code> field set to <code>Static</code> and referencing them dynamically through Label Selectors in the <code>ResourceSet</code>:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSet\nmetadata:\n  name: app1\n  namespace: apps\nspec:\n  inputsFrom:\n    - kind: ResourceSetInputProvider\n      selector:\n        matchLabels:\n          some: label\n        matchExpressions:\n          - key: anotherLabel\n            operator: In\n            values:\n              - value1\n              - value2\n  resources:\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: OCIRepository\n      metadata:\n        name: app1-&lt;&lt; inputs.tenant &gt;&gt;\n        namespace: apps\n      spec:\n        interval: 10m\n        url: oci://my.registry/org/charts/app1\n        ref:\n          semver: &lt;&lt; inputs.app.version | quote &gt;&gt;\n    - apiVersion: helm.toolkit.fluxcd.io/v2\n      kind: HelmRelease\n      metadata:\n        name: app1-&lt;&lt; inputs.tenant &gt;&gt;\n        namespace: apps\n      spec:\n        interval: 1h\n        releaseName: app1-&lt;&lt; inputs.tenant &gt;&gt;\n        chartRef:\n          kind: OCIRepository\n          name: app1-&lt;&lt; inputs.tenant &gt;&gt;\n        values:\n          replicaCount: &lt;&lt; inputs.app.replicas | int &gt;&gt;\n</code></pre> <p>Then you can create the <code>ResourceSetInputProvider</code> resources with the <code>Static</code> input provider type and labels matching the <code>ResourceSet</code> selector:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSetInputProvider\nmetadata:\n  name: app1-tenant1\n  namespace: apps\n  labels:\n    some: label\n    anotherLabel: value1\nspec:\n  type: Static\n  defaultValues:\n    tenant: \"tenant1\"\n    app:\n      version: \"6.7.x\"\n      replicas: 2\n---\napiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSetInputProvider\nmetadata:\n  name: app1-tenant2\n  namespace: apps\n  labels:\n    some: label\n    anotherLabel: value2\nspec:\n  type: Static\n  defaultValues:\n    tenant: \"tenant2\"\n    app:\n      version: \"6.6.x\"\n      replicas: 3\n</code></pre> <p>Note: The <code>ResourceSet</code> and <code>ResourceSetInputProvider</code> resources must be in the same namespace.</p>"},{"location":"operator/resourcesets/app-definition/#multi-cluster-example","title":"Multi-cluster example","text":"<p>When deploying applications across multiple environments from a management cluster, the ResourceSet API can simplify the definition of the application and its customization for each target cluster.</p> <p>With Kustomize overlays the following structure is needed to deploy an app instance per environment:</p> <pre><code>apps/\n\u2514\u2500\u2500 app1\n    \u251c\u2500\u2500 base\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 flux-kustomization.yaml\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 flux-git-repository.yaml\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 kustomization.yaml\n    \u251c\u2500\u2500 overlays\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 dev\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 kustomization.yaml\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 vars-patch.yaml\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 kubeconfig-patch.yaml\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 production\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 kustomization.yaml\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 vars-patch.yaml\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 kubeconfig-patch.yaml\n    \u2514\u2500\u2500 bundle\n        \u2514\u2500\u2500 kustomization.yaml\n</code></pre> <p>Using a ResourceSet, the same can be achieved with a single file:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSet\nmetadata:\n  name: app1\n  namespace: apps\nspec:\n  inputs:\n    - cluster: \"dev\"\n      branch: \"main\"\n      ingress: \"app1.dev.example.com\"\n    - cluster: \"production\"\n      branch: \"prod\"\n      ingress: \"app1.example.com\"\n  resources:\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: GitRepository\n      metadata:\n        name: app1-&lt;&lt; inputs.cluster &gt;&gt;\n        namespace: apps\n      spec:\n        interval: 5m\n        url: https://my.git/org/app1-deploy\n        ref:\n          branch: &lt;&lt; inputs.branch &gt;&gt;\n    - apiVersion: kustomize.toolkit.fluxcd.io/v1\n      kind: Kustomization\n      metadata:\n        name: app1-&lt;&lt; inputs.cluster &gt;&gt;\n        namespace: apps\n      spec:\n        interval: 10m\n        prune: true\n        path: \"./deploy\"\n        sourceRef:\n          kind: GitRepository\n          name: app1-&lt;&lt; inputs.cluster &gt;&gt;\n        postBuild:\n          substitute:\n            domain: &lt;&lt; inputs.ingress &gt;&gt;\n        kubeConfig:\n          secretRef:\n            name: &lt;&lt; inputs.cluster &gt;&gt;-kubeconfig\n</code></pre>"},{"location":"operator/resourcesets/app-definition/#monorepo-example","title":"Monorepo example","text":"<p>When an application is composed of multiple microservices, the ResourceSet API can be used to define the deployment of each component and the rollout order based on dependencies.</p> <p>Assuming the following directory structure in a monorepo where the Kubernetes resources are templated using Flux variables:</p> <pre><code>deploy/\n\u251c\u2500\u2500 frontend\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 deployment.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ingress.yaml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 service.yaml\n\u251c\u2500\u2500 backend\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 deployment.yaml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 service.yaml\n\u2514\u2500\u2500 database\n    \u251c\u2500\u2500 deployment.yaml\n    \u251c\u2500\u2500 pvc.yaml\n    \u2514\u2500\u2500 service.yaml\n</code></pre> <p>Using a ResourceSet, we can generate one GitRepository that points to the monorepo, and a set of Flux Kustomizations one for each component that depends on the previous one:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSet\nmetadata:\n  name: app1\n  namespace: apps\nspec:\n  inputs:\n    - service: \"frontend\"\n      dependsOn: \"backend\"\n    - service: \"backend\"\n      dependsOn: \"database\"\n    - service: \"database\"\n      dependsOn: \"\"\n  resourcesTemplate: |\n    ---\n    apiVersion: source.toolkit.fluxcd.io/v1\n    kind: GitRepository\n    metadata:\n      name: app1\n      namespace: apps\n    spec:\n      interval: 5m\n      url: https://my.git/org/app1-deploy\n      ref:\n        branch: main\n    ---\n    apiVersion: kustomize.toolkit.fluxcd.io/v1\n    kind: Kustomization\n    metadata:\n      name: app1-&lt;&lt; inputs.service &gt;&gt;\n      namespace: apps\n    spec:\n      &lt;&lt; if inputs.dependsOn &gt;&gt;\n      dependsOn:\n        - name: app1-&lt;&lt; inputs.dependsOn &gt;&gt;\n      &lt;&lt; end &gt;&gt;\n      path: \"./deploy/&lt;&lt; inputs.service &gt;&gt;\"\n      interval: 30m\n      retryInterval: 5m\n      prune: true\n      wait: true\n      timeout: 5m\n      sourceRef:\n        kind: GitRepository\n        name: app1\n      postBuild:\n        substituteFrom:\n          - kind: ConfigMap\n            name: app1-vars\n</code></pre>"},{"location":"operator/resourcesets/app-definition/#working-with-resourcesets","title":"Working with ResourceSets","text":"<p>When working with ResourceSets, you can use the Flux Operator CLI for building ResourceSet templates locally and for listing, reconciling, suspending and resuming ResourceSets in-cluster.</p> <p>The following commands are available:</p> <pre><code># Build the given ResourceSet and print the generated objects\nflux-operator build rset -f my-resourceset.yaml\n\n# List all ResourceSets in the cluster\nflux-operator get rset --all-namespaces\n\n# Reconcile a ResourceSet \nflux-operator -n apps reconcile rset podinfo\n\n# Suspend a ResourceSet \nflux-operator -n apps suspend rset podinfo\n\n# Resume a ResourceSet \nflux-operator -n apps resume rset podinfo\n</code></pre> <p>See the Flux Operator CLI documentation for more details on how to use the CLI.</p>"},{"location":"operator/resourcesets/app-definition/#further-reading","title":"Further reading","text":"<p>To learn more about the ResourceSet API, its templating capabilities and dependency management, see the ResourceSet API reference.</p>"},{"location":"operator/resourcesets/github-pull-requests/","title":"Ephemeral Environments for GitHub Pull Requests","text":"<p>This guide demonstrates how to use the Flux Operator ResourceSet API to automate the deployment of applications changes made in GitHub Pull Requests to ephemeral environments for testing and validation.</p>"},{"location":"operator/resourcesets/github-pull-requests/#development-workflow","title":"Development workflow","text":"<ul> <li>A developer opens a Pull Request with changes to the app code and Helm chart.</li> <li>The CI builds and pushes the app container image to GitHub Container Registry. The image is tagged with the Git commit SHA.</li> <li>Another developer reviews the changes and labels the Pull Request with the <code>deploy/flux-preview</code> label.</li> <li>Flux Operator running in the preview cluster scans the repository and finds the new PR using the label filter.</li> <li>Flux Operator installs a Helm release using the PR number and the commit SHA inputs to deploy the app and chart changes in the cluster.</li> <li>The app is accessible at a preview URL composed of the PR number and the app name.</li> <li>The developers iterate over changes, with each push to the PR branch triggering a Helm release upgrade in the cluster.</li> <li>The developers are notified of the Helm release status in the Slack channel and on the PR page.</li> <li>Once the PR is approved and merged, the Flux Operator uninstalls the Helm release from the cluster.</li> </ul>"},{"location":"operator/resourcesets/github-pull-requests/#gitops-workflow","title":"GitOps workflow","text":"<p>To enable the development workflow, we'll define a series of Flux Operator custom resources in the preview cluster. Note that the preview cluster must be provisioned with a Flux Instance and the Kubernetes manifests part of the GitOps workflow should be stored in the Git repository used by the Flux Instance.</p>"},{"location":"operator/resourcesets/github-pull-requests/#preview-namespace","title":"Preview namespace","text":"<p>First we'll create a dedicated namespace called <code>app-preview</code> where all the app instances generated from GitHub Pull Requests will be deployed. We'll also create a service account for Flux that limits the permissions to the <code>app-preview</code> namespace.</p> <pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: app-preview\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: flux\n  namespace: app-preview\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: flux\n  namespace: app-preview\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: admin\nsubjects:\n  - kind: ServiceAccount\n    name: flux\n    namespace: app-preview\n</code></pre>"},{"location":"operator/resourcesets/github-pull-requests/#github-authentication","title":"GitHub authentication","text":"<p>In the <code>app-preview</code> namespace, we'll create a Kubernetes Secret containing a GitHub PAT that grants read access to the app repository and PRs.</p> <pre><code>flux -n app-preview create secret git github-auth \\\n  --url=https://github.com/org/app \\\n  --username=flux \\\n  --password=${GITHUB_TOKEN}\n</code></pre> <p>Alternatively, we can use a GitHub App token for authentication:</p> <pre><code>flux create secret githubapp github-auth \\\n  --app-id=\"1\" \\\n  --app-installation-id=\"2\" \\\n  --app-private-key=./private-key-file.pem\n</code></pre> <p>Note that GitHub App support was added in Flux v2.5 and Flux Operator v0.15.</p>"},{"location":"operator/resourcesets/github-pull-requests/#resourceset-input-provider","title":"ResourceSet input provider","text":"<p>In the <code>app-preview</code> namespace, we'll create a ResourceSetInputProvider that tells Flux Operator to scan the repository for PRs labeled with <code>deploy/flux-preview</code>:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSetInputProvider\nmetadata:\n  name: app-pull-requests\n  namespace: app-preview\n  annotations:\n    fluxcd.controlplane.io/reconcileEvery: \"10m\"\nspec:\n  type: GitHubPullRequest\n  url: https://github.com/org/app\n  secretRef:\n    name: github-auth\n  filter:\n    labels:\n      - \"deploy/flux-preview\"\n  defaultValues:\n    chart: \"charts/app\"\n</code></pre>"},{"location":"operator/resourcesets/github-pull-requests/#github-webhook","title":"GitHub Webhook","text":"<p>Optionally, we can create a Flux Webhook Receiver that GitHub will call to notify the Flux Operator when a new PR is opened or updated: </p> <pre><code>apiVersion: notification.toolkit.fluxcd.io/v1\nkind: Receiver\nmetadata:\n  name: github-receiver\n  namespace: app-preview\nspec:\n  type: github\n  secretRef:\n    name: receiver-token\n  resources:\n    - apiVersion: fluxcd.controlplane.io/v1\n      kind: ResourceSetInputProvider\n      name: app-pull-requests\n</code></pre>"},{"location":"operator/resourcesets/github-pull-requests/#resourceset-template","title":"ResourceSet template","text":"<p>Finally, to deploy the app from PRs we'll create a ResourceSet that takes its inputs from the <code>ResourceSetInputProvider</code>:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSet\nmetadata:\n  name: app\n  namespace: app-preview\nspec:\n  serviceAccountName: flux\n  inputsFrom:\n    - apiVersion: fluxcd.controlplane.io/v1\n      kind: ResourceSetInputProvider\n      name: app-pull-requests\n  resources:\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: GitRepository\n      metadata:\n        name: app-&lt;&lt; inputs.id &gt;&gt;\n        namespace: app-preview\n      spec:\n        provider: generic # or 'github' if using GitHub App\n        interval: 1h\n        url: https://github.com/org/app\n        ref:\n          commit: &lt;&lt; inputs.sha &gt;&gt;\n        secretRef:\n          name: github-auth\n    - apiVersion: helm.toolkit.fluxcd.io/v2\n      kind: HelmRelease\n      metadata:\n        name: app-&lt;&lt; inputs.id &gt;&gt;\n        namespace: app-preview\n        annotations:\n          event.toolkit.fluxcd.io/preview-url: \"https://app-&lt;&lt; inputs.id &gt;&gt;.example.com\"\n          event.toolkit.fluxcd.io/pr-number: &lt;&lt; inputs.id | quote &gt;&gt;\n          event.toolkit.fluxcd.io/branch: &lt;&lt; inputs.branch | quote &gt;&gt;\n          event.toolkit.fluxcd.io/author: &lt;&lt; inputs.author | quote &gt;&gt;\n      spec:\n        serviceAccountName: flux\n        interval: 10m\n        releaseName: app-&lt;&lt; inputs.id &gt;&gt;\n        chart:\n          spec:\n            chart: &lt;&lt; inputs.chart &gt;&gt;\n            reconcileStrategy: Revision\n            sourceRef:\n              kind: GitRepository\n              name: app-&lt;&lt; inputs.id &gt;&gt;\n        values:\n          image:\n            tag: &lt;&lt; inputs.sha &gt;&gt;\n          ingress:\n            hosts:\n              - host: app-&lt;&lt; inputs.id &gt;&gt;.example.com\n</code></pre> <p>The above <code>ResouceSet</code> will generate a Flux <code>GitRepository</code> and a <code>HelmRelease</code> for each opened PR. The PR number passed as <code>&lt;&lt; inputs.id &gt;&gt;</code> is used as the name suffix for the Flux objects, and is also used to compose the Ingress host name where the app can be accessed.</p> <p>The latest commit SHA pushed to the PR HEAD is passed as <code>&lt;&lt; inputs.sha &gt;&gt;</code>, the SHA is used to set the app image tag in the Helm release values.</p> <p>The preview URL, PR number, branch name and author are set as annotations on the HelmRelease object to enrich the Flux notifications that the dev team receives.</p> <p>To verify the ResourceSet templates are valid, we can use the Flux Operator CLI and build them locally:</p> <pre><code>flux-operator build resourceset -f app-resourceset.yaml \\\n  --inputs-from test-inputs.yaml\n</code></pre> <p>The <code>test-inputs.yaml</code> file should contain mock PR data e.g.:</p> <pre><code>   - author: test\n     branch: feat/test\n     id: \"1\"\n     sha: bf5d6e01cf802734853f6f3417b237e3ad0ba35d\n     title: 'testing'\n</code></pre>"},{"location":"operator/resourcesets/github-pull-requests/#notifications","title":"Notifications","text":"<p>To receive notifications when a PR triggers a Helm release install, upgrade and uninstall (including any deploy errors), a Flux Alert can be created in the <code>app-preview</code> namespace:</p> <pre><code>---\napiVersion: notification.toolkit.fluxcd.io/v1beta3\nkind: Provider\nmetadata:\n  name: slack-bot\n  namespace: app-preview\nspec:\n  type: slack\n  channel: general\n  address: https://slack.com/api/chat.postMessage\n  secretRef:\n    name: slack-bot-token\n---\napiVersion: notification.toolkit.fluxcd.io/v1beta3\nkind: Alert\nmetadata:\n  name: slack\n  namespace: app-preview\nspec:\n  providerRef:\n    name: slack-bot\n  eventSources:\n    - kind: GitRepository\n      name: '*'\n    - kind: HelmRelease\n      name: '*'\n  eventMetadata:\n    cluster: \"preview-cluster-1\"\n    region: \"us-east-1\"\n</code></pre>"},{"location":"operator/resourcesets/github-pull-requests/#status-reporting-on-pull-requests","title":"Status reporting on Pull Requests","text":"<p>To notify the developers of the preview deployment status, we can use the Flux GitHub Dispatch Provider to post a comment on the PR page with the preview URL and the latest Helm release status.</p> <p>First we create a Flux Provider and Alert in the <code>app-preview</code> namespace:</p> <pre><code>---\napiVersion: notification.toolkit.fluxcd.io/v1beta3\nkind: Provider\nmetadata:\n  name: github-dispatch\n  namespace: app-preview\nspec:\n  type: githubdispatch\n  address: https://github.com/org/app\n  secretRef:\n    name: github-auth\n---\napiVersion: notification.toolkit.fluxcd.io/v1beta3\nkind: Alert\nmetadata:\n  name: github-pr-comment\n  namespace: app-preview\nspec:\n  providerRef:\n    name: github-dispatch\n  eventSources:\n    - kind: HelmRelease\n      name: '*'\n</code></pre> <p>Then in the GitHub repository, we need to define a GitHub Workflow that parses the Flux event metadata and posts a comment on the PR page:</p> <pre><code>name: flux-preview-comment\non:\n  repository_dispatch:\njobs:\n  comment:\n    if: github.event.client_payload.metadata.pr-number != ''\n    runs-on: ubuntu-latest\n    permissions:\n      pull-requests: write\n    steps:\n      - name: Compose Comment\n        run: |\n          tee comment.md &lt;&lt;'EOF'\n          Flux deployment ${{ github.event.client_payload.severity }}:\n          - Preview URL: ${{ github.event.client_payload.metadata.preview-url }}\n          - Revision: ${{ github.event.client_payload.metadata.revision }}\n          - Status: ${{ github.event.client_payload.message }}\n          EOF\n      - name: Post Comment\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          GITHUB_REPO: ${{ github.repository }}\n          PR_NUMBER: ${{ github.event.client_payload.metadata.pr-number }}\n        run: |\n          gh pr comment $PR_NUMBER \\\n          --repo $GITHUB_REPO \\\n          --body-file comment.md \\\n          --create-if-none \\\n          --edit-last\n</code></pre> <p>Every time a commit is pushed to the PR branch, the Flux Operator will upgrade the Helm release and will update the PR comment with the latest deployment status and the preview URL.</p>"},{"location":"operator/resourcesets/github-pull-requests/#github-workflow","title":"GitHub Workflow","text":"<p>To automate the build and push of the app container image to GitHub Container Registry, the GitHub Actions workflow should include the following steps:</p> <pre><code>name: push-image-preview\non:\n  pull_request:\n    branches: ['main']\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Login to GitHub Container Registry\n        uses: docker/login-action@v3\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n      - name: Generate image metadata\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: |\n            ghcr.io/${{ github.repository }}\n          tags: |\n            type=raw,value=${{ github.event.pull_request.head.sha }}\n      - name: Build and push image\n        uses: docker/build-push-action@v6\n        with:\n          push: true\n          context: .\n          file: ./Dockerfile\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n</code></pre> <p>Note that we tag the container image with <code>${{ github.event.pull_request.head.sha }}</code>. This ensures that the image tag matches the commit SHA of the PR HEAD that the ResourceSet uses to deploy the app.</p>"},{"location":"operator/resourcesets/github-pull-requests/#delay-updates-if-the-build-takes-too-long","title":"Delay updates if the build takes too long","text":"<p>If your GitHub Workflow takes too long to build artifacts, e.g. more than 10 minutes, you may want to keep the previous commit SHA in the ResourceSet until the new SHA is completely built by your workflow. In order to do that you can use a Flux <code>Receiver</code> of the type <code>generic</code> instead of <code>github</code> to trigger the reconciliation of the <code>ResourceSetInputProvider</code>:</p> <pre><code>apiVersion: notification.toolkit.fluxcd.io/v1\nkind: Receiver\nmetadata:\n  name: github-receiver\n  namespace: app-preview\nspec:\n  type: generic\n  secretRef:\n    name: receiver-token\n  resources:\n    - apiVersion: fluxcd.controlplane.io/v1\n      kind: ResourceSetInputProvider\n      name: app-pull-requests\n</code></pre> <p>This is necessary because the Flux webhook must be called only at the end of the GitHub Workflow, so make sure to store the webhook URL as a secret in your GitHub repository, e.g. <code>FLUX_RECEIVER_WEBHOOK</code>.</p> <p>You also need to create a label in your GitHub repository to tell the <code>ResourceSetInputProvider</code> to skip updating the exported inputs for the pull request when this label is present, e.g. <code>deploy/flux-preview-pause</code>. This label will be dynamically added and removed by the GitHub Workflow that builds the artifacts. In your <code>ResourceSetInputProvider</code> add the following configuration:</p> <pre><code>...\nspec:\n  skip:\n    labels:\n      - \"deploy/flux-preview-pause\"\n...\n</code></pre> <p>Finally, add the following parts to the job of your GitHub Workflow:</p> <pre><code>...\n    permissions:\n      pull-requests: write # for adding/removing labels to the pull request\n...\n      # Add the following immediately after the checkout step (checkout must always be the first):\n      - name: Add label to prevent ResourceSetInputProvider from updating\n        run: gh pr edit $PR_NUMBER --add-label deploy/flux-preview-pause\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          PR_NUMBER: ${{ github.event.pull_request.number }}\n...\n      # Add the following at the end of the job:\n      - name: Remove label to allow ResourceSetInputProvider to update\n        run: gh pr edit $PR_NUMBER --remove-label deploy/flux-preview-pause\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          PR_NUMBER: ${{ github.event.pull_request.number }}\n      - name: Trigger Flux Receiver\n        run: curl -X POST $FLUX_RECEIVER_WEBHOOK\n        env:\n          FLUX_RECEIVER_WEBHOOK: ${{ secrets.FLUX_RECEIVER_WEBHOOK }}\n</code></pre> <p>There's still a chance that Flux Operator will reconcile your <code>ResourceSetInputProvider</code> between the moment when you make a Git push and the moment when the GitHub Workflow adds the pause label, this will cause your ephemeral environment to be updated with the new SHA before the artifacts are built, but this is unlikely to happen if your GitHub Workflows are quickly scheduled on runners.</p>"},{"location":"operator/resourcesets/github-pull-requests/#further-reading","title":"Further reading","text":"<p>To learn more about ResourceSets and the various configuration options, see the following docs:</p> <ul> <li>ResourceSet API reference</li> <li>ResourceSetInputProvider API reference</li> </ul>"},{"location":"operator/resourcesets/gitlab-merge-requests/","title":"Ephemeral Environments for GitLab Merge Requests","text":"<p>This guide demonstrates how to use the Flux Operator ResourceSet API to automate the deployment of applications changes made in GitLab Merge Requests to ephemeral environments for testing and validation.</p>"},{"location":"operator/resourcesets/gitlab-merge-requests/#development-workflow","title":"Development workflow","text":"<ul> <li>A developer opens a Merge Requests with changes to the app code and Helm chart.</li> <li>The CI builds and pushes the app container image to GitLab Container Registry. The image is tagged with the Git commit SHA.</li> <li>Another developer reviews the changes and labels the Merge Request with the <code>deploy/flux-preview</code> label.</li> <li>Flux Operator running in the preview cluster scans the GitLab project and finds the new MR using the label filter.</li> <li>Flux Operator installs a Helm release using the MR number and the commit SHA inputs to deploy the app and chart changes in the cluster.</li> <li>The app is accessible at a preview URL composed of the MR number and the app name.</li> <li>The developers iterate over changes, with each push to the MR branch triggering a Helm release upgrade in the cluster.</li> <li>The developers are notified of the Helm release status in the MS Teams channel.</li> <li>Once the MR is approved and merged, the Flux Operator uninstalls the Helm release from the cluster.</li> </ul>"},{"location":"operator/resourcesets/gitlab-merge-requests/#gitops-workflow","title":"GitOps workflow","text":"<p>To enable the development workflow, we'll define a series of Flux Operator custom resources in the preview cluster. Note that the preview cluster must be provisioned with a Flux Instance and the Kubernetes manifests part of the GitOps workflow should be stored in the GitLab project used by the Flux Instance.</p>"},{"location":"operator/resourcesets/gitlab-merge-requests/#preview-namespace","title":"Preview namespace","text":"<p>First we'll create a dedicated namespace called <code>app-preview</code> where all the app instances generated from GitLab Merge Requests will be deployed. We'll also create a service account for Flux that limits the permissions to the <code>app-preview</code> namespace.</p> <pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: app-preview\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: flux\n  namespace: app-preview\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: flux\n  namespace: app-preview\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: admin\nsubjects:\n  - kind: ServiceAccount\n    name: flux\n    namespace: app-preview\n</code></pre> <p>In this namespace, we'll create a Kubernetes Secret containing a GitLab PAT that grants read access to the app project and MRs.</p> <pre><code>flux -n app-preview create secret git gitlab-token-readonly \\\n  --url=https://gitlab.com/group/app \\\n  --username=flux \\\n  --password=${GITLAB_TOKEN}\n</code></pre>"},{"location":"operator/resourcesets/gitlab-merge-requests/#resourceset-input-provider","title":"ResourceSet input provider","text":"<p>In the <code>app-preview</code> namespace, we'll create a ResourceSetInputProvider that tells Flux Operator to scan the GitLab project for MRs labeled with <code>deploy/flux-preview</code>:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSetInputProvider\nmetadata:\n  name: app-merge-requests\n  namespace: app-preview\n  annotations:\n    fluxcd.controlplane.io/reconcileEvery: \"10m\"\nspec:\n  type: GitLabMergeRequest\n  url: https://gitlab.com/group/app\n  secretRef:\n    name: gitlab-token-readonly\n  filter:\n    labels:\n      - \"deploy/flux-preview\"\n  defaultValues:\n    chart: \"charts/app\"\n</code></pre>"},{"location":"operator/resourcesets/gitlab-merge-requests/#gitlab-webhook","title":"GitLab Webhook","text":"<p>Optionally, we can create a Flux Webhook Receiver that GitLab will call to notify the Flux Operator when a new MR is opened or updated: </p> <pre><code>apiVersion: notification.toolkit.fluxcd.io/v1\nkind: Receiver\nmetadata:\n  name: gitlab-receiver\n  namespace: app-preview\nspec:\n  type: gitlab\n  secretRef:\n    name: receiver-token\n  resources:\n    - apiVersion: fluxcd.controlplane.io/v1\n      kind: ResourceSetInputProvider\n      name: app-merge-requests\n</code></pre>"},{"location":"operator/resourcesets/gitlab-merge-requests/#resourceset-template","title":"ResourceSet template","text":"<p>Finally, to deploy the app from MRs, we'll create a ResourceSet that uses the <code>ResourceSetInputProvider</code> as its input source:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSet\nmetadata:\n  name: app\n  namespace: app-preview\nspec:\n  serviceAccountName: flux\n  inputsFrom:\n    - apiVersion: fluxcd.controlplane.io/v1\n      kind: ResourceSetInputProvider\n      name: app-merge-requests\n  resources:\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: GitRepository\n      metadata:\n        name: app-&lt;&lt; inputs.id &gt;&gt;\n        namespace: app-preview\n      spec:\n        interval: 1h\n        url: https://gitlab.com/group/app\n        ref:\n          commit: &lt;&lt; inputs.sha &gt;&gt;\n        secretRef:\n          name: gitlab-token-readonly\n    - apiVersion: helm.toolkit.fluxcd.io/v2\n      kind: HelmRelease\n      metadata:\n        name: app-&lt;&lt; inputs.id &gt;&gt;\n        namespace: app-preview\n        annotations:\n          event.toolkit.fluxcd.io/preview-url: \"https://app-&lt;&lt; inputs.id &gt;&gt;.example.com\"\n          event.toolkit.fluxcd.io/branch: &lt;&lt; inputs.branch | quote &gt;&gt;\n          event.toolkit.fluxcd.io/author: &lt;&lt; inputs.author | quote &gt;&gt;\n      spec:\n        serviceAccountName: flux\n        interval: 10m\n        releaseName: app-&lt;&lt; inputs.id &gt;&gt;\n        chart:\n          spec:\n            chart: &lt;&lt; inputs.chart &gt;&gt;\n            reconcileStrategy: Revision\n            sourceRef:\n              kind: GitRepository\n              name: app-&lt;&lt; inputs.id &gt;&gt;\n        values:\n          image:\n            tag: &lt;&lt; inputs.sha &gt;&gt;\n          ingress:\n            hosts:\n              - host: app-&lt;&lt; inputs.id &gt;&gt;.example.com\n</code></pre> <p>The above <code>ResouceSet</code> will generate a Flux <code>GitRepository</code> and a <code>HelmRelease</code> for each opened MR. The MR number passed as <code>&lt;&lt; inputs.id &gt;&gt;</code> is used as the name suffix for the Flux objects, and is also used to compose the Ingress host name where the app can be accessed.</p> <p>The latest commit SHA pushed to the MR HEAD is passed as <code>&lt;&lt; inputs.sha &gt;&gt;</code>, the SHA is used to set the app image tag in the Helm release values.</p> <p>The preview URL, branch name and author are set as annotations on the HelmRelease object to enrich the Flux notifications that the dev team receives.</p> <p>To verify the ResourceSet templates are valid, we can use the Flux Operator CLI and build them locally:</p> <pre><code>flux-operator build resourceset -f app-resourceset.yaml \\\n  --inputs-from test-inputs.yaml\n</code></pre> <p>The <code>test-inputs.yaml</code> file should contain mock MR data e.g.:</p> <pre><code>   - author: test\n     branch: feat/test\n     id: \"1\"\n     sha: bf5d6e01cf802734853f6f3417b237e3ad0ba35d\n     title: 'testing'\n</code></pre>"},{"location":"operator/resourcesets/gitlab-merge-requests/#notifications","title":"Notifications","text":"<p>To receive notifications when a MR triggers a Helm release install, upgrade and uninstall (including any deploy errors), a Flux Alert can be created in the <code>app-preview</code> namespace:</p> <pre><code>---\napiVersion: notification.toolkit.fluxcd.io/v1beta3\nkind: Provider\nmetadata:\n  name: msteams\n  namespace: app-preview\nspec:\n  type: msteams\n  secretRef:\n    name: msteams-webhook\n---\napiVersion: notification.toolkit.fluxcd.io/v1beta3\nkind: Alert\nmetadata:\n  name: msteams\n  namespace: app-preview\nspec:\n  providerRef:\n    name: msteams\n  eventSources:\n    - kind: GitRepository\n      name: '*'\n    - kind: HelmRelease\n      name: '*'\n  eventMetadata:\n    cluster: \"preview-cluster-1\"\n    region: \"eastus-1\"\n</code></pre>"},{"location":"operator/resourcesets/gitlab-merge-requests/#further-reading","title":"Further reading","text":"<p>To learn more about ResourceSets and the various configuration options, see the following docs:</p> <ul> <li>ResourceSet API reference</li> <li>ResourceSetInputProvider API reference</li> </ul>"},{"location":"operator/resourcesets/image-automation/","title":"Using ResourceSets for Image Update Automation","text":"<p>This guide demonstrates how to use the Flux Operator APIs as an alternative to the Flux Image Automation controllers.</p> <p>The Flux Operator approach to image update automation is suitable for Gitless GitOps workflows where instead of pushing changes to a Git repository, the updates are applied directly to the cluster based on policies defined in the desired state.</p>"},{"location":"operator/resourcesets/image-automation/#how-resourcesets-and-input-providers-work","title":"How ResourceSets and Input Providers Work","text":"<p>Before diving into the configuration, it's important to understand how The Flux Operator APIs work together to enable deployment rollouts based on container image updates.</p> <p>The ResourceSet API allows you to define a set of Flux resources for deploying an application, while the ResourceSetInputProvider API is used to provide inputs to the <code>ResourceSet</code>, such as Helm chart versions and container image tags that determine which configuration of the application should be deployed.</p>"},{"location":"operator/resourcesets/image-automation/#gitops-workflow","title":"GitOps Workflow","text":"<p>To demonstrate the image update automation workflow, we'll define a series of Flux Operator custom resources in a cluster. Note that the cluster must be provisioned with a Flux Instance.</p> <p>For this example, we'll use the <code>podinfo</code> demo application, that consists of a Helm chart stored as an OCI artifact in GitHub Container Registry that deploys two container images: <code>podinfo</code> and <code>redis</code>.</p>"},{"location":"operator/resourcesets/image-automation/#configure-registry-scanning","title":"Configure Registry Scanning","text":"<p>First, we'll create a <code>ResourceSetInputProvider</code> that scan the registry for new versions of the <code>podinfo</code> Helm chart and pick the latest stable version according to semver:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSetInputProvider\nmetadata:\n  name: podinfo-chart\n  namespace: apps\n  annotations:\n    fluxcd.controlplane.io/reconcileEvery: \"15m\"\nspec:\n  type: OCIArtifactTag\n  url: oci://ghcr.io/stefanprodan/charts/podinfo\n  filter:\n    semver: \"&gt;=6.0.0\"\n    limit: 1\n</code></pre> <p>Next, we'll create a <code>ResourceSetInputProvider</code> the podinfo container image that scans the registry for new digests of <code>ghcr.io/stefanprodan/podinfo:latest</code> image:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSetInputProvider\nmetadata:\n  name: podinfo-image\n  namespace: apps\n  annotations:\n    fluxcd.controlplane.io/reconcileEvery: \"5m\"\nspec:\n  type: OCIArtifactTag\n  url: oci://ghcr.io/stefanprodan/podinfo\n  filter:\n    includeTag: \"latest\"\n    limit: 1\n</code></pre> <p>Finally, we'll create a <code>ResourceSetInputProvider</code> for the <code>docker.io/redis</code> image that picks the latest semver version of the alpine variant:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSetInputProvider\nmetadata:\n  name: redis-image\n  namespace: apps\n  annotations:\n    fluxcd.controlplane.io/reconcileEvery: \"15m\"\nspec:\n  type: OCIArtifactTag\n  url: oci://docker.io/redis\n  filter:\n    semver: \"&gt;0.0.0-0\"\n    includeTag: \".*-alpine$\"\n    limit: 1\n</code></pre> <p>Note that you can provide credentials for private registries by referencing a Secret of type <code>kubernetes.io/dockerconfigjson</code> in the <code>spec.secretRef</code> field.</p>"},{"location":"operator/resourcesets/image-automation/#configure-the-app-deployment","title":"Configure the App Deployment","text":"<p>With the providers in place, we can now create a <code>ResourceSet</code> that generates the Flux resources required to deploy the <code>podinfo</code> application using the latest chart and container images exported by the input providers:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSet\nmetadata:\n  name: podinfo\n  namespace: apps\n  annotations:\n    fluxcd.controlplane.io/reconcileTimeout: \"5m\"\nspec:\n  inputStrategy:\n    name: Permute\n  inputsFrom:\n    - kind: ResourceSetInputProvider\n      name: podinfo-chart\n    - kind: ResourceSetInputProvider\n      name: podinfo-image\n    - kind: ResourceSetInputProvider\n      name: redis-image\n  resources:\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: OCIRepository\n      metadata:\n        name: podinfo\n        namespace: &lt;&lt; inputs.podinfo_chart.provider.namespace &gt;&gt;\n      spec:\n        interval: 12h\n        url: oci://ghcr.io/stefanprodan/charts/podinfo\n        ref:\n          tag: &lt;&lt; inputs.podinfo_chart.tag &gt;&gt;\n    - apiVersion: helm.toolkit.fluxcd.io/v2\n      kind: HelmRelease\n      metadata:\n        name: podinfo\n        namespace: &lt;&lt; inputs.podinfo_chart.provider.namespace &gt;&gt;\n      spec:\n        interval: 30m\n        releaseName: podinfo\n        chartRef:\n          kind: OCIRepository\n          name: podinfo\n        values:\n          image:\n            tag: \"&lt;&lt; inputs.podinfo_image.tag &gt;&gt;@&lt;&lt; inputs.podinfo_image.digest &gt;&gt;\"\n          redis:\n            enabled: true\n            tag: \"&lt;&lt; inputs.redis_image.tag &gt;&gt;@&lt;&lt; inputs.redis_image.digest &gt;&gt;\"\n</code></pre> <p>In the resources section of the <code>ResourceSet</code>, we define an <code>OCIRepository</code> that points to the Helm chart and a <code>HelmRelease</code> that deploys the application using the chart.</p> <p>The chart version is set using the <code>&lt;&lt; inputs.podinfo_chart.tag &gt;&gt;</code> template variable, which is populated by the <code>podinfo-chart</code> input provider. Every time the input provider detects a new chart version, the <code>ResourceSet</code> will trigger a Helm release upgrade to deploy the new version.</p> <p>The container image tags for <code>podinfo</code> and <code>redis</code> are set along with their digests using the following template variables:</p> <ul> <li><code>&lt;&lt; inputs.podinfo_image.tag &gt;&gt;@&lt;&lt; inputs.podinfo_image.digest &gt;&gt;</code></li> <li><code>&lt;&lt; inputs.redis_image.tag &gt;&gt;@&lt;&lt; inputs.redis_image.digest &gt;&gt;</code></li> </ul> <p>These template variables are populated by the respective input providers and will trigger a Helm release upgrade whenever a new image version is detected, either based on a new digest for the <code>latest</code> tag of <code>podinfo</code> or a new semver version of the <code>redis</code> image.</p>"},{"location":"operator/resourcesets/image-automation/#patching-container-images","title":"Patching Container Images","text":"<p>There are cases when a Helm chart does not expose all its images in values. In such cases, you can use Kustomize patches to modify the manifests before helm-controller applies them:</p> <pre><code>apiVersion: helm.toolkit.fluxcd.io/v2\nkind: HelmRelease\nspec:\n  postRenderers:\n    - kustomize:            \n        images:\n          - name: ghcr.io/stefanprodan/podinfo\n            newTag: &lt;&lt; inputs.podinfo_image.tag | quote &gt;&gt;\n            digest: &lt;&lt; inputs.podinfo_image.digest | quote &gt;&gt;\n</code></pre> <p>Similarly, when an application is deployed using a Flux <code>Kustomization</code>, you can use the <code>.spec.images</code> field to define the container images to be updated:</p> <pre><code>apiVersion: kustomize.toolkit.fluxcd.io/v1\nkind: Kustomization\nspec:\n  images:\n    - name: ghcr.io/stefanprodan/podinfo\n      newTag: &lt;&lt; inputs.podinfo_image.tag | quote &gt;&gt;\n      digest: &lt;&lt; inputs.podinfo_image.digest | quote &gt;&gt;\n</code></pre>"},{"location":"operator/resourcesets/image-automation/#configure-notifications","title":"Configure Notifications","text":"<p>To get notified when the image update triggers a deployment, we can create a Flux Alert that sends notifications to e.g. a Slack channel:</p> <pre><code>---\napiVersion: notification.toolkit.fluxcd.io/v1beta3\nkind: Provider\nmetadata:\n  name: slack-bot\n  namespace: apps\nspec:\n  type: slack\n  channel: general\n  address: https://slack.com/api/chat.postMessage\n  secretRef:\n    name: slack-bot-token\n---\napiVersion: notification.toolkit.fluxcd.io/v1beta3\nkind: Alert\nmetadata:\n  name: slack\n  namespace: apps\nspec:\n  providerRef:\n    name: slack-bot\n  eventSources:\n    - kind: OCIRepository\n      name: '*'\n    - kind: HelmRelease\n      name: '*'\n    - kind: Kustomization\n      name: '*'\n    - kind: ResourceSet\n      name: '*'\n  eventMetadata:\n    cluster: \"dev-cluster-1\"\n    region: \"us-east-1\"\n</code></pre>"},{"location":"operator/resourcesets/image-automation/#working-with-resourcesets","title":"Working with ResourceSets","text":"<p>Using the Flux Operator CLI, you can interact with ResourceSets and their input providers.</p> <p>To view the status of the <code>ResourceSet</code>, its input providers and the deployed <code>HelmRelease</code>:</p> <pre><code>flux-operator -n apps get all\n</code></pre> <p>To pause the update automation for a particular image, you can suspend the corresponding <code>ResourceSetInputProvider</code> with:</p> <pre><code>flux-operator -n apps suspend rsip redis-image\n</code></pre> <p>To pause the entire image update automation workflow, you can suspend the <code>ResourceSet</code> with:</p> <pre><code>flux-operator -n apps suspend rset podinfo\n</code></pre> <p>To resume the automation:</p> <pre><code>flux-operator -n apps resume rsip redis-image\nflux-operator -n apps resume rset podinfo\n</code></pre> <p>To trigger an immediate image scan:</p> <pre><code>flux-operator -n apps reconcile rsip redis-image\n</code></pre> <p>In addition, you can use the CLI to build the <code>ResourceSet</code> locally and verify that the templates are valid with mock input data:</p> <pre><code>flux-operator build rset -f podinfo-resourceset.yaml \\\n  --inputs-from-provider static-inputs.yaml\n</code></pre>"},{"location":"operator/resourcesets/image-automation/#further-reading","title":"Further reading","text":"<p>To learn more about ResourceSets and the various configuration options, see the following docs:</p> <ul> <li>ResourceSet API reference</li> <li>ResourceSetInputProvider API reference</li> </ul>"},{"location":"operator/resourcesets/introduction/","title":"ResourceSets Introduction","text":"<p>The Flux Operator ResourceSet API offers a high-level abstraction for defining and managing Flux resources and related Kubernetes objects as a single unit. The ResourceSet API is designed to reduce the complexity of GitOps workflows and to enable self-service for developers and platform teams.</p>"},{"location":"operator/resourcesets/introduction/#features","title":"Features","text":""},{"location":"operator/resourcesets/introduction/#application-definitions","title":"Application definitions","text":"<p>The CNCF Flux project does not impose a specific application definition format or structure, instead it provides a set of APIs that can be used as building blocks to define and manage the continuous delivery of applications in a GitOps manner.</p> <p>The Flux Operator with the ResourceSet API enables platform teams to define their own application standard as a group of Flux and Kubernetes resources that can be templated, parameterized and deployed as a single unit across environments.</p> <p>To get started with ResourceSets see the Using ResourceSets for Application Definitions guide.</p>"},{"location":"operator/resourcesets/introduction/#self-service-environments","title":"Self-service environments","text":"<p>A main goal of the Flux Operator is to enable self-service environments. In order to achieve this, the ResourceSet controller integrates with services such as GitHub and GitLab to automate the lifecycle of applications based on external events and state changes.</p> <p>One such use-case is deploying app code and/or config changes made in a GitHub Pull Request or GitLab Merge Request to an ephemeral environment for testing and validation. The Flux Operator has the ability to create, update and delete application instances on-demand based on the ResourceSet definitions and Pull/Merge Requests state.</p> <p>To get started with self-service environments see the following guides:</p> <ul> <li>Ephemeral Environments for GitHub Pull Requests</li> <li>Ephemeral Environments for GitLab Merge Requests</li> </ul> <p>Another use-case is to automate the provisioning of new environments for feature branches, and for long-lived branches to deploy to dedicated namespaces and/or clusters, effectively enabling Namespace-as-a-Service to developers securely in a GitOps manner.</p>"},{"location":"operator/resourcesets/introduction/#time-based-delivery","title":"Time-based Delivery","text":"<p>The ResourceSet API also supports time-based delivery, allowing platform teams to define deployment windows for applications based on time intervals or specific dates.</p> <p>To get started with deployment windows, see the Time-Based Delivery guide.</p>"},{"location":"operator/resourcesets/time-based-delivery/","title":"Using ResourceSets for Time-Based Delivery","text":"<p>In highly regulated industries, deploying software changes requires strict adherence to compliance frameworks and operational policies. These organizations must demonstrate control over when changes are deployed to production systems, often requiring:</p> <ul> <li>Change Advisory Board (CAB) approval windows - Deployments only during pre-approved time slots</li> <li>Business continuity requirements - No deployments during peak business hours or critical operations</li> <li>Compliance auditing - Detailed records of when and why deployments occurred</li> <li>Risk management - Controlled rollout windows to minimize business impact</li> <li>Operational readiness - Ensuring sufficient staff coverage during deployment windows</li> </ul> <p>The Flux Operator addresses these requirements through time-based reconciliation schedules, providing organizations with the governance controls they need while maintaining the benefits of GitOps automation.</p>"},{"location":"operator/resourcesets/time-based-delivery/#how-resourcesets-and-input-providers-work","title":"How ResourceSets and Input Providers Work","text":"<p>Before diving into the configuration, it's important to understand how The Flux Operator APIs work together to enable controlled deployments.</p> <p>The ResourceSet API allows you to define a set of Flux resources for deploying an application, while the ResourceSetInputProvider API is used to provide inputs to the <code>ResourceSet</code>, such as Git commit SHA and branch name or tag name, that determine what version of the application should be deployed.</p> <p>Instead of using a Flux <code>GitRepository</code> and <code>Kustomization</code> directly, we'll generate these resources dynamically with a <code>ResourceSet</code>. To control when Flux pulls changes from Git we'll pin the <code>GitRepository</code> to a specific commit SHA, the <code>ResourceSetInputProvider</code> will be responsible for fetching the latest commit SHA from a Git branch or tag, at the defined reconciliation schedule.</p>"},{"location":"operator/resourcesets/time-based-delivery/#gitops-workflow","title":"GitOps Workflow","text":"<ul> <li>Define a ResourceSetInputProvider: This provider will scan a Git branch or tag    for changes and export the commit SHA as an input.</li> <li>Configure schedule: The provider will have a reconciliation schedule    that defines when it should check for changes in the Git repository.</li> <li>Define a ResourceSet: The ResourceSet will use the inputs from the provider    to create a <code>GitRepository</code> and <code>Kustomization</code> that deploys the application    at the specified commit SHA.</li> </ul>"},{"location":"operator/resourcesets/time-based-delivery/#resourcesetinputprovider-definition","title":"ResourceSetInputProvider Definition","text":"<p>Assuming the Kubernetes deployment manifests for an application are stored in a Git repository, you can define a input provider that scans a branch for changes and exports the commit SHA:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSetInputProvider\nmetadata:\n  name: my-app-main\n  namespace: apps\n  labels:\n    app.kubernetes.io/name: my-app\n  annotations:\n    fluxcd.controlplane.io/reconcileEvery: \"10m\"\n    fluxcd.controlplane.io/reconcileTimeout: \"1m\"\nspec:\n  schedule:\n    - cron: \"0 8 * * 1-5\"\n      timeZone: \"Europe/London\"\n      window: 8h\n  type: GitHubBranch # or GitLabBranch / AzureDevOpsBranch\n  url: https://github.com/my-org/my-app\n  secretRef:\n    name: gh-app-auth\n  filter:\n    includeBranch: \"^main$\"\n  defaultValues:\n    env: \"production\"\n</code></pre> <p>For when Git tags are used to version the application, you can define an input provider that scans the Git tags and exports the latest tag according to a semantic versioning:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSetInputProvider\nmetadata:\n  name: my-app-release\n  namespace: apps\n  labels:\n    app.kubernetes.io/name: my-app\n  annotations:\n    fluxcd.controlplane.io/reconcileEvery: \"10m\"\n    fluxcd.controlplane.io/reconcileTimeout: \"1m\"\nspec:\n  schedule:\n    - cron: \"0 8 * * 1-5\"\n      timeZone: \"Europe/London\"\n      window: 8h\n  type: GitHubTag # or GitLabTag / AzureDevOpsTag\n  url: https://github.com/my-org/my-app\n  secretRef:\n    name: gh-auth\n  filter:\n    semver: \"&gt;=1.0.0\"\n    limit: 1\n</code></pre>"},{"location":"operator/resourcesets/time-based-delivery/#resourceset-definition","title":"ResourceSet Definition","text":"<p>The exported inputs can then be used in a <code>ResourceSet</code> to deploy the application using the commit SHA from the input provider:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSet\nmetadata:\n  name: my-app\n  namespace: apps\nspec:\n  inputsFrom:\n    - kind: ResourceSetInputProvider\n      selector:\n        matchLabels:\n          app.kubernetes.io/name: my-app\n  resources:\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: GitRepository\n      metadata:\n        name: my-app\n        namespace: &lt;&lt; inputs.provider.namespace &gt;&gt;\n      spec:\n        interval: 12h\n        url: https://github.com/my-org/my-app\n        ref:\n          commit: &lt;&lt; inputs.sha &gt;&gt;\n        secretRef:\n          name: gh-auth\n        sparseCheckout:\n          - deploy\n    - apiVersion: kustomize.toolkit.fluxcd.io/v1\n      kind: Kustomization\n      metadata:\n        name: my-app\n        namespace: &lt;&lt; inputs.provider.namespace &gt;&gt;\n      spec:\n        interval: 30m\n        retryInterval: 5m\n        prune: true\n        wait: true\n        timeout: 5m\n        sourceRef:\n          kind: GitRepository\n          name: my-app\n        path: deploy/&lt;&lt; inputs.env &gt;&gt;\n</code></pre> <p>When the <code>ResourceSetInputProvider</code> runs according to its schedule, if it finds a new commit, the <code>ResourceSet</code> will be automatically updated with the new commit SHA which will trigger an application deployment for the new version.</p>"},{"location":"operator/resourcesets/time-based-delivery/#helm-release-workflow","title":"Helm Release Workflow","text":"<p>For applications packaged with Helm, you can use a similar approach to trigger a Helm release upgrade in a controlled manner when a new chart version is available. For this to work, the Helm chart must be stored in a container registry as an OCI artifact.</p> <p>Example <code>ResourceSetInputProvider</code> that scans an OCI repository and exports the latest stable version as an input:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSetInputProvider\nmetadata:\n   name: podinfo-release\n   namespace: apps\n   labels:\n      app.kubernetes.io/name: podinfo\n   annotations:\n      fluxcd.controlplane.io/reconcileEvery: \"10m\"\n      fluxcd.controlplane.io/reconcileTimeout: \"1m\"\nspec:\n   schedule:\n      - cron: \"0 12 * * 1-5\"\n        timeZone: \"UTC\"\n   type: OCIArtifactTag\n   url: oci://ghcr.io/stefanprodan/charts/podinfo\n   filter:\n      semver: \"&gt;=1.0.0\"\n      limit: 1\n</code></pre> <p>Example <code>ResourceSet</code> that deploys a Flux HelmRelease using the artifact tag exported by the input provider as the latest chart version:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSet\nmetadata:\n  name: podinfo\n  namespace: apps\nspec:\n  inputsFrom:\n    - kind: ResourceSetInputProvider\n      selector:\n        matchLabels:\n          app.kubernetes.io/name: podinfo\n  resources:\n    - apiVersion: source.toolkit.fluxcd.io/v1\n      kind: OCIRepository\n      metadata:\n        name: podinfo\n        namespace: &lt;&lt; inputs.provider.namespace &gt;&gt;\n      spec:\n        interval: 10m\n        url: oci://ghcr.io/stefanprodan/charts/podinfo\n        ref:\n          tag: &lt;&lt; inputs.tag &gt;&gt;\n    - apiVersion: helm.toolkit.fluxcd.io/v2\n      kind: HelmRelease\n      metadata:\n        name: podinfo\n        namespace: &lt;&lt; inputs.provider.namespace &gt;&gt;\n      spec:\n        interval: 30m\n        releaseName: podinfo\n        chartRef:\n          kind: OCIRepository\n          name: podinfo\n        values:\n          replicaCount: 2\n</code></pre> <p>OCI Artifacts Support</p> <p>Note that Flux Operator supports OIDC-based authentication for container registries such as Amazon ECR, Azure ACR and Google GAR. For more details, see the ResourceSetInputProvider API reference.</p>"},{"location":"operator/resourcesets/time-based-delivery/#scheduling-configuration","title":"Scheduling Configuration","text":"<p>The <code>.spec.schedule</code> field in the <code>ResourceSetInputProvider</code> allows you to define when the input provider should run to check for changes in source repositories.</p>"},{"location":"operator/resourcesets/time-based-delivery/#schedule-definition","title":"Schedule Definition","text":"<p>The schedule is defined as a list of cron expressions, each with an optional time zone and window.</p> <p>Example:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSetInputProvider\nspec:\n  schedule:\n    # Every day-of-week from Monday through Thursday\n    # between 10:00 to 16:00\n    - cron: \"0 10 * * 1-4\"\n      timeZone: \"America/New_York\"\n      window: \"6h\"\n</code></pre> <p>The <code>cron</code> field accepts standard cron expressions with five fields:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute (0 - 59)\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23)\n\u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of month (1 - 31)\n\u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12)\n\u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of week (0 - 6) (Sunday to Saturday)\n\u2502 \u2502 \u2502 \u2502 \u2502\n* * * * *\n</code></pre> <p>Use crontab.guru to help generate and validate cron expressions.</p> <p>The <code>timeZone</code> field specifies the time zone for interpreting the cron schedule using IANA time zone names. If not specified, the time zone defaults to <code>UTC</code>.</p> <p>The <code>window</code> field defines the duration during which reconciliations are allowed to run after the scheduled time. The format is a Go duration string, e.g. <code>30m</code>, <code>1h</code>, <code>2h30m</code>. Must be either <code>0s</code> (no window) or at least twice the reconciliation timeout <code>4m</code>.</p>"},{"location":"operator/resourcesets/time-based-delivery/#schedule-window","title":"Schedule Window","text":"<p>When a non-zero window is specified, reconciliation is allowed throughout the entire window duration:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSetInputProvider\nmetadata:\n   annotations:\n    fluxcd.controlplane.io/reconcileEvery: \"10m\"\nspec:\n  schedule:\n    - cron: \"0 8 * * 1-5\"\n      timeZone: \"UTC\"\n      window: \"8h\"\n</code></pre> <p>In this case:</p> <ul> <li>At creation time, the input provider will not execute immediately, but will wait for the next scheduled time.</li> <li>The input provider will start reconciling at 08:00 UTC every weekday (Monday to Friday).</li> <li>The reconciliation will continue until 16:00 UTC, every 10 minutes, as specified by the <code>reconcileEvery</code> annotation.</li> <li>Any changes to the input provider object during this window will be reconciled immediately.</li> </ul>"},{"location":"operator/resourcesets/time-based-delivery/#zero-duration-window","title":"Zero-Duration Window","text":"<p>When the window is omitted or set to <code>0s</code>, flux-operator makes the best effort to reconcile at the exact scheduled time:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSetInputProvider\nmetadata:\n   annotations:\n    fluxcd.controlplane.io/reconcileEvery: \"10m\"\nspec:\n  schedule:\n    - cron: \"0 8 * * 1-5\"\n      timeZone: \"UTC\"\n      window: \"0s\"\n</code></pre> <p>In this case:</p> <ul> <li>At creation time, the input provider will execute immediately ignoring the schedule.</li> <li>The input provider will reconcile at 08:00 UTC every weekday (Monday to Friday).</li> <li>Any changes to the input provider object will be reconciled immediately, even outside the scheduled time.</li> </ul>"},{"location":"operator/resourcesets/time-based-delivery/#multiple-schedules","title":"Multiple Schedules","text":"<p>The schedule can contain multiple cron expressions, allowing for complex scheduling scenarios:</p> <pre><code>apiVersion: fluxcd.controlplane.io/v1\nkind: ResourceSetInputProvider\nspec:\n  schedule:\n    # Every day-of-week from Monday through Thursday\n    # between 10:00 to 16:00 NY time\n    - cron: \"0 10 * * 1-4\"\n      timeZone: \"America/New_York\"\n      window: \"6h\"\n    # Every Friday from 10:00 to 13:00 UK time\n    - cron: \"0 10 * * 5\"\n      timeZone: \"Europe/London\"\n      window: \"3h\"\n</code></pre> <p>In this case:</p> <ul> <li>The input provider reconciles if any schedule matches the current time.</li> <li>The next scheduled time is determined by the earliest upcoming schedule.</li> <li>Each schedule operates independently with its own time zone and window.</li> </ul>"},{"location":"operator/resourcesets/time-based-delivery/#command-line-operations","title":"Command-Line Operations","text":"<p>The <code>flux-operator</code> CLI can be used to perform manual operations such as forcing a reconciliation, checking the status of the input provider or disabling it.</p> <p>To force a reconciliation outside the defined schedule:</p> <pre><code>flux-operator reconcile rsip my-app-main --namespace apps --force\n</code></pre> <p>To check the status of input providers including their next schedule time:</p> <pre><code>flux-operator get rsip --all-namespaces\n</code></pre> <p>To suspend an input provider and prevent it from reconciling:</p> <pre><code>flux-operator suspend rsip my-app-main --namespace apps\n</code></pre> <p>To resume a suspended input provider:</p> <pre><code>flux-operator resume rsip my-app-main --namespace apps\n</code></pre> <p>See the Flux Operator CLI documentation for more details on how to use the CLI.</p>"},{"location":"operator/resourcesets/time-based-delivery/#further-reading","title":"Further reading","text":"<p>To learn more about ResourceSets and the various configuration options, see the following docs:</p> <ul> <li>ResourceSet API reference</li> <li>ResourceSetInputProvider API reference</li> </ul>"},{"location":"pricing/","title":"Pricing","text":"<p>The ControlPlane distribution is offered on a yearly subscription basis and includes enterprise-grade support services for running Flux in production.</p>"},{"location":"pricing/#subscription-plans","title":"Subscription Plans","text":"<ul> <li> <p> CPE-1 Bundle</p> <p> Up to 1 cluster or 10 nodes</p> <p> $1250 USD / month</p> <p> Contact us</p> </li> <li> <p> CPE-10 Bundle</p> <p> Up to 10 clusters or 100 nodes</p> <p> $6250 USD / month</p> <p> Contact us</p> </li> <li> <p> CPE-25 Bundle</p> <p> Up to 25 clusters or 250 nodes</p> <p> $10500 USD / month</p> <p> Contact us</p> </li> <li> <p> CPE-100 Bundle</p> <p> Up to 100 clusters or 1000 nodes</p> <p> $42000 USD / month</p> <p> Contact us</p> </li> </ul> <p>Free for non-Production environments</p> <p>The offer is based on the number of Production clusters or the number of Production nodes across clusters (whichever is hit first). Dev &amp; Staging environments are covered at no extra cost.</p> <p>AWS Marketplace</p> <p>Amazon EKS customers can purchase the ControlPlane Enterprise for Flux CD from the AWS Marketplace.</p>"},{"location":"pricing/#support-services","title":"Support Services","text":"<p>ControlPlane offers a range of support services to help you get the most out of Enterprise for Flux CD. The support services included in the subscription plans are:</p> <ul> <li>Around-the-Clock Support: dedicated 24/7/365 on-call assistance for Flux-related production outages</li> <li>Vulnerability Management: disclosures and remediation guidance for Flux-related vulnerabilities</li> <li>Continuous Updates: regular communication on Flux updates, patches, RFCs, and roadmap changes</li> </ul> <p>Additional support services such as training, consulting, architectural reviews, and custom development are available upon request.</p>"},{"location":"pricing/#custom-plans","title":"Custom Plans","text":"<p>At ControlPlane, we understand that organizations come in various sizes and have different requirements, especially when it comes to managing and securing their Kubernetes deployments using GitOps principles. Our goal is to provide exceptional value to our customers while also contributing positively to the open-source CNCF Flux project. ControlPlane Enterprise for Flux CD is designed to meet this dual objective by offering a hardened, enterprise-grade distribution and support services that go beyond what the open-source project provides.</p> <p>Contact us to discuss your specific requirements and to get a quote that fits your needs.</p>"},{"location":"releases/release-v2.2/","title":"Enterprise Distribution for Flux v2.2","text":""},{"location":"releases/release-v2.2/#supported-kubernetes-versions","title":"Supported Kubernetes Versions","text":"Distribution Versions Kubernetes 1.24 1.25 1.26 1.27 1.28 1.29 OpenShift 4.12 4.13 4.14 4.15"},{"location":"releases/release-v2.2/#api-versions","title":"API Versions","text":""},{"location":"releases/release-v2.2/#general-availability-ga","title":"General Availability (GA)","text":"kind apiVersion GitRepository <code>source.toolkit.fluxcd.io/v1</code> Kustomization <code>kustomize.toolkit.fluxcd.io/v1</code> Receiver <code>notification.toolkit.fluxcd.io/v1</code>"},{"location":"releases/release-v2.2/#beta-preview","title":"Beta (Preview)","text":"kind apiVersion Alert <code>notification.toolkit.fluxcd.io/v1beta3</code> Bucket <code>source.toolkit.fluxcd.io/v1beta2</code> HelmChart <code>source.toolkit.fluxcd.io/v1beta2</code> HelmRelease <code>helm.toolkit.fluxcd.io/v2beta2</code> HelmRepository <code>source.toolkit.fluxcd.io/v1beta2</code> ImagePolicy <code>image.toolkit.fluxcd.io/v1beta2</code> ImageRepository <code>image.toolkit.fluxcd.io/v1beta2</code> ImageUpdateAutomation <code>image.toolkit.fluxcd.io/v1beta1</code> OCIRepository <code>source.toolkit.fluxcd.io/v1beta2</code> Provider <code>notification.toolkit.fluxcd.io/v1beta3</code>"},{"location":"releases/release-v2.2/#promotions","title":"Promotions","text":"Kind New Version Deprecated Version Group Alert v1beta3 v1beta2 <code>notification.toolkit.fluxcd.io</code> Provider v1beta3 v1beta2 <code>notification.toolkit.fluxcd.io</code> HelmRelease v2beta2 v2beta2 <code>helm.toolkit.fluxcd.io</code>"},{"location":"releases/release-v2.2/#v223","title":"v2.2.3","text":"<p>Upstream changelog: fluxcd/flux2 v2.2.3</p>"},{"location":"releases/release-v2.2/#mainline-v223","title":"Mainline v2.2.3","text":""},{"location":"releases/release-v2.2/#flux-controllers","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.2.4 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.2.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v0.37.4 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.2.4 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v0.31.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v0.37.1 amd64 / arm64"},{"location":"releases/release-v2.2/#flux-manifests","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.2.3"},{"location":"releases/release-v2.2/#fips-compliant-v223","title":"FIPS-compliant v2.2.3","text":""},{"location":"releases/release-v2.2/#flux-controllers_1","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.2.4 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.2.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v0.37.4 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.2.4 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v0.31.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v0.37.1 amd64 / arm64"},{"location":"releases/release-v2.2/#flux-manifests_1","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.2.3"},{"location":"releases/release-v2.2/#v222","title":"v2.2.2","text":"<p>Upstream changelog: fluxcd/flux2 v2.2.2</p>"},{"location":"releases/release-v2.2/#mainline-v222","title":"Mainline v2.2.2","text":""},{"location":"releases/release-v2.2/#flux-controllers_2","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.2.3 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.2.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v0.37.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.2.3 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v0.31.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v0.37.0 amd64 / arm64"},{"location":"releases/release-v2.2/#flux-manifests_2","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.2.2"},{"location":"releases/release-v2.2/#fips-compliant-v222","title":"FIPS-compliant v2.2.2","text":""},{"location":"releases/release-v2.2/#flux-controllers_3","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.2.3 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.2.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v0.37.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.2.3 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v0.31.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v0.37.0 amd64 / arm64"},{"location":"releases/release-v2.2/#flux-manifests_3","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.2.2"},{"location":"releases/release-v2.2/#v221","title":"v2.2.1","text":"<p>Upstream changelog: fluxcd/flux2 v2.2.1</p>"},{"location":"releases/release-v2.2/#mainline-v221","title":"Mainline v2.2.1","text":""},{"location":"releases/release-v2.2/#flux-controllers_4","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.2.3 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.2.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v0.37.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.2.3 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v0.31.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v0.37.0 amd64 / arm64"},{"location":"releases/release-v2.2/#flux-manifests_4","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.2.1"},{"location":"releases/release-v2.2/#fips-compliant-v221","title":"FIPS-compliant v2.2.1","text":""},{"location":"releases/release-v2.2/#flux-controllers_5","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.2.3 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.2.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v0.37.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.2.3 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v0.31.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v0.37.0 amd64 / arm64"},{"location":"releases/release-v2.2/#flux-manifests_5","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.2.1"},{"location":"releases/release-v2.2/#v220","title":"v2.2.0","text":"<p>Upstream changelog: fluxcd/flux2 v2.2.0</p>"},{"location":"releases/release-v2.2/#mainline-v220","title":"Mainline v2.2.0","text":""},{"location":"releases/release-v2.2/#flux-controllers_6","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.2.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.2.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v0.37.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.2.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v0.31.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v0.37.0 amd64 / arm64"},{"location":"releases/release-v2.2/#flux-manifests_6","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.2.0"},{"location":"releases/release-v2.2/#fips-compliant-v220","title":"FIPS-compliant v2.2.0","text":""},{"location":"releases/release-v2.2/#flux-controllers_7","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.2.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.2.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v0.37.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.2.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v0.31.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v0.37.0 amd64 / arm64"},{"location":"releases/release-v2.2/#flux-manifests_7","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.2.0"},{"location":"releases/release-v2.3/","title":"Enterprise Distribution for Flux v2.3","text":""},{"location":"releases/release-v2.3/#supported-kubernetes-versions","title":"Supported Kubernetes Versions","text":"Distribution Versions Kubernetes 1.25 1.26 1.27 1.28 1.29 1.30 OpenShift 4.12 4.13 4.14 4.15"},{"location":"releases/release-v2.3/#api-versions","title":"API Versions","text":""},{"location":"releases/release-v2.3/#general-availability-ga","title":"General Availability (GA)","text":"kind apiVersion GitRepository <code>source.toolkit.fluxcd.io/v1</code> HelmChart <code>source.toolkit.fluxcd.io/v1</code> HelmRelease <code>helm.toolkit.fluxcd.io/v2</code> HelmRepository <code>source.toolkit.fluxcd.io/v1</code> Kustomization <code>kustomize.toolkit.fluxcd.io/v1</code> Receiver <code>notification.toolkit.fluxcd.io/v1</code>"},{"location":"releases/release-v2.3/#beta-preview","title":"Beta (Preview)","text":"kind apiVersion Alert <code>notification.toolkit.fluxcd.io/v1beta3</code> Bucket <code>source.toolkit.fluxcd.io/v1beta2</code> ImagePolicy <code>image.toolkit.fluxcd.io/v1beta2</code> ImageRepository <code>image.toolkit.fluxcd.io/v1beta2</code> ImageUpdateAutomation <code>image.toolkit.fluxcd.io/v1beta2</code> OCIRepository <code>source.toolkit.fluxcd.io/v1beta2</code> Provider <code>notification.toolkit.fluxcd.io/v1beta3</code>"},{"location":"releases/release-v2.3/#promotions","title":"Promotions","text":"Kind New Version Deprecated Version Group HelmChart v1 v1beta2 <code>source.toolkit.fluxcd.io</code> HelmRelease v2 v2beta2 <code>helm.toolkit.fluxcd.io</code> HelmRepository v1 v1beta2 <code>source.toolkit.fluxcd.io</code> ImageUpdateAutomation v1beta2 v1beta1 <code>image.toolkit.fluxcd.io</code>"},{"location":"releases/release-v2.3/#v230","title":"v2.3.0","text":"<p>Upstream changelog: fluxcd/flux2 v2.3.0</p>"},{"location":"releases/release-v2.3/#mainline-v230","title":"Mainline v2.3.0","text":""},{"location":"releases/release-v2.3/#flux-controllers","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.3.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.3.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v1.0.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.3.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v0.32.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v0.38.0 amd64 / arm64"},{"location":"releases/release-v2.3/#flux-manifests","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.3.0"},{"location":"releases/release-v2.3/#fips-compliant-v230","title":"FIPS-compliant v2.3.0","text":""},{"location":"releases/release-v2.3/#flux-controllers_1","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.3.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.3.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v1.0.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.3.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v0.32.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v0.38.0 amd64 / arm64"},{"location":"releases/release-v2.3/#flux-controllers-for-aws-marketplace","title":"Flux Controllers for AWS Marketplace","text":"Controller Version Architectures <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-controller</code> v1.3.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/kustomize-controller</code> v1.3.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/helm-controller</code> v1.0.1 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/notification-controller</code> v1.3.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-reflector-controller</code> v0.32.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-automation-controller</code> v0.38.0 amd64 / arm64"},{"location":"releases/release-v2.3/#flux-manifests_1","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.3.0"},{"location":"releases/release-v2.4/","title":"Enterprise Distribution for Flux v2.4.x","text":""},{"location":"releases/release-v2.4/#supported-kubernetes-versions","title":"Supported Kubernetes Versions","text":"Distribution Versions Kubernetes 1.26 1.27 1.28 1.29 1.30 1.31 1.32 OpenShift 4.12 4.13 4.14 4.15 4.16 4.17"},{"location":"releases/release-v2.4/#api-versions","title":"API Versions","text":""},{"location":"releases/release-v2.4/#general-availability-ga","title":"General Availability (GA)","text":"kind apiVersion GitRepository <code>source.toolkit.fluxcd.io/v1</code> HelmChart <code>source.toolkit.fluxcd.io/v1</code> HelmRelease <code>helm.toolkit.fluxcd.io/v2</code> HelmRepository <code>source.toolkit.fluxcd.io/v1</code> Bucket <code>source.toolkit.fluxcd.io/v1</code> Kustomization <code>kustomize.toolkit.fluxcd.io/v1</code> Receiver <code>notification.toolkit.fluxcd.io/v1</code>"},{"location":"releases/release-v2.4/#beta-preview","title":"Beta (Preview)","text":"kind apiVersion Alert <code>notification.toolkit.fluxcd.io/v1beta3</code> ImagePolicy <code>image.toolkit.fluxcd.io/v1beta2</code> ImageRepository <code>image.toolkit.fluxcd.io/v1beta2</code> ImageUpdateAutomation <code>image.toolkit.fluxcd.io/v1beta2</code> OCIRepository <code>source.toolkit.fluxcd.io/v1beta2</code> Provider <code>notification.toolkit.fluxcd.io/v1beta3</code>"},{"location":"releases/release-v2.4/#promotions","title":"Promotions","text":"Kind New Version Deprecated Version Group Bucket v1 v1beta2 <code>source.toolkit.fluxcd.io</code>"},{"location":"releases/release-v2.4/#v240","title":"v2.4.0","text":"<p>Upstream changelog: fluxcd/flux2 v2.4.0</p>"},{"location":"releases/release-v2.4/#mainline-v240","title":"Mainline v2.4.0","text":""},{"location":"releases/release-v2.4/#flux-controllers","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.4.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.4.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v1.1.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.4.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v0.33.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v0.39.0 amd64 / arm64"},{"location":"releases/release-v2.4/#flux-manifests","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.4.0"},{"location":"releases/release-v2.4/#fips-compliant-v240","title":"FIPS-compliant v2.4.0","text":""},{"location":"releases/release-v2.4/#flux-controllers_1","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.4.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.4.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v1.1.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.4.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v0.33.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v0.39.0 amd64 / arm64"},{"location":"releases/release-v2.4/#flux-controllers-for-aws-marketplace","title":"Flux Controllers for AWS Marketplace","text":"Controller Version Architectures <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-controller</code> v1.4.1 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/kustomize-controller</code> v1.4.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/helm-controller</code> v1.1.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/notification-controller</code> v1.4.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-reflector-controller</code> v0.33.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-automation-controller</code> v0.39.0 amd64 / arm64"},{"location":"releases/release-v2.4/#flux-manifests_1","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.4.0"},{"location":"releases/release-v2.5/","title":"Enterprise Distribution for Flux v2.5.x","text":""},{"location":"releases/release-v2.5/#supported-kubernetes-versions","title":"Supported Kubernetes Versions","text":"Distribution Versions Kubernetes 1.27 1.28 1.29 1.30 1.31 1.32 1.33 OpenShift 4.12 4.13 4.14 4.15 4.16 4.17 4.18"},{"location":"releases/release-v2.5/#api-versions","title":"API Versions","text":""},{"location":"releases/release-v2.5/#general-availability-ga","title":"General Availability (GA)","text":"kind apiVersion GitRepository <code>source.toolkit.fluxcd.io/v1</code> HelmChart <code>source.toolkit.fluxcd.io/v1</code> HelmRelease <code>helm.toolkit.fluxcd.io/v2</code> HelmRepository <code>source.toolkit.fluxcd.io/v1</code> Bucket <code>source.toolkit.fluxcd.io/v1</code> Kustomization <code>kustomize.toolkit.fluxcd.io/v1</code> Receiver <code>notification.toolkit.fluxcd.io/v1</code>"},{"location":"releases/release-v2.5/#beta-preview","title":"Beta (Preview)","text":"kind apiVersion Alert <code>notification.toolkit.fluxcd.io/v1beta3</code> ImagePolicy <code>image.toolkit.fluxcd.io/v1beta2</code> ImageRepository <code>image.toolkit.fluxcd.io/v1beta2</code> ImageUpdateAutomation <code>image.toolkit.fluxcd.io/v1beta2</code> OCIRepository <code>source.toolkit.fluxcd.io/v1beta2</code> Provider <code>notification.toolkit.fluxcd.io/v1beta3</code>"},{"location":"releases/release-v2.5/#v251","title":"v2.5.1","text":"<p>Upstream changelog: fluxcd/flux2 v2.5.1</p>"},{"location":"releases/release-v2.5/#mainline-v251","title":"Mainline v2.5.1","text":""},{"location":"releases/release-v2.5/#flux-controllers","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.5.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.5.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v1.2.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.5.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v0.34.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v0.40.0 amd64 / arm64"},{"location":"releases/release-v2.5/#flux-manifests","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.5.1"},{"location":"releases/release-v2.5/#fips-compliant-v251","title":"FIPS-compliant v2.5.1","text":""},{"location":"releases/release-v2.5/#flux-controllers_1","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.5.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.5.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v1.2.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.5.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v0.34.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v0.40.0 amd64 / arm64"},{"location":"releases/release-v2.5/#flux-controllers-for-aws-marketplace","title":"Flux Controllers for AWS Marketplace","text":"Controller Version Architectures <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-controller</code> v1.5.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/kustomize-controller</code> v1.5.1 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/helm-controller</code> v1.2.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/notification-controller</code> v1.5.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-reflector-controller</code> v0.34.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-automation-controller</code> v0.40.0 amd64 / arm64"},{"location":"releases/release-v2.5/#flux-manifests_1","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.5.1"},{"location":"releases/release-v2.5/#v250","title":"v2.5.0","text":"<p>Upstream changelog: fluxcd/flux2 v2.5.0</p>"},{"location":"releases/release-v2.5/#mainline-v250","title":"Mainline v2.5.0","text":""},{"location":"releases/release-v2.5/#flux-controllers_2","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.5.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.5.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v1.2.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.5.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v0.34.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v0.40.0 amd64 / arm64"},{"location":"releases/release-v2.5/#flux-manifests_2","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.5.0"},{"location":"releases/release-v2.5/#fips-compliant-v250","title":"FIPS-compliant v2.5.0","text":""},{"location":"releases/release-v2.5/#flux-controllers_3","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.5.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.5.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v1.2.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.5.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v0.34.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v0.40.0 amd64 / arm64"},{"location":"releases/release-v2.5/#flux-controllers-for-aws-marketplace_1","title":"Flux Controllers for AWS Marketplace","text":"Controller Version Architectures <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-controller</code> v1.5.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/kustomize-controller</code> v1.5.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/helm-controller</code> v1.2.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/notification-controller</code> v1.5.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-reflector-controller</code> v0.34.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-automation-controller</code> v0.40.0 amd64 / arm64"},{"location":"releases/release-v2.5/#flux-manifests_3","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.5.0"},{"location":"releases/release-v2.6/","title":"Enterprise Distribution for Flux v2.6.x","text":""},{"location":"releases/release-v2.6/#supported-kubernetes-versions","title":"Supported Kubernetes Versions","text":"Distribution Versions Kubernetes 1.28 1.29 1.30 1.31 1.32 1.33 OpenShift 4.14 4.15 4.16 4.17 4.18"},{"location":"releases/release-v2.6/#api-versions","title":"API Versions","text":""},{"location":"releases/release-v2.6/#general-availability-ga","title":"General Availability (GA)","text":"kind apiVersion Bucket <code>source.toolkit.fluxcd.io/v1</code> GitRepository <code>source.toolkit.fluxcd.io/v1</code> HelmChart <code>source.toolkit.fluxcd.io/v1</code> HelmRelease <code>helm.toolkit.fluxcd.io/v2</code> HelmRepository <code>source.toolkit.fluxcd.io/v1</code> Kustomization <code>kustomize.toolkit.fluxcd.io/v1</code> OCIRepository <code>source.toolkit.fluxcd.io/v1</code> Receiver <code>notification.toolkit.fluxcd.io/v1</code>"},{"location":"releases/release-v2.6/#beta-preview","title":"Beta (Preview)","text":"kind apiVersion Alert <code>notification.toolkit.fluxcd.io/v1beta3</code> ImagePolicy <code>image.toolkit.fluxcd.io/v1beta2</code> ImageRepository <code>image.toolkit.fluxcd.io/v1beta2</code> ImageUpdateAutomation <code>image.toolkit.fluxcd.io/v1beta2</code> Provider <code>notification.toolkit.fluxcd.io/v1beta3</code>"},{"location":"releases/release-v2.6/#v264","title":"v2.6.4","text":"<p>Upstream changelog: fluxcd/flux2 v2.6.4</p>"},{"location":"releases/release-v2.6/#mainline-v264","title":"Mainline v2.6.4","text":""},{"location":"releases/release-v2.6/#flux-controllers","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.6.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.6.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v1.3.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v0.35.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v0.41.2 amd64 / arm64"},{"location":"releases/release-v2.6/#flux-manifests","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.6.4"},{"location":"releases/release-v2.6/#fips-compliant-v264","title":"FIPS-compliant v2.6.4","text":""},{"location":"releases/release-v2.6/#flux-controllers_1","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.6.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.6.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v1.3.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v0.35.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v0.41.2 amd64 / arm64"},{"location":"releases/release-v2.6/#flux-controllers-for-aws-marketplace","title":"Flux Controllers for AWS Marketplace","text":"Controller Version Architectures <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-controller</code> v1.6.2 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/kustomize-controller</code> v1.6.1 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/helm-controller</code> v1.3.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/notification-controller</code> v1.6.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-reflector-controller</code> v0.35.2 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-automation-controller</code> v0.41.2 amd64 / arm64"},{"location":"releases/release-v2.6/#flux-manifests_1","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.6.4"},{"location":"releases/release-v2.6/#v263","title":"v2.6.3","text":"<p>Upstream changelog: fluxcd/flux2 v2.6.3</p>"},{"location":"releases/release-v2.6/#mainline-v263","title":"Mainline v2.6.3","text":""},{"location":"releases/release-v2.6/#flux-controllers_2","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.6.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v1.3.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v0.35.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v0.41.2 amd64 / arm64"},{"location":"releases/release-v2.6/#flux-manifests_2","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.6.3"},{"location":"releases/release-v2.6/#fips-compliant-v263","title":"FIPS-compliant v2.6.3","text":""},{"location":"releases/release-v2.6/#flux-controllers_3","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.6.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v1.3.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v0.35.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v0.41.2 amd64 / arm64"},{"location":"releases/release-v2.6/#flux-controllers-for-aws-marketplace_1","title":"Flux Controllers for AWS Marketplace","text":"Controller Version Architectures <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-controller</code> v1.6.2 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/kustomize-controller</code> v1.6.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/helm-controller</code> v1.3.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/notification-controller</code> v1.6.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-reflector-controller</code> v0.35.2 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-automation-controller</code> v0.41.2 amd64 / arm64"},{"location":"releases/release-v2.6/#flux-manifests_3","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.6.3"},{"location":"releases/release-v2.6/#v262","title":"v2.6.2","text":"<p>Upstream changelog: fluxcd/flux2 v2.6.2</p>"},{"location":"releases/release-v2.6/#mainline-v262","title":"Mainline v2.6.2","text":""},{"location":"releases/release-v2.6/#flux-controllers_4","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.6.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v1.3.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v0.35.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v0.41.1 amd64 / arm64"},{"location":"releases/release-v2.6/#flux-manifests_4","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.6.2"},{"location":"releases/release-v2.6/#fips-compliant-v262","title":"FIPS-compliant v2.6.2","text":""},{"location":"releases/release-v2.6/#flux-controllers_5","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.6.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v1.3.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v0.35.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v0.41.1 amd64 / arm64"},{"location":"releases/release-v2.6/#flux-controllers-for-aws-marketplace_2","title":"Flux Controllers for AWS Marketplace","text":"Controller Version Architectures <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-controller</code> v1.6.1 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/kustomize-controller</code> v1.6.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/helm-controller</code> v1.3.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/notification-controller</code> v1.6.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-reflector-controller</code> v0.35.2 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-automation-controller</code> v0.41.1 amd64 / arm64"},{"location":"releases/release-v2.6/#flux-manifests_5","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.6.2"},{"location":"releases/release-v2.6/#v261","title":"v2.6.1","text":"<p>Upstream changelog: fluxcd/flux2 v2.6.1</p>"},{"location":"releases/release-v2.6/#mainline-v261","title":"Mainline v2.6.1","text":""},{"location":"releases/release-v2.6/#flux-controllers_6","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v1.3.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v0.35.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v0.41.0 amd64 / arm64"},{"location":"releases/release-v2.6/#flux-manifests_6","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.6.1"},{"location":"releases/release-v2.6/#fips-compliant-v261","title":"FIPS-compliant v2.6.1","text":""},{"location":"releases/release-v2.6/#flux-controllers_7","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v1.3.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v0.35.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v0.41.0 amd64 / arm64"},{"location":"releases/release-v2.6/#flux-controllers-for-aws-marketplace_3","title":"Flux Controllers for AWS Marketplace","text":"Controller Version Architectures <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-controller</code> v1.6.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/kustomize-controller</code> v1.6.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/helm-controller</code> v1.3.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/notification-controller</code> v1.6.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-reflector-controller</code> v0.35.1 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-automation-controller</code> v0.41.0 amd64 / arm64"},{"location":"releases/release-v2.6/#flux-manifests_7","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.6.1"},{"location":"releases/release-v2.6/#v260","title":"v2.6.0","text":"<p>Upstream changelog: fluxcd/flux2 v2.6.0</p>"},{"location":"releases/release-v2.6/#mainline-v260","title":"Mainline v2.6.0","text":""},{"location":"releases/release-v2.6/#flux-controllers_8","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v1.3.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v0.35.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v0.41.0 amd64 / arm64"},{"location":"releases/release-v2.6/#flux-manifests_8","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.6.0"},{"location":"releases/release-v2.6/#fips-compliant-v260","title":"FIPS-compliant v2.6.0","text":""},{"location":"releases/release-v2.6/#flux-controllers_9","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v1.3.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.6.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v0.35.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v0.41.0 amd64 / arm64"},{"location":"releases/release-v2.6/#flux-controllers-for-aws-marketplace_4","title":"Flux Controllers for AWS Marketplace","text":"Controller Version Architectures <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-controller</code> v1.6.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/kustomize-controller</code> v1.6.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/helm-controller</code> v1.3.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/notification-controller</code> v1.6.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-reflector-controller</code> v0.35.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-automation-controller</code> v0.41.0 amd64 / arm64"},{"location":"releases/release-v2.6/#flux-manifests_9","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.6.0"},{"location":"releases/release-v2.7/","title":"Enterprise Distribution for Flux v2.7.x","text":""},{"location":"releases/release-v2.7/#supported-kubernetes-versions","title":"Supported Kubernetes Versions","text":"Distribution Versions Kubernetes 1.29 1.30 1.31 1.32 1.33 1.34 OpenShift 4.16 4.17 4.18 4.19"},{"location":"releases/release-v2.7/#api-versions","title":"API Versions","text":""},{"location":"releases/release-v2.7/#general-availability-ga","title":"General Availability (GA)","text":"kind apiVersion Bucket <code>source.toolkit.fluxcd.io/v1</code> GitRepository <code>source.toolkit.fluxcd.io/v1</code> HelmChart <code>source.toolkit.fluxcd.io/v1</code> HelmRelease <code>helm.toolkit.fluxcd.io/v2</code> HelmRepository <code>source.toolkit.fluxcd.io/v1</code> ImagePolicy <code>image.toolkit.fluxcd.io/v1</code> ImageRepository <code>image.toolkit.fluxcd.io/v1</code> ImageUpdateAutomation <code>image.toolkit.fluxcd.io/v1</code> Kustomization <code>kustomize.toolkit.fluxcd.io/v1</code> OCIRepository <code>source.toolkit.fluxcd.io/v1</code> Receiver <code>notification.toolkit.fluxcd.io/v1</code>"},{"location":"releases/release-v2.7/#beta-preview","title":"Beta (Preview)","text":"kind apiVersion Alert <code>notification.toolkit.fluxcd.io/v1beta3</code> Provider <code>notification.toolkit.fluxcd.io/v1beta3</code> ArtifactGenerator <code>source.extensions.fluxcd.io/v1beta1</code>"},{"location":"releases/release-v2.7/#v273","title":"v2.7.3","text":"<p>Upstream changelog: fluxcd/flux2 v2.7.3</p>"},{"location":"releases/release-v2.7/#mainline-v273","title":"Mainline v2.7.3","text":""},{"location":"releases/release-v2.7/#flux-controllers","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.7.3 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/source-watcher</code> v2.0.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.7.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v1.4.3 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.7.4 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v1.0.3 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v1.0.3 amd64 / arm64"},{"location":"releases/release-v2.7/#flux-manifests","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.7.3"},{"location":"releases/release-v2.7/#fips-compliant-v273","title":"FIPS-compliant v2.7.3","text":""},{"location":"releases/release-v2.7/#flux-controllers_1","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.7.3 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/source-watcher</code> v2.0.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.7.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v1.4.3 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.7.4 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v1.0.3 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v1.0.3 amd64 / arm64"},{"location":"releases/release-v2.7/#flux-controllers-for-aws-marketplace","title":"Flux Controllers for AWS Marketplace","text":"Controller Version Architectures <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-controller</code> v1.7.3 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-watcher</code> v2.0.2 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/kustomize-controller</code> v1.7.2 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/helm-controller</code> v1.4.3 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/notification-controller</code> v1.7.4 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-reflector-controller</code> v1.0.3 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-automation-controller</code> v1.0.3 amd64 / arm64"},{"location":"releases/release-v2.7/#flux-manifests_1","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.7.3"},{"location":"releases/release-v2.7/#v272","title":"v2.7.2","text":"<p>Upstream changelog: fluxcd/flux2 v2.7.2</p>"},{"location":"releases/release-v2.7/#mainline-v272","title":"Mainline v2.7.2","text":""},{"location":"releases/release-v2.7/#flux-controllers_2","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.7.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/source-watcher</code> v2.0.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.7.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v1.4.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.7.3 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v1.0.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v1.0.2 amd64 / arm64"},{"location":"releases/release-v2.7/#flux-manifests_2","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.7.2"},{"location":"releases/release-v2.7/#fips-compliant-v272","title":"FIPS-compliant v2.7.2","text":""},{"location":"releases/release-v2.7/#flux-controllers_3","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.7.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/source-watcher</code> v2.0.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.7.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v1.4.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.7.3 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v1.0.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v1.0.2 amd64 / arm64"},{"location":"releases/release-v2.7/#flux-controllers-for-aws-marketplace_1","title":"Flux Controllers for AWS Marketplace","text":"Controller Version Architectures <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-controller</code> v1.7.2 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-watcher</code> v2.0.2 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/kustomize-controller</code> v1.7.1 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/helm-controller</code> v1.4.2 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/notification-controller</code> v1.7.3 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-reflector-controller</code> v1.0.2 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-automation-controller</code> v1.0.2 amd64 / arm64"},{"location":"releases/release-v2.7/#flux-manifests_3","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.7.2"},{"location":"releases/release-v2.7/#v271","title":"v2.7.1","text":"<p>Upstream changelog: fluxcd/flux2 v2.7.1</p>"},{"location":"releases/release-v2.7/#mainline-v271","title":"Mainline v2.7.1","text":""},{"location":"releases/release-v2.7/#flux-controllers_4","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.7.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/source-watcher</code> v2.0.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.7.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v1.4.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.7.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v1.0.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v1.0.1 amd64 / arm64"},{"location":"releases/release-v2.7/#flux-manifests_4","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.7.1"},{"location":"releases/release-v2.7/#fips-compliant-v271","title":"FIPS-compliant v2.7.1","text":""},{"location":"releases/release-v2.7/#flux-controllers_5","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.7.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/source-watcher</code> v2.0.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.7.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v1.4.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.7.2 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v1.0.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v1.0.1 amd64 / arm64"},{"location":"releases/release-v2.7/#flux-controllers-for-aws-marketplace_2","title":"Flux Controllers for AWS Marketplace","text":"Controller Version Architectures <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-controller</code> v1.7.1 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-watcher</code> v2.0.1 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/kustomize-controller</code> v1.7.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/helm-controller</code> v1.4.1 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/notification-controller</code> v1.7.2 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-reflector-controller</code> v1.0.1 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-automation-controller</code> v1.0.1 amd64 / arm64"},{"location":"releases/release-v2.7/#flux-manifests_5","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.7.1"},{"location":"releases/release-v2.7/#v270","title":"v2.7.0","text":"<p>Upstream changelog: fluxcd/flux2 v2.7.0</p>"},{"location":"releases/release-v2.7/#mainline-v270","title":"Mainline v2.7.0","text":""},{"location":"releases/release-v2.7/#flux-controllers_6","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/alpine/source-controller</code> v1.7.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/source-watcher</code> v2.0.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/kustomize-controller</code> v1.7.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/helm-controller</code> v1.4.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/notification-controller</code> v1.7.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-reflector-controller</code> v1.0.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/alpine/image-automation-controller</code> v1.0.1 amd64 / arm64"},{"location":"releases/release-v2.7/#flux-manifests_6","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/alpine/flux-manifests</code> v2.7.0"},{"location":"releases/release-v2.7/#fips-compliant-v270","title":"FIPS-compliant v2.7.0","text":""},{"location":"releases/release-v2.7/#flux-controllers_7","title":"Flux Controllers","text":"Controller Version Architectures <code>ghcr.io/controlplaneio-fluxcd/distroless/source-controller</code> v1.7.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/source-watcher</code> v2.0.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/kustomize-controller</code> v1.7.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/helm-controller</code> v1.4.0 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/notification-controller</code> v1.7.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-reflector-controller</code> v1.0.1 amd64 / arm64 <code>ghcr.io/controlplaneio-fluxcd/distroless/image-automation-controller</code> v1.0.1 amd64 / arm64"},{"location":"releases/release-v2.7/#flux-controllers-for-aws-marketplace_3","title":"Flux Controllers for AWS Marketplace","text":"Controller Version Architectures <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-controller</code> v1.7.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/source-watcher</code> v2.0.1 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/kustomize-controller</code> v1.7.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/helm-controller</code> v1.4.0 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/notification-controller</code> v1.7.1 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-reflector-controller</code> v1.0.1 amd64 / arm64 <code>709825985650.dkr.ecr.us-east-1.amazonaws.com/controlplane/fluxcd/image-automation-controller</code> v1.0.1 amd64 / arm64"},{"location":"releases/release-v2.7/#flux-manifests_7","title":"Flux Manifests","text":"OCI Artifact Version <code>ghcr.io/controlplaneio-fluxcd/distroless/flux-manifests</code> v2.7.0"}]}